{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "833254f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights1: [[-0.22137975  0.00167169 -0.02890704 -0.07835327 -0.0818913  -0.04473316\n",
      "  -0.07977414 -0.07876425 -0.11839853 -0.14203129]\n",
      " [-0.10793411 -0.1782907  -0.13217254 -0.096198   -0.18868302 -0.01842692\n",
      "  -0.14197238 -0.13404006  0.15476579  0.04679777]\n",
      " [-0.23875195 -0.15475638  0.3718874  -0.19314677 -0.26335707  0.27412208\n",
      "  -0.43937395  0.02040501 -0.22349327  0.28245337]\n",
      " [ 0.0537452   0.01703331  0.34149903  0.32587405  0.12686899 -0.05327587\n",
      "   0.04133178 -0.3077049  -0.24370899  0.42517325]\n",
      " [-0.13117826  0.00646638 -0.09754206  0.00469225  0.11569048 -0.21067804\n",
      "   0.06001542  0.10219516  0.0855197  -0.09519465]]\n",
      "o_times: [2.204 1.595 2.172]\n",
      "Epoch 1/10 — avg loss=0.3277\n",
      "             ‖W1‖=1.305, ‖W2‖=3.934\n",
      "\n",
      "weights1: [[-0.21493659  0.00433183 -0.02628947 -0.07719417 -0.07926001 -0.03877565\n",
      "  -0.07552159 -0.07432399 -0.11569948 -0.13656268]\n",
      " [-0.10142247 -0.17330226 -0.12821799 -0.09413382 -0.18510016 -0.0098191\n",
      "  -0.13636231 -0.12829904  0.15679013  0.05097681]\n",
      " [-0.23332322 -0.15106608  0.37624426 -0.19214273 -0.26038358  0.28575867\n",
      "  -0.43361832  0.02425816 -0.22074092  0.29016368]\n",
      " [ 0.05820025  0.01977684  0.34518357  0.3292059   0.12894972 -0.04594754\n",
      "   0.04477799 -0.30219933 -0.2408425   0.43319268]\n",
      " [-0.13117826  0.00646638 -0.09754206  0.00469225  0.11569048 -0.21067804\n",
      "   0.06001542  0.10219516  0.0855197  -0.09519465]]\n",
      "o_times: [2.205 1.595 2.172]\n",
      "Epoch 2/10 — avg loss=0.3277\n",
      "             ‖W1‖=1.303, ‖W2‖=3.921\n",
      "\n",
      "weights1: [[-0.20568307  0.00781079 -0.0225326  -0.07550286 -0.07554752 -0.03040226\n",
      "  -0.06952827 -0.0680707  -0.11189102 -0.12871803]\n",
      " [-0.09207472 -0.16628852 -0.12253872 -0.09116442 -0.18004645  0.00227271\n",
      "  -0.12845809 -0.12021404  0.15965214  0.05701003]\n",
      " [-0.22546554 -0.14587168  0.38253596 -0.19066008 -0.25618664  0.30224163\n",
      "  -0.42550164  0.02971002 -0.21685437  0.30134268]\n",
      " [ 0.06454897  0.02364666  0.35050199  0.33392793  0.13189124 -0.03563049\n",
      "   0.0496495  -0.29444892 -0.23679803  0.44481353]\n",
      " [-0.13117826  0.00646638 -0.09754206  0.00469225  0.11569048 -0.21067804\n",
      "   0.06001542  0.10219516  0.0855197  -0.09519465]]\n",
      "o_times: [2.206 1.595 2.174]\n",
      "Epoch 3/10 — avg loss=0.3262\n",
      "             ‖W1‖=1.301, ‖W2‖=3.905\n",
      "\n",
      "weights1: [[-0.19405189  0.0119867  -0.01772547 -0.0733052  -0.07090934 -0.0198735\n",
      "  -0.0620461  -0.06028278 -0.10713354 -0.11868163]\n",
      " [-0.08031327 -0.15757601 -0.11526519 -0.08736983 -0.17373506  0.01615314\n",
      "  -0.11859294 -0.11014748  0.16323686  0.06479909]\n",
      " [-0.21552823 -0.13940828  0.39065777 -0.18870677 -0.25094037  0.32323575\n",
      "  -0.4153623   0.03653882 -0.2119945   0.31586296]\n",
      " [ 0.07254237  0.02847256  0.35736298  0.33985664  0.13557575 -0.02261487\n",
      "   0.05575975 -0.28480247 -0.23174626  0.45989503]\n",
      " [-0.13117827  0.00646638 -0.09754206  0.00469225  0.11569048 -0.21067804\n",
      "   0.06001542  0.10219516  0.0855197  -0.09519465]]\n",
      "o_times: [2.209 1.596 2.176]\n",
      "Epoch 4/10 — avg loss=0.3249\n",
      "             ‖W1‖=1.302, ‖W2‖=3.888\n",
      "\n",
      "weights1: [[-0.18047894  0.01674012 -0.01194259 -0.07063517 -0.06549814 -0.00735152\n",
      "  -0.05333433 -0.05123196 -0.10158329 -0.10661642]\n",
      " [-0.06656379 -0.14748199 -0.10650586 -0.08283334 -0.16637486  0.03177642\n",
      "  -0.1071116  -0.09845231  0.1674328   0.0742747 ]\n",
      " [-0.203863   -0.13190495  0.40053849 -0.18630114 -0.2448159   0.34867099\n",
      "  -0.40354674  0.04453158 -0.20631803  0.33367184]\n",
      " [ 0.08193107  0.03409134  0.36570212  0.34682563  0.13988946 -0.00705585\n",
      "   0.0629128  -0.27360051 -0.22585352  0.47837152]\n",
      " [-0.13117827  0.00646638 -0.09754206  0.00469225  0.11569048 -0.21067804\n",
      "   0.06001542  0.10219516  0.0855197  -0.09519465]]\n",
      "o_times: [2.212 1.598 2.178]\n",
      "Epoch 5/10 — avg loss=0.3231\n",
      "             ‖W1‖=1.306, ‖W2‖=3.871\n",
      "\n",
      "weights1: [[-0.1653796   0.02195285 -0.00524873 -0.06754339 -0.05945944  0.00704445\n",
      "  -0.04363077 -0.04118263 -0.09539002 -0.09266369]\n",
      " [-0.05123266 -0.13631828 -0.09635433 -0.07765575 -0.15816528  0.04915727\n",
      "  -0.09433006 -0.08547362  0.17213285  0.08539535]\n",
      " [-0.19080675 -0.1235871   0.41213302 -0.18348011 -0.2379763   0.37866335\n",
      "  -0.39037384  0.05347688 -0.19997513  0.35478598]\n",
      " [ 0.09247805  0.04034069  0.37547548  0.35466312  0.14472319  0.01096555\n",
      "   0.07093099 -0.26117492 -0.21927956  0.50024383]\n",
      " [-0.13117827  0.00646638 -0.09754206  0.00469225  0.11569048 -0.21067804\n",
      "   0.06001542  0.10219516  0.0855197  -0.09519465]]\n",
      "o_times: [2.216 1.6   2.18 ]\n",
      "Epoch 6/10 — avg loss=0.3210\n",
      "             ‖W1‖=1.317, ‖W2‖=3.856\n",
      "\n",
      "weights1: [[-0.14914559  0.02751225  0.00229671 -0.06407581 -0.05293082  0.02140956\n",
      "  -0.03308683 -0.03038051 -0.08869445 -0.07695566]\n",
      " [-0.0347055  -0.12437858 -0.08489318 -0.071932   -0.14929461  0.06836491\n",
      "  -0.08047064 -0.07153159  0.17723584  0.09814032]\n",
      " [-0.17668035 -0.11466778  0.42542374 -0.1802764  -0.23057597  0.41351443\n",
      "  -0.37602858  0.06317727 -0.19310728  0.37929386]\n",
      " [ 0.1039549   0.04706526  0.38666176  0.36320161  0.14997367  0.03227887\n",
      "   0.0796598  -0.24783391 -0.21217474  0.52558418]\n",
      " [-0.13117827  0.00646638 -0.09754206  0.00469225  0.11569048 -0.21067804\n",
      "   0.06001542  0.10219516  0.0855197  -0.09519465]]\n",
      "o_times: [2.222 1.602 2.184]\n",
      "Epoch 7/10 — avg loss=0.3186\n",
      "             ‖W1‖=1.336, ‖W2‖=3.844\n",
      "\n",
      "weights1: [[-0.13215651  0.03330885  0.0099473  -0.06028688 -0.04604257  0.0358447\n",
      "  -0.02193909 -0.01905794 -0.0816297  -0.059618  ]\n",
      " [-0.01736014 -0.11193893 -0.07219441 -0.0657655  -0.13994095  0.08950095\n",
      "  -0.06584458 -0.05692773  0.18264484  0.11250388]\n",
      " [-0.16180081 -0.1053493   0.44041239 -0.17673336 -0.22276149  0.45367872\n",
      "  -0.36083497  0.07344357 -0.18584883  0.40733568]\n",
      " [ 0.11612965  0.05411741  0.39925327  0.37227062  0.15554223  0.05704006\n",
      "   0.08892318 -0.23386766 -0.20468164  0.5545095 ]\n",
      " [-0.13117827  0.00646638 -0.09754206  0.00469225  0.11569048 -0.21067804\n",
      "   0.06001542  0.10219516  0.0855197  -0.09519465]]\n",
      "o_times: [2.227 1.605 2.187]\n",
      "Epoch 8/10 — avg loss=0.3156\n",
      "             ‖W1‖=1.365, ‖W2‖=3.837\n",
      "\n",
      "weights1: [[-1.14762323e-01  3.92377173e-02  1.77215426e-02 -5.62325194e-02\n",
      "  -3.89155863e-02  5.04519755e-02 -1.04055010e-02 -7.43212340e-03\n",
      "  -7.43186592e-02 -4.07741575e-02]\n",
      " [ 4.49699624e-04 -9.92571757e-02 -5.83231783e-02 -5.92625590e-02\n",
      "  -1.30269665e-01  1.12705020e-01 -5.07379793e-02 -4.19443915e-02\n",
      "   1.88268907e-01  1.28493396e-01]\n",
      " [-1.46465940e-01 -9.58220762e-02  4.57119779e-01 -1.72897141e-01\n",
      "  -2.14669077e-01  4.99803449e-01 -3.45092795e-01  8.40913246e-02\n",
      "  -1.78324369e-01  4.39113872e-01]\n",
      " [ 1.28772138e-01  6.13544355e-02  4.13256110e-01  3.81691507e-01\n",
      "   1.61335157e-01  8.54939774e-02  9.85559088e-02 -2.19547127e-01\n",
      "  -1.96932342e-01  5.87192332e-01]\n",
      " [-1.31178265e-01  6.46637541e-03 -9.75420634e-02  4.69224677e-03\n",
      "   1.15690476e-01 -2.10678045e-01  6.00154219e-02  1.02195157e-01\n",
      "   8.55197047e-02 -9.51946510e-02]]\n",
      "o_times: [2.233 1.608 2.19 ]\n",
      "Epoch 9/10 — avg loss=0.3127\n",
      "             ‖W1‖=1.405, ‖W2‖=3.836\n",
      "\n",
      "weights1: [[-0.09736325  0.04517597  0.02568488 -0.05039847 -0.03170469  0.0654925\n",
      "   0.00123681  0.00422689 -0.06692031 -0.02026691]\n",
      " [ 0.01773777 -0.08666453 -0.0431436  -0.05019514 -0.12050564  0.13858481\n",
      "  -0.035539   -0.02695561  0.19397777  0.14641607]\n",
      " [-0.13102569 -0.08632327  0.47590182 -0.16722692 -0.2064712   0.55385965\n",
      "  -0.32917001  0.09482237 -0.17069402  0.47557178]\n",
      " [ 0.14154587  0.06855212  0.42895996  0.39443519  0.16719147  0.11863747\n",
      "   0.10826905 -0.205224   -0.18910574  0.6245525 ]\n",
      " [-0.13117827  0.00646638 -0.09754206  0.00469225  0.11569048 -0.21067805\n",
      "   0.06001542  0.10219516  0.0855197  -0.09519465]]\n",
      "o_times: [2.24  1.612 2.193]\n",
      "Epoch 10/10 — avg loss=0.3236\n",
      "             ‖W1‖=1.461, ‖W2‖=3.847\n",
      "\n",
      "Trained W1: [[-0.09736325  0.04517597  0.02568488 -0.05039847 -0.03170469  0.0654925\n",
      "   0.00123681  0.00422689 -0.06692031 -0.02026691]\n",
      " [ 0.01773777 -0.08666453 -0.0431436  -0.05019514 -0.12050564  0.13858481\n",
      "  -0.035539   -0.02695561  0.19397777  0.14641607]\n",
      " [-0.13102569 -0.08632327  0.47590182 -0.16722692 -0.2064712   0.55385965\n",
      "  -0.32917001  0.09482237 -0.17069402  0.47557178]\n",
      " [ 0.14154587  0.06855212  0.42895996  0.39443519  0.16719147  0.11863747\n",
      "   0.10826905 -0.205224   -0.18910574  0.6245525 ]\n",
      " [-0.13117827  0.00646638 -0.09754206  0.00469225  0.11569048 -0.21067805\n",
      "   0.06001542  0.10219516  0.0855197  -0.09519465]]\n",
      "Trained W2: [[-0.26967375 -0.81613192  0.38103619]\n",
      " [ 0.79158498 -0.72706975  0.2474707 ]\n",
      " [ 0.8113499  -0.90293824  0.36318747]\n",
      " [ 0.83754761 -0.7985578   0.37309689]\n",
      " [ 0.09004986 -0.68154957  0.31056638]\n",
      " [ 1.30313134 -0.97647529  0.42558182]\n",
      " [ 0.78168397 -0.82136151  0.47341668]\n",
      " [ 0.73085812 -0.80050885  0.41733095]\n",
      " [ 0.53296462 -0.67398451  0.29446035]\n",
      " [ 1.1901373  -0.98729203  0.36500606]\n",
      " [-0.01780186 -0.05807777  0.03830319]]\n",
      "Hidden times for x0: [0.988 0.996 1.061 1.005 0.978 1.073 0.984 0.986 0.989 1.094]\n",
      "Hidden times for x1: [0.995 0.991 1.143 1.028 0.976 1.131 0.963 0.975 0.958 1.192]\n",
      "\n",
      "=== Test predictions ===\n",
      "Input: [0.9 0.7 0.3 0.4]\n",
      " Spike times: [2.227 1.635 2.19 ]\n",
      " Predicted class: 0, True class: 0\n",
      "\n",
      "Input: [0.6 0.7 0.8 0.9]\n",
      " Spike times: [2.248 1.616 2.197]\n",
      " Predicted class: 0, True class: 2\n",
      "\n",
      "Input: [0.9 0.7 0.3 0.4]\n",
      " Spike times: [2.227 1.635 2.19 ]\n",
      " Predicted class: 0, True class: 0\n",
      "\n",
      "Input: [0.6 0.7 0.8 0.9]\n",
      " Spike times: [2.248 1.616 2.197]\n",
      " Predicted class: 0, True class: 2\n",
      "\n",
      "Input: [0.9 0.7 0.3 0.4]\n",
      " Spike times: [2.227 1.635 2.19 ]\n",
      " Predicted class: 0, True class: 0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 282\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xi, yi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X, Y):\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m# call layer_forward(positionally) rather than with layer1_idx=\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     h_times \u001b[38;5;241m=\u001b[39m layer_forward(xi, W1_tr, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 282\u001b[0m     o_times \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m     pred_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(o_times)  \u001b[38;5;66;03m# changed to argmin WHY???\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     true_class \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(yi)\n",
      "Cell \u001b[1;32mIn[1], line 67\u001b[0m, in \u001b[0;36mlayer_forward\u001b[1;34m(inputs, W, layer_idx)\u001b[0m\n\u001b[0;32m     64\u001b[0m defaultclock\u001b[38;5;241m.\u001b[39mdt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\u001b[38;5;241m*\u001b[39mms\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# single post‐synaptic neuron\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mNeuronGroup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;43m    v : 1\u001b[39;49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;43m    sum : 1\u001b[39;49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;43m    sr : 1\u001b[39;49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;43m    scheduled_time : second\u001b[39;49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;43m    global_clock : 1\u001b[39;49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;43m\u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv>1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv=0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexact\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# init\u001b[39;00m\n\u001b[0;32m     76\u001b[0m G\u001b[38;5;241m.\u001b[39mv \u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39msum \u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39msr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\groups\\neurongroup.py:537\u001b[0m, in \u001b[0;36mNeuronGroup.__init__\u001b[1;34m(self, N, model, method, method_options, threshold, reset, refractory, events, namespace, dtype, dt, clock, order, name, codeobj_class)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    521\u001b[0m     N,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    535\u001b[0m     codeobj_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    536\u001b[0m ):\n\u001b[1;32m--> 537\u001b[0m     \u001b[43mGroup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstart\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    547\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\units\\fundamentalunits.py:2652\u001b[0m, in \u001b[0;36mcheck_units.<locals>.do_check_units.<locals>.new_f\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m   2642\u001b[0m             error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2643\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2644\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected a quantity with unit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2645\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2646\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2647\u001b[0m             )\n\u001b[0;32m   2648\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DimensionMismatchError(\n\u001b[0;32m   2649\u001b[0m                 error_message, get_dimensions(newkeyset[k])\n\u001b[0;32m   2650\u001b[0m             )\n\u001b[1;32m-> 2652\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m au:\n\u001b[0;32m   2654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(au[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m], Callable) \u001b[38;5;129;01mand\u001b[39;00m au[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   2655\u001b[0m         \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   2656\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool_,\n\u001b[0;32m   2657\u001b[0m     ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\core\\base.py:77\u001b[0m, in \u001b[0;36mBrianObject.__init__\u001b[1;34m(self, dt, clock, when, order, namespace, name)\u001b[0m\n\u001b[0;32m     75\u001b[0m         base, _ \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(sys\u001b[38;5;241m.\u001b[39mmodules[modulename]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)\n\u001b[0;32m     76\u001b[0m         bases\u001b[38;5;241m.\u001b[39mappend(base)\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname, linenum, funcname, line \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(base \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m fname \u001b[38;5;28;01mfor\u001b[39;00m base \u001b[38;5;129;01min\u001b[39;00m bases):\n\u001b[0;32m     79\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  File \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlinenum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\traceback.py:228\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 228\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\traceback.py:390\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f, lineno \u001b[38;5;129;01min\u001b[39;00m frame_gen:\n\u001b[0;32m    388\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f, (lineno, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_from_extended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_locals\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\traceback.py:429\u001b[0m, in \u001b[0;36mStackSummary._extract_from_extended_frame_gen\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    425\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    426\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals,\n\u001b[0;32m    427\u001b[0m         end_lineno\u001b[38;5;241m=\u001b[39mend_lineno, colno\u001b[38;5;241m=\u001b[39mcolno, end_colno\u001b[38;5;241m=\u001b[39mend_colno))\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 429\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(fullname)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from brian2 import *\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "from brian2 import prefs, set_device\n",
    "\n",
    "# Tell Brian2 to use the Cython code generator:\n",
    "prefs.codegen.target = 'cython'\n",
    "\n",
    "# Optionally compile but keep Python interface:\n",
    "set_device('runtime')  # default; compiles operations to .so but stays in Python process\n",
    "\n",
    "\n",
    "# suppress overflow warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "numpy.seterr(over='ignore', under='ignore')\n",
    "logging.getLogger('brian2').setLevel(logging.ERROR)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Spike timing and derivative\n",
    "\n",
    "start_scope()\n",
    "defaultclock.dt = 0.001*ms\n",
    "\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(w=1, global_clock=1, layer=1, sum=1, spikes_received=1, result=1)\n",
    "def spike_timing(w, global_clock, layer, sum, spikes_received):\n",
    "    x = global_clock % 1\n",
    "    return np.tanh(w * x)\n",
    "\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(w=1, global_clock=1, layer=1, sum=1, spikes_received=1, result=1)\n",
    "def d_spike_timing_dw(w, global_clock, layer, sum, spikes_received):\n",
    "    x = global_clock % 1\n",
    "    eps = 1e-9\n",
    "    if w >= 0:\n",
    "        return - np.power(x, (1 - w), where=(x>0), out=np.zeros_like(x)) * np.log(x + eps)\n",
    "    else:\n",
    "        return - np.power((1 - x), (1 + w), where=(x<1), out=np.ones_like(x)) * np.log(1 - x + eps)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Forward pass: 4->10->3 using two-stage mini_urd\n",
    "\n",
    "def layer_forward(inputs, W, layer_idx):\n",
    "    \"\"\"\n",
    "    inputs: array of spike times (ms) from previous layer (shape: n_in,)\n",
    "    W: weight matrix shape (n_in+1, n_out)  ← note the extra bias row\n",
    "    layer_idx: integer layer number\n",
    "    returns: array of output spike times (ms)\n",
    "    \"\"\"\n",
    "    # 1) augment inputs with bias spike @ t=0\n",
    "    bias_time = 0.0\n",
    "    aug_inputs = np.concatenate((inputs, [bias_time]))  # shape (n_in+1,)\n",
    "\n",
    "    n_in_plus_bias, n_out = W.shape\n",
    "    assert aug_inputs.size == n_in_plus_bias\n",
    "\n",
    "    out_times = []\n",
    "    for j in range(n_out):\n",
    "        start_scope()\n",
    "        defaultclock.dt = 0.001*ms\n",
    "\n",
    "        # single post‐synaptic neuron\n",
    "        G = NeuronGroup(1, '''\n",
    "            v : 1\n",
    "            sum : 1\n",
    "            sr : 1\n",
    "            scheduled_time : second\n",
    "            global_clock : 1\n",
    "        ''', threshold='v>1', reset='v=0', method='exact')\n",
    "\n",
    "        # init\n",
    "        G.v = G.sum = G.sr = 0\n",
    "        G.global_clock = 0\n",
    "        G.scheduled_time = 1e9*second\n",
    "\n",
    "        # stim: now includes bias spike at t=0\n",
    "        stim = SpikeGeneratorGroup(n_in_plus_bias,\n",
    "                                   indices=list(range(n_in_plus_bias)),\n",
    "                                   times=aug_inputs*ms)\n",
    "\n",
    "        S = Synapses(stim, G, '''w:1\n",
    "            layer:1''',\n",
    "            on_pre='''\n",
    "            sr += 1\n",
    "            sum += spike_timing(w, global_clock, layer, sum, sr)\n",
    "            scheduled_time = (sum/sr + layer)*ms\n",
    "        ''')\n",
    "        S.connect(True)\n",
    "        S.w = W[:, j]\n",
    "        S.layer = layer_idx\n",
    "\n",
    "        G.run_regularly('''\n",
    "            v = int(abs(t - scheduled_time) < 0.001*ms) * 1.2\n",
    "            global_clock += 0.001\n",
    "        ''', dt=0.001*ms)\n",
    "\n",
    "        mon = SpikeMonitor(G)\n",
    "        run(5*ms)\n",
    "\n",
    "        ts = mon.spike_trains()[0]\n",
    "        t0 = float(ts[0]/ms) if len(ts)>0 else float(5.0)\n",
    "        out_times.append(t0)\n",
    "\n",
    "    return np.array(out_times)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Training loop with backprop for 4-10-3\n",
    "def train_snn_backprop(\n",
    "    X, Y,                # lists of input arrays (4,) and target (3,)\n",
    "    W1_init, W2_init,\n",
    "    epochs=10, lr=0.1,\n",
    "    max_grad=20.0, w_min=-20.0, w_max=20.0,\n",
    "    non_target_time=2.0,\n",
    "    λ=0.5                # non-target penalty weight\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a 4→10→3 spiking network with:\n",
    "      • batched gradient updates\n",
    "      • boosted hidden-layer learning rate\n",
    "      • separate gradient clipping per layer\n",
    "      • classical momentum smoothing\n",
    "    \"\"\"\n",
    "    # Initialize weights\n",
    "    W1 = W1_init.copy()      # shape (5,10) including bias row\n",
    "    W2 = W2_init.copy()      # shape (11,3) including bias row\n",
    "\n",
    "    # Momentum buffers\n",
    "    beta = 0.9\n",
    "    vW1 = np.zeros_like(W1)\n",
    "    vW2 = np.zeros_like(W2)\n",
    "\n",
    "    layer1_idx, layer2_idx = 1, 2\n",
    "    N = len(X)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        # Accumulators for this epoch\n",
    "        acc_dW1 = np.zeros_like(W1)\n",
    "        acc_dW2 = np.zeros_like(W2)\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for xi, yi in zip(X, Y):\n",
    "            # — Forward pass —\n",
    "            h_times = layer_forward(xi, W1, layer1_idx)\n",
    "            o_times = layer_forward(h_times, W2, layer2_idx)\n",
    "\n",
    "            # — Separation loss —\n",
    "            target_idx = np.argmax(yi)\n",
    "            L_target = 0.5 * (o_times[target_idx] - yi[target_idx])**2\n",
    "            non_ids = [j for j in range(len(o_times)) if j != target_idx]\n",
    "            L_non = 0.5 * λ * sum([(o_times[j] - non_target_time)**2 for j in non_ids])\n",
    "            L = L_target + L_non\n",
    "            epoch_loss += L\n",
    "\n",
    "            # — Gradients for W2 —\n",
    "            delta_o = np.zeros_like(o_times)\n",
    "            delta_o[target_idx] = (o_times[target_idx] - yi[target_idx])\n",
    "            for j in non_ids:\n",
    "                delta_o[j] = λ * (o_times[j] - non_target_time)\n",
    "\n",
    "            aug_h = np.concatenate((h_times, [0.0]))\n",
    "            dW2 = np.zeros_like(W2)\n",
    "            for k in range(W2.shape[0]):\n",
    "                for j in range(W2.shape[1]):\n",
    "                    dW2[k, j] = delta_o[j] * d_spike_timing_dw(\n",
    "                        W2[k, j], aug_h[k], layer2_idx, 0, 1)\n",
    "\n",
    "            # — Backprop into hidden & gradients for W1 —\n",
    "            delta_h = np.zeros_like(h_times)\n",
    "            for k in range(len(h_times)):\n",
    "                for j in range(W2.shape[1]):\n",
    "                    dt_dw_output = d_spike_timing_dw(W2[k, j], aug_h[k], layer2_idx, 0, 1)\n",
    "                    delta_h[k] += delta_o[j] * dt_dw_output  # Remove the W2[k,j] multiplication\n",
    "\n",
    "            aug_xi = np.concatenate((xi, [0.0]))\n",
    "            dW1 = np.zeros_like(W1)\n",
    "            for i in range(W1.shape[0]):\n",
    "                for k in range(W1.shape[1]):\n",
    "                    dW1[i, k] = delta_h[k] * d_spike_timing_dw(\n",
    "                        W1[i, k], aug_xi[i], layer1_idx, 0, 1)\n",
    "\n",
    "            # — Accumulate —\n",
    "            acc_dW1 += dW1\n",
    "            acc_dW2 += dW2\n",
    "\n",
    "        # — Average & clip gradients —\n",
    "        acc_dW1 /= N\n",
    "        acc_dW2 /= N\n",
    "\n",
    "        # Boost hidden-layer rate\n",
    "        lr1 = lr\n",
    "\n",
    "        # Separate clipping thresholds\n",
    "        g1 = np.clip(acc_dW1, -max_grad, max_grad)\n",
    "        g2 = np.clip(acc_dW2, -max_grad,   max_grad)\n",
    "\n",
    "        # — Momentum updates —\n",
    "        vW1 = beta * vW1 + (1 - beta) * g1\n",
    "        vW2 = beta * vW2 + (1 - beta) * g2\n",
    "\n",
    "        # — Apply weight updates & clamp —\n",
    "        W1 = W1 - lr * vW1\n",
    "        W2 = W2 - lr * vW2\n",
    "\n",
    "        print(\"weights1:\", W1)\n",
    "        print(\"o_times:\", o_times)\n",
    "\n",
    "        print(f\"Epoch {ep+1}/{epochs} — avg loss={epoch_loss/N:.4f}\")\n",
    "        print(f\"             ‖W1‖={np.linalg.norm(W1):.3f}, ‖W2‖={np.linalg.norm(W2):.3f}\\n\")\n",
    "\n",
    "    return W1, W2\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # example usage with fixed input/target pairs\n",
    "    # 4 inputs per sample, constant across 8 samples\n",
    "    x0 = np.array([0.9, 0.7, 0.3, 0.4])\n",
    "    x1 = np.array([0.6, 0.7, 0.8, 0.9])\n",
    "    X = [x0 if i % 2 == 0 else x1 for i in range(8)]\n",
    "    # 3-targets (network outputs 3 values): use desired spike times [2.1, 2.0, 1.0]\n",
    "    y0 = np.array([2.95, 2.05, 2.05])\n",
    "    y1 = np.array([2.05, 2.05, 2.95])\n",
    "    Y = [y0 if i % 2 == 0 else y1 for i in range(8)]\n",
    "    # X= []\n",
    "    # Y = []\n",
    "    # for _ in range(10):\n",
    "    #     X.append(x0 + np.random.randn(4)*0.02);  Y.append(y0)\n",
    "    #     X.append(x1 + np.random.randn(4)*0.02);  Y.append(y1)\n",
    "    \n",
    "\n",
    "    \n",
    "     #W1_0 = np.array([[0.21958991, 0.16223261, 0.02545166, 0.18849804, 0.09521701, 0.22744421, 0.05556097, 0.33130229, 0.03974721, 0.1968464],\n",
    "    #             [0.41958955, 0.47541312, 0.22287581, 0.69627866, 0.83639384, 0.79597959, 0.15029805, 0.126486, 0.18285382, 0.07470098],\n",
    "    #             [0.69559509, 0.41228614, 0.06028855, 0.51098037, 0.33730611, 1.17605488, 0.15405119, 0.28079173, 0.17365651, 0.23041775],\n",
    "    #             [0.79721356, 0.82210554, 0.15028745, 1.09421856, 0.68280376, 1.07577422, 0.16962136, 0.23838796, 0.0735181, 0.1719861],\n",
    "    #             [0.0631449, 0.10618091, 0.05791614, 0.0260418, -0.01797577, -0.1209534, 0.18702474, -0.01662061, -0.0683026, 0.05468931]])\n",
    "        #W1_0 = [[ 0.21958991,  0.16223261,  0.02545166  0.18849804  0.09521701  0.22744421, 0.05556097  0.33130229  0.03974721  0.1968464 ], [ 0.41958955  0.47541312  0.22287581  0.69627866  0.83639384  0.79597959, 0.15029805  0.126486    0.18285382  0.07470098], [ 0.69559509  0.41228614  0.06028855  0.51098037  0.33730611  1.17605488, 0.15405119  0.28079173  0.17365651  0.23041775], [ 0.79721356  0.82210554  0.15028745  1.09421856  0.68280376  1.07577422, 0.16962136  0.23838796  0.0735181   0.1719861 ], [ 0.0631449   0.10618091  0.05791614  0.0260418  -0.01797577 -0.1209534, 0.18702474 -0.01662061 -0.0683026   0.05468931]]\n",
    "        \n",
    "    \n",
    "    # W1_0 = np.random.randn(5, 10) * 0.1  # +1 for bias\n",
    "    # W2_0 = np.random.randn(11, 3) * 0.1\n",
    "\n",
    "    W1_0 = np.load('W1.npy')\n",
    "    W2_0 = np.load('W2.npy')\n",
    "\n",
    "    # W2_0 = np.array([[ 0.38843549, -1.10085101,  0.38776897],\n",
    "    #             [ 0.35841177, -1.06985881,  0.40542767],\n",
    "    #             [ 0.40732835, -0.63317637,  0.59202003],\n",
    "    #             [ 0.32589618, -0.9691458,   0.48481597],\n",
    "    #             [ 0.26060079, -0.85267046,  0.75057083],\n",
    "    #             [ 0.31287437, -1.34806606,  0.44407244],\n",
    "    #             [ 0.1996638,  -0.65507816,  0.27473825],\n",
    "    #             [ 0.40169137, -0.9979045,   0.09884702],\n",
    "    #             [ 0.37579471, -0.62826323,  0.58035222],\n",
    "    #             [ 0.2191151,  -0.84980247,  0.14767976],\n",
    "    #             [ 0.11199583, -0.16498428,  0.00871235]])\n",
    "    \n",
    "    # will print out last times so DO NOT run the same the same expermeent to have a differnt outcoem\n",
    "\n",
    "\n",
    "    # train\n",
    "    W1_tr, W2_tr = train_snn_backprop(X, Y, W1_0, W2_0,\n",
    "                                      epochs=10, lr=0.1)\n",
    "    print(\"Trained W1:\", W1_tr)\n",
    "    print(\"Trained W2:\", W2_tr) \n",
    "    print(\"Hidden times for x0:\", layer_forward(x0, W1_tr, 1))\n",
    "    print(\"Hidden times for x1:\", layer_forward(x1, W1_tr, 1))\n",
    "\n",
    "    # ── Now test on the same two patterns ──\n",
    "    print(\"\\n=== Test predictions ===\")\n",
    "    for xi, yi in zip(X, Y):\n",
    "        # call layer_forward(positionally) rather than with layer1_idx=\n",
    "        h_times = layer_forward(xi, W1_tr, 1)\n",
    "        o_times = layer_forward(h_times, W2_tr, 2)\n",
    "\n",
    "        pred_class = np.argmax(o_times)  # changed to argmin WHY???\n",
    "        true_class = np.argmax(yi)\n",
    "\n",
    "        print(f\"Input: {xi}\")\n",
    "        print(f\" Spike times: {o_times}\")\n",
    "        print(f\" Predicted class: {pred_class}, True class: {true_class}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b97bc2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Hidden times range: [1.3470, 1.6060], std: 0.0787\n",
      "Output times: [2.541 2.497 2.496], separation: 0.0450\n",
      "Sample loss: L_t=0.3875, L_n=0.1880, L_sep=1.1139, Total=1.6894\n",
      "dW1 range: [-0.1089, 0.0965], std: 0.0391\n",
      "dW2 range: [-0.0532, 0.1740], std: 0.0367\n",
      "Epoch 1: Hidden times range: [1.4320, 1.6090], std: 0.0621\n",
      "Output times: [2.527 2.521 2.511], separation: 0.0160\n",
      "Sample loss: L_t=0.4452, L_n=0.2345, L_sep=1.2550, Total=1.9347\n",
      "dW1 range: [-0.0872, 0.1170], std: 0.0413\n",
      "dW2 range: [-0.0701, 0.1465], std: 0.0333\n",
      "Epoch 1: Hidden times range: [1.4440, 1.5950], std: 0.0518\n",
      "Output times: [2.462 2.506 2.517], separation: 0.0550\n",
      "Sample loss: L_t=0.4572, L_n=0.1669, L_sep=1.0672, Total=1.6914\n",
      "dW1 range: [-0.0902, 0.1055], std: 0.0379\n",
      "dW2 range: [-0.0499, 0.1663], std: 0.0337\n",
      "Epoch 1: Hidden times range: [1.4530, 1.6410], std: 0.0508\n",
      "Output times: [2.454 2.491 2.478], separation: 0.0370\n",
      "Sample loss: L_t=0.6676, L_n=0.1656, L_sep=1.1520, Total=1.9852\n",
      "dW1 range: [-0.0780, 0.0772], std: 0.0359\n",
      "dW2 range: [-0.0642, 0.2283], std: 0.0465\n",
      "Epoch 1: Hidden times range: [1.2980, 1.5990], std: 0.1027\n",
      "Output times: [2.491 2.512 2.518], separation: 0.0270\n",
      "Sample loss: L_t=0.4725, L_n=0.2047, L_sep=1.2005, Total=1.8777\n",
      "dW1 range: [-0.1279, 0.1270], std: 0.0450\n",
      "dW2 range: [-0.0592, 0.1509], std: 0.0391\n",
      "Epoch 1: Hidden times range: [1.3760, 1.5510], std: 0.0562\n",
      "Output times: [2.573 2.506 2.518], separation: 0.0670\n",
      "Sample loss: L_t=0.4542, L_n=0.2862, L_sep=1.0125, Total=1.7529\n",
      "dW1 range: [-0.0866, 0.0867], std: 0.0368\n",
      "dW2 range: [-0.0845, 0.1657], std: 0.0369\n",
      "Epoch 1: Hidden times range: [1.3960, 1.6530], std: 0.0784\n",
      "Output times: [2.55  2.507 2.518], separation: 0.0430\n",
      "Sample loss: L_t=0.3629, L_n=0.2204, L_sep=1.1234, Total=1.7067\n",
      "dW1 range: [-0.0891, 0.0856], std: 0.0378\n",
      "dW2 range: [-0.0592, 0.1683], std: 0.0363\n",
      "Epoch 1: Hidden times range: [1.3790, 1.5860], std: 0.0573\n",
      "Output times: [2.569 2.482 2.516], separation: 0.0870\n",
      "Sample loss: L_t=0.5692, L_n=0.2913, L_sep=0.9245, Total=1.7850\n",
      "dW1 range: [-0.1243, 0.1154], std: 0.0459\n",
      "dW2 range: [-0.0832, 0.1656], std: 0.0369\n",
      "Epoch 1: ||g1||=0.0857, ||g2||=0.0470, acc=0.375\n",
      "  avg loss=1.8029\n",
      "Epoch 2: Hidden times range: [1.4190, 1.5640], std: 0.0511\n",
      "Output times: [2.553 2.516 2.492], separation: 0.0610\n",
      "Sample loss: L_t=0.3548, L_n=0.2035, L_sep=1.0397, Total=1.5981\n",
      "dW1 range: [-0.0900, 0.0735], std: 0.0359\n",
      "dW2 range: [-0.0523, 0.1665], std: 0.0334\n",
      "Epoch 2: Hidden times range: [1.4090, 1.6710], std: 0.0697\n",
      "Output times: [2.486 2.49  2.496], separation: 0.0100\n",
      "Sample loss: L_t=0.5425, L_n=0.1776, L_sep=1.2852, Total=2.0054\n",
      "dW1 range: [-0.1667, 0.1600], std: 0.0468\n",
      "dW2 range: [-0.0703, 0.1616], std: 0.0356\n",
      "Epoch 2: Hidden times range: [1.4110, 1.6510], std: 0.0784\n",
      "Output times: [2.461 2.49  2.519], separation: 0.0580\n",
      "Sample loss: L_t=0.4512, L_n=0.1505, L_sep=1.0534, Total=1.6551\n",
      "dW1 range: [-0.0847, 0.0814], std: 0.0348\n",
      "dW2 range: [-0.0567, 0.1652], std: 0.0357\n",
      "Epoch 2: Hidden times range: [1.3470, 1.5690], std: 0.0707\n",
      "Output times: [2.575 2.49  2.518], separation: 0.0850\n",
      "Sample loss: L_t=0.2987, L_n=0.2038, L_sep=0.9331, Total=1.4356\n",
      "dW1 range: [-0.1155, 0.0957], std: 0.0379\n",
      "dW2 range: [-0.0592, 0.1527], std: 0.0328\n",
      "Epoch 2: Hidden times range: [1.3930, 1.6130], std: 0.0631\n",
      "Output times: [2.487 2.49  2.528], separation: 0.0410\n",
      "Sample loss: L_t=0.5425, L_n=0.2120, L_sep=1.1329, Total=1.8874\n",
      "dW1 range: [-0.0928, 0.1296], std: 0.0415\n",
      "dW2 range: [-0.0620, 0.1616], std: 0.0353\n",
      "Epoch 2: Hidden times range: [1.3740, 1.6000], std: 0.0624\n",
      "Output times: [2.505 2.516 2.51 ], separation: 0.0110\n",
      "Sample loss: L_t=0.4786, L_n=0.2163, L_sep=1.2802, Total=1.9751\n",
      "dW1 range: [-0.0964, 0.0959], std: 0.0383\n",
      "dW2 range: [-0.0632, 0.1701], std: 0.0362\n",
      "Epoch 2: Hidden times range: [1.4300, 1.6060], std: 0.0552\n",
      "Output times: [2.588 2.487 2.501], separation: 0.1010\n",
      "Sample loss: L_t=0.2677, L_n=0.1834, L_sep=0.8653, Total=1.3164\n",
      "dW1 range: [-0.0994, 0.1155], std: 0.0384\n",
      "dW2 range: [-0.0545, 0.1446], std: 0.0298\n",
      "Epoch 2: Hidden times range: [1.4530, 1.6070], std: 0.0468\n",
      "Output times: [2.557 2.488 2.484], separation: 0.0730\n",
      "Sample loss: L_t=0.5491, L_n=0.2441, L_sep=0.9857, Total=1.7789\n",
      "dW1 range: [-0.0998, 0.1388], std: 0.0440\n",
      "dW2 range: [-0.0795, 0.1625], std: 0.0356\n",
      "Epoch 2: ||g1||=0.1002, ||g2||=0.0454, acc=0.375\n",
      "  avg loss=1.7065\n",
      "Epoch 3: Hidden times range: [1.4270, 1.6580], std: 0.0714\n",
      "Output times: [2.539 2.514 2.537], separation: 0.0250\n",
      "Sample loss: L_t=0.3931, L_n=0.2491, L_sep=1.2103, Total=1.8525\n",
      "dW1 range: [-0.0966, 0.0929], std: 0.0361\n",
      "dW2 range: [-0.0644, 0.1752], std: 0.0375\n",
      "Epoch 3: Hidden times range: [1.3770, 1.6950], std: 0.0971\n",
      "Output times: [2.495 2.57  2.508], separation: 0.0750\n",
      "Sample loss: L_t=0.3110, L_n=0.1980, L_sep=0.9768, Total=1.4858\n",
      "dW1 range: [-0.0907, 0.0949], std: 0.0378\n",
      "dW2 range: [-0.0601, 0.1221], std: 0.0317\n",
      "Epoch 3: Hidden times range: [1.3600, 1.5910], std: 0.0622\n",
      "Output times: [2.523 2.521 2.549], separation: 0.0280\n",
      "Sample loss: L_t=0.3656, L_n=0.2407, L_sep=1.1956, Total=1.8019\n",
      "dW1 range: [-0.1405, 0.1199], std: 0.0431\n",
      "dW2 range: [-0.0689, 0.1487], std: 0.0332\n",
      "Epoch 3: Hidden times range: [1.4550, 1.6210], std: 0.0479\n",
      "Output times: [2.455 2.525 2.506], separation: 0.0700\n",
      "Sample loss: L_t=0.6639, L_n=0.2271, L_sep=0.9990, Total=1.8901\n",
      "dW1 range: [-0.0945, 0.1424], std: 0.0413\n",
      "dW2 range: [-0.0559, 0.2277], std: 0.0447\n",
      "Epoch 3: Hidden times range: [1.3790, 1.5850], std: 0.0659\n",
      "Output times: [2.481 2.513 2.532], separation: 0.0510\n",
      "Sample loss: L_t=0.4694, L_n=0.2111, L_sep=1.0858, Total=1.7663\n",
      "dW1 range: [-0.1186, 0.0751], std: 0.0384\n",
      "dW2 range: [-0.0631, 0.1500], std: 0.0337\n",
      "Epoch 3: Hidden times range: [1.3740, 1.6010], std: 0.0761\n",
      "Output times: [2.442 2.525 2.513], separation: 0.0830\n",
      "Sample loss: L_t=0.4694, L_n=0.1722, L_sep=0.9418, Total=1.5834\n",
      "dW1 range: [-0.0613, 0.0923], std: 0.0342\n",
      "dW2 range: [-0.0544, 0.1685], std: 0.0358\n",
      "Epoch 3: Hidden times range: [1.4110, 1.5960], std: 0.0683\n",
      "Output times: [2.469 2.503 2.528], separation: 0.0590\n",
      "Sample loss: L_t=0.6139, L_n=0.2274, L_sep=1.0488, Total=1.8901\n",
      "dW1 range: [-0.0800, 0.0910], std: 0.0372\n",
      "dW2 range: [-0.0620, 0.2190], std: 0.0441\n",
      "Epoch 3: Hidden times range: [1.3450, 1.5650], std: 0.0787\n",
      "Output times: [2.55  2.495 2.527], separation: 0.0550\n",
      "Sample loss: L_t=0.5262, L_n=0.2789, L_sep=1.0672, Total=1.8723\n",
      "dW1 range: [-0.1318, 0.1374], std: 0.0443\n",
      "dW2 range: [-0.0773, 0.1588], std: 0.0384\n",
      "Epoch 3: ||g1||=0.1224, ||g2||=0.0653, acc=0.250\n",
      "  avg loss=1.7678\n",
      "Epoch 4: Hidden times range: [1.3900, 1.6390], std: 0.0680\n",
      "Output times: [2.557 2.499 2.496], separation: 0.0610\n",
      "Sample loss: L_t=0.3443, L_n=0.1899, L_sep=1.0397, Total=1.5739\n",
      "dW1 range: [-0.1067, 0.0956], std: 0.0407\n",
      "dW2 range: [-0.0532, 0.1640], std: 0.0342\n",
      "Epoch 4: Hidden times range: [1.4230, 1.5720], std: 0.0481\n",
      "Output times: [2.492 2.51  2.501], separation: 0.0180\n",
      "Sample loss: L_t=0.4786, L_n=0.1881, L_sep=1.2450, Total=1.9117\n",
      "dW1 range: [-0.0890, 0.1062], std: 0.0413\n",
      "dW2 range: [-0.0592, 0.1512], std: 0.0318\n",
      "Epoch 4: Hidden times range: [1.4170, 1.6030], std: 0.0694\n",
      "Output times: [2.428 2.496 2.493], separation: 0.0680\n",
      "Sample loss: L_t=0.5327, L_n=0.1328, L_sep=1.0080, Total=1.6735\n",
      "dW1 range: [-0.0783, 0.1016], std: 0.0386\n",
      "dW2 range: [-0.0472, 0.1794], std: 0.0370\n",
      "Epoch 4: Hidden times range: [1.3730, 1.6050], std: 0.0695\n",
      "Output times: [2.5   2.509 2.349], separation: 0.1600\n",
      "Sample loss: L_t=0.5101, L_n=0.1119, L_sep=0.6372, Total=1.2592\n",
      "dW1 range: [-0.0766, 0.0834], std: 0.0345\n",
      "dW2 range: [-0.0504, 0.1996], std: 0.0398\n",
      "Epoch 4: Hidden times range: [1.3030, 1.5650], std: 0.0812\n",
      "Output times: [2.454 2.489 2.476], separation: 0.0350\n",
      "Sample loss: L_t=0.5458, L_n=0.1325, L_sep=1.1616, Total=1.8399\n",
      "dW1 range: [-0.1876, 0.1198], std: 0.0498\n",
      "dW2 range: [-0.0477, 0.1614], std: 0.0366\n",
      "Epoch 4: Hidden times range: [1.3610, 1.5720], std: 0.0622\n",
      "Output times: [2.503 2.512 2.521], separation: 0.0180\n",
      "Sample loss: L_t=0.4452, L_n=0.2100, L_sep=1.2450, Total=1.9002\n",
      "dW1 range: [-0.1017, 0.1057], std: 0.0362\n",
      "dW2 range: [-0.0626, 0.1640], std: 0.0348\n",
      "Epoch 4: Hidden times range: [1.3870, 1.5920], std: 0.0730\n",
      "Output times: [2.562 2.503 2.496], separation: 0.0660\n",
      "Sample loss: L_t=0.3313, L_n=0.1939, L_sep=1.0170, Total=1.5422\n",
      "dW1 range: [-0.0733, 0.0631], std: 0.0332\n",
      "dW2 range: [-0.0532, 0.1609], std: 0.0339\n",
      "Epoch 4: Hidden times range: [1.3810, 1.5980], std: 0.0778\n",
      "Output times: [2.474 2.557 2.509], separation: 0.0830\n",
      "Sample loss: L_t=0.3443, L_n=0.1799, L_sep=0.9418, Total=1.4660\n",
      "dW1 range: [-0.0747, 0.0800], std: 0.0365\n",
      "dW2 range: [-0.0567, 0.1282], std: 0.0304\n",
      "Epoch 4: ||g1||=0.0861, ||g2||=0.0551, acc=0.250\n",
      "  avg loss=1.6458\n",
      "Epoch 5: Hidden times range: [1.4170, 1.5990], std: 0.0615\n",
      "Output times: [2.603 2.496 2.504], separation: 0.1070\n",
      "Sample loss: L_t=0.2341, L_n=0.1949, L_sep=0.8405, Total=1.2696\n",
      "dW1 range: [-0.0764, 0.1053], std: 0.0392\n",
      "dW2 range: [-0.0554, 0.1352], std: 0.0291\n",
      "Epoch 5: Hidden times range: [1.4270, 1.6790], std: 0.0743\n",
      "Output times: [2.47  2.531 2.601], separation: 0.1310\n",
      "Sample loss: L_t=0.4159, L_n=0.2927, L_sep=0.7450, Total=1.4535\n",
      "dW1 range: [-0.1981, 0.1899], std: 0.0499\n",
      "dW2 range: [-0.0820, 0.1405], std: 0.0343\n",
      "Epoch 5: Hidden times range: [1.4110, 1.5870], std: 0.0617\n",
      "Output times: [2.495 2.482 2.534], separation: 0.0520\n",
      "Sample loss: L_t=0.4073, L_n=0.1730, L_sep=1.0811, Total=1.6614\n",
      "dW1 range: [-0.0757, 0.0652], std: 0.0339\n",
      "dW2 range: [-0.0601, 0.1569], std: 0.0333\n",
      "Epoch 5: Hidden times range: [1.3670, 1.6280], std: 0.0713\n",
      "Output times: [2.461 2.424 2.482], separation: 0.0580\n",
      "Sample loss: L_t=0.6423, L_n=0.1173, L_sep=1.0534, Total=1.8130\n",
      "dW1 range: [-0.1029, 0.1376], std: 0.0430\n",
      "dW2 range: [-0.0572, 0.2240], std: 0.0441\n",
      "Epoch 5: Hidden times range: [1.4350, 1.6010], std: 0.0528\n",
      "Output times: [2.483 2.525 2.514], separation: 0.0420\n",
      "Sample loss: L_t=0.4334, L_n=0.1931, L_sep=1.1281, Total=1.7546\n",
      "dW1 range: [-0.1082, 0.1292], std: 0.0433\n",
      "dW2 range: [-0.0581, 0.1434], std: 0.0312\n",
      "Epoch 5: Hidden times range: [1.4280, 1.5890], std: 0.0605\n",
      "Output times: [2.608 2.482 2.485], separation: 0.1260\n",
      "Sample loss: L_t=0.5591, L_n=0.3136, L_sep=0.7644, Total=1.6372\n",
      "dW1 range: [-0.0786, 0.0725], std: 0.0363\n",
      "dW2 range: [-0.0954, 0.1838], std: 0.0400\n",
      "Epoch 5: Hidden times range: [1.3470, 1.5910], std: 0.0730\n",
      "Output times: [2.447 2.481 2.503], separation: 0.0560\n",
      "Sample loss: L_t=0.6934, L_n=0.1800, L_sep=1.0626, Total=1.9360\n",
      "dW1 range: [-0.1058, 0.0876], std: 0.0370\n",
      "dW2 range: [-0.0551, 0.2327], std: 0.0466\n",
      "Epoch 5: Hidden times range: [1.4050, 1.6320], std: 0.0658\n",
      "Output times: [2.447 2.472 2.507], separation: 0.0600\n",
      "Sample loss: L_t=0.6034, L_n=0.1566, L_sep=1.0442, Total=1.8043\n",
      "dW1 range: [-0.0741, 0.0839], std: 0.0372\n",
      "dW2 range: [-0.0571, 0.1693], std: 0.0362\n",
      "Epoch 5: ||g1||=0.0733, ||g2||=0.0612, acc=0.375\n",
      "  avg loss=1.6662\n",
      "Epoch 6: Hidden times range: [1.3470, 1.6360], std: 0.0953\n",
      "Output times: [2.455 2.483 2.555], separation: 0.1000\n",
      "Sample loss: L_t=0.6639, L_n=0.2406, L_sep=0.8694, Total=1.7740\n",
      "dW1 range: [-0.0830, 0.0653], std: 0.0350\n",
      "dW2 range: [-0.0694, 0.2277], std: 0.0493\n",
      "Epoch 6: Hidden times range: [1.3710, 1.6000], std: 0.0657\n",
      "Output times: [2.445 2.559 2.518], separation: 0.1140\n",
      "Sample loss: L_t=0.3390, L_n=0.1667, L_sep=0.8120, Total=1.3178\n",
      "dW1 range: [-0.1101, 0.1016], std: 0.0394\n",
      "dW2 range: [-0.0592, 0.1264], std: 0.0295\n",
      "Epoch 6: Hidden times range: [1.3720, 1.6040], std: 0.0723\n",
      "Output times: [2.506 2.483 2.486], separation: 0.0230\n",
      "Sample loss: L_t=0.5558, L_n=0.1848, L_sep=1.2202, Total=1.9607\n",
      "dW1 range: [-0.0814, 0.1027], std: 0.0388\n",
      "dW2 range: [-0.0636, 0.1833], std: 0.0389\n",
      "Epoch 6: Hidden times range: [1.4120, 1.6340], std: 0.0616\n",
      "Output times: [2.491 2.48  2.494], separation: 0.0140\n",
      "Sample loss: L_t=0.5392, L_n=0.1703, L_sep=1.2650, Total=1.9745\n",
      "dW1 range: [-0.0738, 0.1112], std: 0.0383\n",
      "dW2 range: [-0.0526, 0.2052], std: 0.0409\n",
      "Epoch 6: Hidden times range: [1.3410, 1.5990], std: 0.0734\n",
      "Output times: [2.436 2.521 2.502], separation: 0.0850\n",
      "Sample loss: L_t=0.4452, L_n=0.1439, L_sep=0.9331, Total=1.5222\n",
      "dW1 range: [-0.1229, 0.1056], std: 0.0432\n",
      "dW2 range: [-0.0548, 0.1449], std: 0.0321\n",
      "Epoch 6: Hidden times range: [1.3760, 1.6010], std: 0.0635\n",
      "Output times: [2.441 2.496 2.484], separation: 0.0550\n",
      "Sample loss: L_t=0.5625, L_n=0.1414, L_sep=1.0672, Total=1.7711\n",
      "dW1 range: [-0.0954, 0.1217], std: 0.0413\n",
      "dW2 range: [-0.0469, 0.1844], std: 0.0373\n",
      "Epoch 6: Hidden times range: [1.3820, 1.5980], std: 0.0773\n",
      "Output times: [2.483 2.492 2.505], separation: 0.0220\n",
      "Sample loss: L_t=0.5658, L_n=0.1921, L_sep=1.2251, Total=1.9830\n",
      "dW1 range: [-0.0775, 0.0792], std: 0.0351\n",
      "dW2 range: [-0.0556, 0.2102], std: 0.0432\n",
      "Epoch 6: Hidden times range: [1.3340, 1.5300], std: 0.0627\n",
      "Output times: [2.536 2.52  2.504], separation: 0.0320\n",
      "Sample loss: L_t=0.4482, L_n=0.2376, L_sep=1.1761, Total=1.8619\n",
      "dW1 range: [-0.1236, 0.1406], std: 0.0435\n",
      "dW2 range: [-0.0729, 0.1454], std: 0.0345\n",
      "Epoch 6: ||g1||=0.1405, ||g2||=0.0629, acc=0.375\n",
      "  avg loss=1.7707\n",
      "Epoch 7: Hidden times range: [1.4300, 1.5950], std: 0.0634\n",
      "Output times: [2.447 2.477 2.485], separation: 0.0380\n",
      "Sample loss: L_t=0.6934, L_n=0.1592, L_sep=1.1472, Total=1.9998\n",
      "dW1 range: [-0.0700, 0.0952], std: 0.0360\n",
      "dW2 range: [-0.0501, 0.2327], std: 0.0458\n",
      "Epoch 7: Hidden times range: [1.3170, 1.6230], std: 0.0927\n",
      "Output times: [2.474 2.493 2.497], separation: 0.0230\n",
      "Sample loss: L_t=0.5327, L_n=0.1679, L_sep=1.2202, Total=1.9208\n",
      "dW1 range: [-0.1387, 0.0831], std: 0.0420\n",
      "dW2 range: [-0.0536, 0.1578], std: 0.0379\n",
      "Epoch 7: Hidden times range: [1.3470, 1.5820], std: 0.0791\n",
      "Output times: [2.554 2.527 2.49 ], separation: 0.0640\n",
      "Sample loss: L_t=0.5425, L_n=0.2839, L_sep=1.0260, Total=1.8525\n",
      "dW1 range: [-0.1036, 0.0714], std: 0.0376\n",
      "dW2 range: [-0.0786, 0.1811], std: 0.0421\n",
      "Epoch 7: Hidden times range: [1.4130, 1.6580], std: 0.0761\n",
      "Output times: [2.547 2.509 2.49 ], separation: 0.0570\n",
      "Sample loss: L_t=0.3710, L_n=0.1943, L_sep=1.0580, Total=1.6233\n",
      "dW1 range: [-0.0984, 0.0942], std: 0.0386\n",
      "dW2 range: [-0.0536, 0.1702], std: 0.0359\n",
      "Epoch 7: Hidden times range: [1.3260, 1.6800], std: 0.1012\n",
      "Output times: [2.445 2.539 2.528], separation: 0.0940\n",
      "Sample loss: L_t=0.3931, L_n=0.1777, L_sep=0.8946, Total=1.4655\n",
      "dW1 range: [-0.1201, 0.1253], std: 0.0429\n",
      "dW2 range: [-0.0620, 0.1356], std: 0.0342\n",
      "Epoch 7: Hidden times range: [1.4360, 1.6580], std: 0.0669\n",
      "Output times: [2.53  2.485 2.481], separation: 0.0490\n",
      "Sample loss: L_t=0.5726, L_n=0.2125, L_sep=1.0951, Total=1.8801\n",
      "dW1 range: [-0.1180, 0.1130], std: 0.0396\n",
      "dW2 range: [-0.0711, 0.1861], std: 0.0395\n",
      "Epoch 7: Hidden times range: [1.4720, 1.5990], std: 0.0472\n",
      "Output times: [2.515 2.489 2.49 ], separation: 0.0260\n",
      "Sample loss: L_t=0.4633, L_n=0.1747, L_sep=1.2054, Total=1.8434\n",
      "dW1 range: [-0.0886, 0.1025], std: 0.0378\n",
      "dW2 range: [-0.0515, 0.1902], std: 0.0376\n",
      "Epoch 7: Hidden times range: [1.3010, 1.6390], std: 0.1038\n",
      "Output times: [2.463 2.483 2.56 ], separation: 0.0970\n",
      "Sample loss: L_t=0.5658, L_n=0.2300, L_sep=0.8820, Total=1.6778\n",
      "dW1 range: [-0.1253, 0.0789], std: 0.0383\n",
      "dW2 range: [-0.0708, 0.1626], std: 0.0414\n",
      "Epoch 7: ||g1||=0.1068, ||g2||=0.0568, acc=0.250\n",
      "  avg loss=1.7829\n",
      "Epoch 8: Hidden times range: [1.3780, 1.6010], std: 0.0770\n",
      "Output times: [2.489 2.488 2.492], separation: 0.0040\n",
      "Sample loss: L_t=0.5458, L_n=0.1756, L_sep=1.3158, Total=2.0373\n",
      "dW1 range: [-0.0866, 0.0899], std: 0.0373\n",
      "dW2 range: [-0.0521, 0.2065], std: 0.0422\n",
      "Epoch 8: Hidden times range: [1.3450, 1.5590], std: 0.0707\n",
      "Output times: [2.518 2.414 2.491], separation: 0.1040\n",
      "Sample loss: L_t=0.8217, L_n=0.2047, L_sep=0.8528, Total=1.8793\n",
      "dW1 range: [-0.1497, 0.1252], std: 0.0460\n",
      "dW2 range: [-0.0673, 0.1951], std: 0.0427\n",
      "Epoch 8: Hidden times range: [1.3470, 1.5910], std: 0.0871\n",
      "Output times: [2.409 2.521 2.481], separation: 0.1120\n",
      "Sample loss: L_t=0.5726, L_n=0.1475, L_sep=0.8201, Total=1.5402\n",
      "dW1 range: [-0.0963, 0.0692], std: 0.0371\n",
      "dW2 range: [-0.0525, 0.1861], std: 0.0402\n",
      "Epoch 8: Hidden times range: [1.3800, 1.6570], std: 0.0787\n",
      "Output times: [2.529 2.51  2.509], separation: 0.0200\n",
      "Sample loss: L_t=0.4217, L_n=0.2140, L_sep=1.2350, Total=1.8707\n",
      "dW1 range: [-0.0941, 0.0900], std: 0.0368\n",
      "dW2 range: [-0.0568, 0.1815], std: 0.0384\n",
      "Epoch 8: Hidden times range: [1.3340, 1.5970], std: 0.0859\n",
      "Output times: [2.479 2.483 2.47 ], separation: 0.0130\n",
      "Sample loss: L_t=0.5658, L_n=0.1478, L_sep=1.2701, Total=1.9838\n",
      "dW1 range: [-0.1093, 0.1170], std: 0.0448\n",
      "dW2 range: [-0.0551, 0.1619], std: 0.0371\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 201\u001b[0m\n\u001b[0;32m    198\u001b[0m W2_0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m W1_tr, W2_tr \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_snn_backprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW1_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2_0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mλ\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal trained weights:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW1 shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, W1_tr\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[10], line 106\u001b[0m, in \u001b[0;36mtrain_snn_backprop\u001b[1;34m(X, Y, W1_init, W2_init, epochs, lr, max_grad, λ)\u001b[0m\n\u001b[0;32m    102\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xi, yi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X, Y):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     h_times \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     o_times \u001b[38;5;241m=\u001b[39m layer_forward(h_times, W2, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# Debug\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 56\u001b[0m, in \u001b[0;36mlayer_forward\u001b[1;34m(inputs, W, layer_idx)\u001b[0m\n\u001b[0;32m     53\u001b[0m G\u001b[38;5;241m.\u001b[39mv \u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39msum \u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39msr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     54\u001b[0m G\u001b[38;5;241m.\u001b[39mscheduled_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e9\u001b[39m\u001b[38;5;241m*\u001b[39msecond\n\u001b[1;32m---> 56\u001b[0m stim \u001b[38;5;241m=\u001b[39m \u001b[43mSpikeGeneratorGroup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_in_plus_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_in_plus_bias\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mtimes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maug_inputs\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m S \u001b[38;5;241m=\u001b[39m Synapses(stim, G, \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124m             w:1\u001b[39m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124m             layer:1\u001b[39m\u001b[38;5;124m'''\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124m               scheduled_time = (layer + sum/sr)*ms\u001b[39m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124m             \u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m     68\u001b[0m S\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\units\\fundamentalunits.py:2652\u001b[0m, in \u001b[0;36mcheck_units.<locals>.do_check_units.<locals>.new_f\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m   2642\u001b[0m             error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2643\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2644\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected a quantity with unit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2645\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2646\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2647\u001b[0m             )\n\u001b[0;32m   2648\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DimensionMismatchError(\n\u001b[0;32m   2649\u001b[0m                 error_message, get_dimensions(newkeyset[k])\n\u001b[0;32m   2650\u001b[0m             )\n\u001b[1;32m-> 2652\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m au:\n\u001b[0;32m   2654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(au[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m], Callable) \u001b[38;5;129;01mand\u001b[39;00m au[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   2655\u001b[0m         \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   2656\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool_,\n\u001b[0;32m   2657\u001b[0m     ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\input\\spikegeneratorgroup.py:177\u001b[0m, in \u001b[0;36mSpikeGeneratorGroup.__init__\u001b[1;34m(self, N, indices, times, dt, clock, period, when, order, sorted, name, codeobj_class)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m#: Remember the dt we used the last time when we checked the spike bins\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m#: to not repeat the work for multiple runs with the same dt\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_previous_dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m \u001b[43mCodeRunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspikegenerator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Activate name attribute access\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_group_attributes()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\groups\\group.py:1191\u001b[0m, in \u001b[0;36mCodeRunner.__init__\u001b[1;34m(self, group, template, code, user_code, dt, clock, when, order, name, check_units, template_kwds, needed_variables, override_conditional_write, codeobj_class, generate_empty_code)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   1174\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1175\u001b[0m     group,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     generate_empty_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1190\u001b[0m ):\n\u001b[1;32m-> 1191\u001b[0m     \u001b[43mBrianObject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m weakproxy_with_fallback(group)\n\u001b[0;32m   1195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate \u001b[38;5;241m=\u001b[39m template\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\units\\fundamentalunits.py:2652\u001b[0m, in \u001b[0;36mcheck_units.<locals>.do_check_units.<locals>.new_f\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m   2642\u001b[0m             error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2643\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2644\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected a quantity with unit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2645\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2646\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2647\u001b[0m             )\n\u001b[0;32m   2648\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DimensionMismatchError(\n\u001b[0;32m   2649\u001b[0m                 error_message, get_dimensions(newkeyset[k])\n\u001b[0;32m   2650\u001b[0m             )\n\u001b[1;32m-> 2652\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m au:\n\u001b[0;32m   2654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(au[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m], Callable) \u001b[38;5;129;01mand\u001b[39;00m au[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   2655\u001b[0m         \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   2656\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool_,\n\u001b[0;32m   2657\u001b[0m     ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\core\\base.py:77\u001b[0m, in \u001b[0;36mBrianObject.__init__\u001b[1;34m(self, dt, clock, when, order, namespace, name)\u001b[0m\n\u001b[0;32m     75\u001b[0m         base, _ \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(sys\u001b[38;5;241m.\u001b[39mmodules[modulename]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)\n\u001b[0;32m     76\u001b[0m         bases\u001b[38;5;241m.\u001b[39mappend(base)\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname, linenum, funcname, line \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(base \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m fname \u001b[38;5;28;01mfor\u001b[39;00m base \u001b[38;5;129;01min\u001b[39;00m bases):\n\u001b[0;32m     79\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  File \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlinenum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\traceback.py:228\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 228\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\traceback.py:390\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f, lineno \u001b[38;5;129;01min\u001b[39;00m frame_gen:\n\u001b[0;32m    388\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f, (lineno, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_from_extended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_locals\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\traceback.py:429\u001b[0m, in \u001b[0;36mStackSummary._extract_from_extended_frame_gen\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    425\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    426\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals,\n\u001b[0;32m    427\u001b[0m         end_lineno\u001b[38;5;241m=\u001b[39mend_lineno, colno\u001b[38;5;241m=\u001b[39mcolno, end_colno\u001b[38;5;241m=\u001b[39mend_colno))\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 429\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(fullname)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from brian2 import *\n",
    "import numpy as np\n",
    "import logging, warnings\n",
    "import random\n",
    "\n",
    "# Brian2 config\n",
    "prefs.codegen.target = 'cython'\n",
    "set_device('runtime')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "np.seterr(over='ignore', under='ignore')\n",
    "logging.getLogger('brian2').setLevel(logging.ERROR)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Spike timing and derivative with smoother sigmoid\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(w=1, global_clock=1, layer=1, sum=1, spikes_received=1, result=1)\n",
    "def spike_timing(w, global_clock, layer, sum, spikes_received):\n",
    "    x = (global_clock % 1)\n",
    "    z = 5.0 * (x - 0.5)  # Smoother sigmoid\n",
    "    sigmoid_val = 1.0 / (1.0 + np.exp(-w * z))\n",
    "    return sigmoid_val\n",
    "\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(w=1, global_clock=1, layer=1, sum=1, spikes_received=1, result=1)\n",
    "def d_spike_timing_dw(w, global_clock, layer, sum, spikes_received):\n",
    "    x = (global_clock % 1)\n",
    "    z = 5.0 * (x - 0.5)\n",
    "    sig = 1.0 / (1.0 + np.exp(-w * z))\n",
    "    return sig * (1.0 - sig) * z\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Forward pass\n",
    "def layer_forward(inputs, W, layer_idx):\n",
    "    bias_time = 0.0\n",
    "    aug_inputs = np.concatenate((inputs, [bias_time]))\n",
    "    n_in_plus_bias, n_out = W.shape\n",
    "    assert aug_inputs.size == n_in_plus_bias\n",
    "    out_times = []\n",
    "\n",
    "    for j in range(n_out):\n",
    "        start_scope()\n",
    "        defaultclock.dt = 0.001*ms\n",
    "\n",
    "        G = NeuronGroup(1, '''\n",
    "            v : 1\n",
    "            sum : 1\n",
    "            sr : 1\n",
    "            scheduled_time : second\n",
    "            global_clock : 1\n",
    "        ''', threshold='v>1', reset='v=0', method='exact')\n",
    "\n",
    "        G.global_clock = np.random.rand()\n",
    "        G.v = G.sum = G.sr = 0\n",
    "        G.scheduled_time = 1e9*second\n",
    "\n",
    "        stim = SpikeGeneratorGroup(n_in_plus_bias,\n",
    "                                   indices=list(range(n_in_plus_bias)),\n",
    "                                   times=aug_inputs*ms)\n",
    "\n",
    "        S = Synapses(stim, G, '''\n",
    "                     w:1\n",
    "                     layer:1''',\n",
    "                     on_pre='''\n",
    "                       sr += 1\n",
    "                       sum += spike_timing(w, global_clock, layer, sum, sr)\n",
    "                       scheduled_time = (layer + sum/sr)*ms\n",
    "                     ''')\n",
    "        S.connect(True)\n",
    "        S.w = W[:, j]\n",
    "        S.layer = layer_idx\n",
    "\n",
    "        G.run_regularly('''\n",
    "            v = int(abs(t - scheduled_time) < 0.001*ms) * 1.2\n",
    "            global_clock += 0.001\n",
    "        ''', dt=0.001*ms)\n",
    "\n",
    "        mon = SpikeMonitor(G)\n",
    "        run(5*ms)\n",
    "\n",
    "        ts = mon.spike_trains()[0]\n",
    "        if len(ts) > 0:\n",
    "            t0 = float(ts[0]/ms)\n",
    "            t0 = max(layer_idx, min(layer_idx + 1, t0))\n",
    "        else:\n",
    "            t0 = layer_idx + 0.5\n",
    "        out_times.append(t0)\n",
    "\n",
    "    return np.array(out_times)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Training loop\n",
    "def train_snn_backprop(X, Y, W1_init, W2_init, epochs=50, lr=0.5, max_grad=5.0, λ=0.5):\n",
    "    W1, W2 = W1_init.copy(), W2_init.copy()\n",
    "    beta = 0.95\n",
    "    vW1 = np.zeros_like(W1)\n",
    "    vW2 = np.zeros_like(W2)\n",
    "    N = len(X)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        acc_dW1 = np.zeros_like(W1)\n",
    "        acc_dW2 = np.zeros_like(W2)\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for xi, yi in zip(X, Y):\n",
    "            # Forward\n",
    "            h_times = layer_forward(xi, W1, 1)\n",
    "            o_times = layer_forward(h_times, W2, 2)\n",
    "\n",
    "            # Debug\n",
    "            print(f\"Epoch {ep+1}: Hidden times range: [{min(h_times):.4f}, {max(h_times):.4f}], std: {np.std(h_times):.4f}\")\n",
    "            print(f\"Output times: {o_times}, separation: {max(o_times) - min(o_times):.4f}\")\n",
    "\n",
    "            # Loss & output deltas\n",
    "            t_idx = np.argmax(yi)\n",
    "            delta_o = np.zeros_like(o_times)\n",
    "            delta_o[t_idx] = (o_times[t_idx] - yi[t_idx])\n",
    "            for j in range(len(o_times)):\n",
    "                if j != t_idx:\n",
    "                    delta_o[j] = λ * (o_times[j] - yi[j])\n",
    "\n",
    "            # Accumulate loss with separation penalty\n",
    "            L_t = 5.0 * (o_times[t_idx] - yi[t_idx])**2  # Scaled target loss\n",
    "            L_n = 5.0 * λ * np.sum(np.fromiter(((o_times[j] - yi[j])**2 for j in range(len(o_times)) if j != t_idx), dtype=float))  # Scaled non-target loss\n",
    "            separation = max(o_times) - min(o_times)\n",
    "            desired_separation = 0.517\n",
    "            L_sep = 5.0 * (desired_separation - separation)**2 if separation < desired_separation else 0.0  # Separation penalty\n",
    "            epoch_loss += (L_t + L_n + L_sep)\n",
    "\n",
    "            # Debug loss components\n",
    "            print(f\"Sample loss: L_t={L_t:.4f}, L_n={L_n:.4f}, L_sep={L_sep:.4f}, Total={L_t + L_n + L_sep:.4f}\")\n",
    "\n",
    "            # Gradients for W2\n",
    "            aug_h = np.concatenate((h_times, [0.0]))\n",
    "            dW2 = np.zeros_like(W2)\n",
    "            for k in range(W2.shape[0]):\n",
    "                for j in range(W2.shape[1]):\n",
    "                    dW2[k, j] = delta_o[j] * d_spike_timing_dw(W2[k, j], aug_h[k], 2, 0, 1)\n",
    "\n",
    "            # Backprop to hidden\n",
    "            delta_h = np.zeros(len(h_times))\n",
    "            for k in range(len(h_times)):\n",
    "                for j in range(W2.shape[1]):\n",
    "                    delta_h[k] += delta_o[j] * d_spike_timing_dw(W2[k, j], aug_h[k], 2, 0, 1)\n",
    "            if np.sum(np.abs(delta_h)) > 0:\n",
    "                delta_h /= np.sum(np.abs(delta_h))  # Normalize\n",
    "\n",
    "            # Gradients for W1\n",
    "            aug_x = np.concatenate((xi, [0.0]))\n",
    "            dW1 = np.zeros_like(W1)\n",
    "            for i in range(W1.shape[0]):\n",
    "                for k in range(W1.shape[1]):\n",
    "                    dW1[i, k] = delta_h[k] * d_spike_timing_dw(W1[i, k], aug_x[i], 1, 0, 1)\n",
    "\n",
    "            # Debug gradients\n",
    "            print(f\"dW1 range: [{np.min(dW1):.4f}, {np.max(dW1):.4f}], std: {np.std(dW1):.4f}\")\n",
    "            print(f\"dW2 range: [{np.min(dW2):.4f}, {np.max(dW2):.4f}], std: {np.std(dW2):.4f}\")\n",
    "\n",
    "            acc_dW1 += dW1\n",
    "            acc_dW2 += dW2\n",
    "\n",
    "        # Average & clip\n",
    "        acc_dW1 /= N\n",
    "        acc_dW2 /= N\n",
    "        g1 = np.clip(acc_dW1, -max_grad, max_grad)\n",
    "        g2 = np.clip(acc_dW2, -max_grad, max_grad)\n",
    "\n",
    "        # Debug: gradient norms and accuracy\n",
    "        print(f\"Epoch {ep+1}: ||g1||={np.linalg.norm(g1):.4f}, ||g2||={np.linalg.norm(g2):.4f}, acc={np.mean([np.argmax(layer_forward(layer_forward(xi, W1, 1), W2, 2)) == np.argmax(yi) for xi, yi in zip(X, Y)]):.3f}\")\n",
    "        print(f\"  avg loss={(epoch_loss/N):.4f}\")\n",
    "\n",
    "        # Momentum\n",
    "        vW1 = beta * vW1 + (1 - beta) * g1\n",
    "        vW2 = beta * vW2 + (1 - beta) * g2\n",
    "        upd1, upd2 = vW1, vW2\n",
    "\n",
    "        # Update & clamp\n",
    "        W1 -= lr * upd1\n",
    "        W2 -= lr * upd2\n",
    "        W1 = np.clip(W1, -20.0, 20.0)\n",
    "        W2 = np.clip(W2, -20.0, 20.0)\n",
    "\n",
    "    return W1, W2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(13)\n",
    "    # Example usage with fixed input/target pairs\n",
    "    x0 = np.array([0.9, 0.7, 0.3, 0.4])\n",
    "    x1 = np.array([0.6, 0.7, 0.8, 0.9])\n",
    "    X = [x0 if i % 3 == 0 else x1 if i % 3 == 1 else x0 for i in range(8)]\n",
    "    # Updated targets to match diagnostics\n",
    "    y0 = np.array([2.8194, 2.3026, 2.3026])  # Class 0\n",
    "    y1 = np.array([2.3026, 2.8194, 2.3026])  # Class 1\n",
    "    y2 = np.array([2.3026, 2.3026, 2.8194])  # Class 2\n",
    "    Y = [y0 if i % 3 == 0 else y1 if i % 3 == 1 else y2 for i in range(8)]\n",
    "\n",
    "    # Initialize weights with larger variance\n",
    "    W1_0 = np.random.randn(5, 10) * 0.5\n",
    "    W2_0 = np.random.randn(11, 3) * 0.5\n",
    "\n",
    "    # Train\n",
    "    W1_tr, W2_tr = train_snn_backprop(X, Y, W1_0, W2_0,\n",
    "                                      epochs=50, lr=0.5, max_grad=5.0, λ=0.5)\n",
    "\n",
    "    print(\"Final trained weights:\")\n",
    "    print(\"W1 shape:\", W1_tr.shape)\n",
    "    print(\"W2 shape:\", W2_tr.shape)\n",
    "\n",
    "    print(\"\\nHidden layer outputs:\")\n",
    "    print(\"Hidden times for x0:\", layer_forward(x0, W1_tr, 1))\n",
    "    print(\"Hidden times for x1:\", layer_forward(x1, W1_tr, 1))\n",
    "    print(\"Output times for x0:\", layer_forward(layer_forward(x0, W1_tr, 1), W2_tr, 2))\n",
    "\n",
    "    # Test predictions\n",
    "    print(\"\\n=== Test predictions ===\")\n",
    "    for i, (xi, yi) in enumerate(zip(X[:8], Y[:8])):\n",
    "        h_times = layer_forward(xi, W1_tr, 1)\n",
    "        o_times = layer_forward(h_times, W2_tr, 2)\n",
    "\n",
    "        pred_class = np.argmax(o_times)\n",
    "        true_class = np.argmax(yi)\n",
    "\n",
    "        print(f\"Sample {i+1} (true class {true_class}):\")\n",
    "        print(f\"  Input: {xi}\")\n",
    "        print(f\"  Output spike times: {o_times}\")\n",
    "        print(f\"  Target spike times: {yi}\")\n",
    "        print(f\"  Predicted class: {pred_class}, Correct: {pred_class == true_class}\")\n",
    "        print(f\"  Output separation: {max(o_times) - min(o_times):.4f}\\n\")\n",
    "\n",
    "    # Overall accuracy\n",
    "    print(f\"Overall accuracy: {np.sum(np.fromiter((np.argmax(layer_forward(layer_forward(xi, W1_tr, 1), W2_tr, 2)) == np.argmax(yi) for xi, yi in zip(X, Y)), dtype=int)) / len(X):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6712157e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creating Adaptive Targets ===\n",
      "Target templates:\n",
      "  Class 0: [2.8194 2.3026 2.3026]\n",
      "  Class 1: [2.3026 2.8194 2.3026]\n",
      "  Class 2: [2.3026 2.3026 2.8194]\n",
      "\n",
      "=== Initial Analysis ===\n",
      "\n",
      "=== Weight Analysis ===\n",
      "W1 stats: mean=-0.1578, std=0.6470, range=[-1.3718, 1.2966]\n",
      "W2 stats: mean=0.0633, std=0.6728, range=[-1.8338, 1.0953]\n",
      "\n",
      "=== Hidden Layer Outputs ===\n",
      "Input 1: [0.9 0.7 0.3 0.4]\n",
      "Hidden times: [1.741 1.506 1.499 1.265 1.726 1.516 1.425 1.7   1.573 1.53 ]\n",
      "Hidden range: [1.2650, 1.7410], std: 0.1391\n",
      "Output times: [2.486 2.585 2.635]\n",
      "Output range: [2.4860, 2.6350], std: 0.0619\n",
      "\n",
      "Input 2: [0.6 0.7 0.8 0.9]\n",
      "Hidden times: [1.399 1.573 1.545 1.247 1.561 1.381 1.538 1.433 1.719 1.476]\n",
      "Hidden range: [1.2470, 1.7190], std: 0.1234\n",
      "Output times: [2.491 2.389 2.48 ]\n",
      "Output range: [2.3890, 2.4910], std: 0.0457\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    C:\\Users\\irtho\\AppData\\Local\\Temp\\ipykernel_2712\\3338928934.py:45: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  loss_non_target = 0.5 * λ * sum((o_times[j] - non_target_time)**2\n",
      " [py.warnings]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: ||g1||=0.0176, ||g2||=0.0656, acc=0.125\n",
      "  avg loss=0.0211\n",
      "  Sample output: [2.516 2.49  2.538], separation: 0.0480\n",
      "Epoch 2: ||g1||=0.0123, ||g2||=0.0475, acc=0.250\n",
      "  avg loss=0.0064\n",
      "Epoch 3: ||g1||=0.0233, ||g2||=0.0657, acc=0.250\n",
      "  avg loss=0.0178\n",
      "Epoch 4: ||g1||=0.0145, ||g2||=0.0508, acc=0.625\n",
      "  avg loss=0.0101\n",
      "Epoch 5: ||g1||=0.0298, ||g2||=0.0687, acc=0.250\n",
      "  avg loss=0.0204\n",
      "Epoch 6: ||g1||=0.0172, ||g2||=0.0968, acc=0.250\n",
      "  avg loss=0.0201\n",
      "  Sample output: [2.53  2.512 2.558], separation: 0.0460\n",
      "Epoch 7: ||g1||=0.0236, ||g2||=0.0720, acc=0.625\n",
      "  avg loss=0.0144\n",
      "Epoch 8: ||g1||=0.0335, ||g2||=0.0639, acc=0.125\n",
      "  avg loss=0.0186\n",
      "Epoch 9: ||g1||=0.0190, ||g2||=0.0677, acc=0.125\n",
      "  avg loss=0.0138\n",
      "Epoch 10: ||g1||=0.0258, ||g2||=0.0613, acc=0.500\n",
      "  avg loss=0.0192\n",
      "Epoch 11: ||g1||=0.0171, ||g2||=0.0479, acc=0.375\n",
      "  avg loss=0.0117\n",
      "  Sample output: [2.426 2.514 2.476], separation: 0.0880\n",
      "Epoch 12: ||g1||=0.0199, ||g2||=0.0608, acc=0.125\n",
      "  avg loss=0.0163\n",
      "Epoch 13: ||g1||=0.0195, ||g2||=0.0442, acc=0.500\n",
      "  avg loss=0.0129\n",
      "Epoch 14: ||g1||=0.0172, ||g2||=0.0454, acc=0.500\n",
      "  avg loss=0.0130\n",
      "Epoch 15: ||g1||=0.0173, ||g2||=0.0871, acc=0.125\n",
      "  avg loss=0.0307\n",
      "Epoch 16: ||g1||=0.0250, ||g2||=0.0602, acc=0.250\n",
      "  avg loss=0.0149\n",
      "  Sample output: [2.498 2.479 2.525], separation: 0.0460\n",
      "Epoch 17: ||g1||=0.0223, ||g2||=0.0626, acc=0.375\n",
      "  avg loss=0.0206\n",
      "Epoch 18: ||g1||=0.0294, ||g2||=0.0979, acc=0.375\n",
      "  avg loss=0.0316\n",
      "Epoch 19: ||g1||=0.0377, ||g2||=0.0734, acc=0.000\n",
      "  avg loss=0.0247\n",
      "Epoch 20: ||g1||=0.0125, ||g2||=0.0390, acc=0.625\n",
      "  avg loss=0.0088\n",
      "Epoch 21: ||g1||=0.0143, ||g2||=0.0503, acc=0.375\n",
      "  avg loss=0.0126\n",
      "  Sample output: [2.525 2.518 2.526], separation: 0.0080\n",
      "Epoch 22: ||g1||=0.0191, ||g2||=0.0461, acc=0.375\n",
      "  avg loss=0.0082\n",
      "Epoch 23: ||g1||=0.0183, ||g2||=0.0488, acc=0.375\n",
      "  avg loss=0.0105\n",
      "Epoch 24: ||g1||=0.0179, ||g2||=0.0787, acc=0.250\n",
      "  avg loss=0.0235\n",
      "Epoch 25: ||g1||=0.0177, ||g2||=0.0554, acc=0.375\n",
      "  avg loss=0.0197\n",
      "Epoch 26: ||g1||=0.0175, ||g2||=0.0565, acc=0.375\n",
      "  avg loss=0.0177\n",
      "  Sample output: [2.536 2.441 2.514], separation: 0.0950\n",
      "Epoch 27: ||g1||=0.0314, ||g2||=0.0606, acc=0.250\n",
      "  avg loss=0.0198\n",
      "Epoch 28: ||g1||=0.0145, ||g2||=0.0424, acc=0.250\n",
      "  avg loss=0.0168\n",
      "Epoch 29: ||g1||=0.0148, ||g2||=0.0412, acc=0.375\n",
      "  avg loss=0.0109\n",
      "Epoch 30: ||g1||=0.0209, ||g2||=0.0523, acc=0.125\n",
      "  avg loss=0.0132\n",
      "\n",
      "=== Final Analysis ===\n",
      "\n",
      "=== Weight Analysis ===\n",
      "W1 stats: mean=-0.1577, std=0.6473, range=[-1.3714, 1.2969]\n",
      "W2 stats: mean=0.0650, std=0.6756, range=[-1.8296, 1.0967]\n",
      "\n",
      "=== Hidden Layer Outputs ===\n",
      "Input 1: [0.9 0.7 0.3 0.4]\n",
      "Hidden times: [1.311 1.607 1.551 1.626 1.724 1.465 1.36  1.729 1.537 1.426]\n",
      "Hidden range: [1.3110, 1.7290], std: 0.1359\n",
      "Output times: [2.461 2.559 2.408]\n",
      "Output range: [2.4080, 2.5590], std: 0.0626\n",
      "\n",
      "Input 2: [0.6 0.7 0.8 0.9]\n",
      "Hidden times: [1.426 1.516 1.434 1.449 1.611 1.308 1.426 1.423 1.551 1.432]\n",
      "Hidden range: [1.3080, 1.6110], std: 0.0791\n",
      "Output times: [2.512 2.448 2.497]\n",
      "Output range: [2.4480, 2.5120], std: 0.0273\n",
      "\n",
      "\n",
      "=== Test Predictions ===\n",
      "Sample 1 (true class 2):\n",
      "  Input: [0.9 0.7 0.3 0.4]\n",
      "  Output spike times: [2.553 2.505 2.469]\n",
      "  Target spike times: [2.3026 2.3026 2.8194]\n",
      "  Predicted class: 0, Correct: False\n",
      "  Output separation: 0.0840\n",
      "\n",
      "Sample 2 (true class 0):\n",
      "  Input: [0.6 0.7 0.8 0.9]\n",
      "  Output spike times: [2.272 2.498 2.525]\n",
      "  Target spike times: [2.8194 2.3026 2.3026]\n",
      "  Predicted class: 2, Correct: False\n",
      "  Output separation: 0.2530\n",
      "\n",
      "Sample 3 (true class 2):\n",
      "  Input: [0.9 0.7 0.3 0.4]\n",
      "  Output spike times: [2.535 2.601 2.542]\n",
      "  Target spike times: [2.3026 2.3026 2.8194]\n",
      "  Predicted class: 1, Correct: False\n",
      "  Output separation: 0.0660\n",
      "\n",
      "Sample 4 (true class 0):\n",
      "  Input: [0.6 0.7 0.8 0.9]\n",
      "  Output spike times: [2.507 2.52  2.418]\n",
      "  Target spike times: [2.8194 2.3026 2.3026]\n",
      "  Predicted class: 1, Correct: False\n",
      "  Output separation: 0.1020\n",
      "\n",
      "Sample 5 (true class 2):\n",
      "  Input: [0.9 0.7 0.3 0.4]\n",
      "  Output spike times: [2.516 2.433 2.501]\n",
      "  Target spike times: [2.3026 2.3026 2.8194]\n",
      "  Predicted class: 0, Correct: False\n",
      "  Output separation: 0.0830\n",
      "\n",
      "Sample 6 (true class 0):\n",
      "  Input: [0.6 0.7 0.8 0.9]\n",
      "  Output spike times: [2.372 2.535 2.499]\n",
      "  Target spike times: [2.8194 2.3026 2.3026]\n",
      "  Predicted class: 1, Correct: False\n",
      "  Output separation: 0.1630\n",
      "\n",
      "Sample 7 (true class 2):\n",
      "  Input: [0.9 0.7 0.3 0.4]\n",
      "  Output spike times: [2.441 2.479 2.475]\n",
      "  Target spike times: [2.3026 2.3026 2.8194]\n",
      "  Predicted class: 1, Correct: False\n",
      "  Output separation: 0.0380\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    C:\\Users\\irtho\\AppData\\Local\\Temp\\ipykernel_2712\\3338928934.py:214: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  print(f\"Overall accuracy: {sum(np.argmax(layer_forward(layer_forward(xi, W1_tr, 1), W2_tr, 2)) == np.argmax(yi) for xi, yi in zip(X, Y)) / len(X):.3f}\")\n",
      " [py.warnings]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 8 (true class 0):\n",
      "  Input: [0.6 0.7 0.8 0.9]\n",
      "  Output spike times: [2.557 2.628 2.441]\n",
      "  Target spike times: [2.8194 2.3026 2.3026]\n",
      "  Predicted class: 1, Correct: False\n",
      "  Output separation: 0.1870\n",
      "\n",
      "Overall accuracy: 0.500\n"
     ]
    }
   ],
   "source": [
    "# Improved training function with better loss function and target alignment\n",
    "def train_snn_backprop_improved(\n",
    "    X, Y,\n",
    "    W1_init, W2_init,\n",
    "    epochs=30, lr=0.2,\n",
    "    max_grad=20.0, w_min=-20.0, w_max=20.0,\n",
    "    λ=0.5, separation_margin=0.1\n",
    "):\n",
    "    W1, W2 = W1_init.copy(), W2_init.copy()\n",
    "    beta = 0.9\n",
    "    vW1 = np.zeros_like(W1)\n",
    "    vW2 = np.zeros_like(W2)\n",
    "    N = len(X)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        acc_dW1 = np.zeros_like(W1)\n",
    "        acc_dW2 = np.zeros_like(W2)\n",
    "        epoch_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "\n",
    "        for xi, yi in zip(X, Y):\n",
    "            # Forward\n",
    "            h_times = layer_forward(xi, W1, 1)\n",
    "            o_times = layer_forward(h_times, W2, 2)\n",
    "\n",
    "            # Find target and predicted classes\n",
    "            t_idx = np.argmax(yi)\n",
    "            p_idx = np.argmax(o_times)\n",
    "            \n",
    "            # Improved loss function: encourage separation\n",
    "            delta_o = np.zeros_like(o_times)\n",
    "            \n",
    "            # For the target class: encourage it to have the latest spike time\n",
    "            target_time = np.max(o_times) + separation_margin\n",
    "            delta_o[t_idx] = (o_times[t_idx] - target_time)\n",
    "            \n",
    "            # For non-target classes: encourage them to have earlier spike times\n",
    "            non_target_time = np.min(o_times) - separation_margin\n",
    "            for j in range(len(o_times)):\n",
    "                if j != t_idx:\n",
    "                    delta_o[j] = λ * (o_times[j] - non_target_time)\n",
    "\n",
    "            # Compute loss\n",
    "            loss_target = 0.5 * (o_times[t_idx] - target_time)**2\n",
    "            loss_non_target = 0.5 * λ * sum((o_times[j] - non_target_time)**2 \n",
    "                                          for j in range(len(o_times)) if j != t_idx)\n",
    "            epoch_loss += (loss_target + loss_non_target)\n",
    "            \n",
    "            # Track accuracy\n",
    "            if p_idx == t_idx:\n",
    "                correct_predictions += 1\n",
    "\n",
    "            # Gradients for W2 (output layer)\n",
    "            aug_h = np.concatenate((h_times, [0.0]))  # Add bias\n",
    "            dW2 = np.zeros_like(W2)\n",
    "            \n",
    "            # Store derivatives for backprop\n",
    "            dspike_dw_hidden = np.zeros((len(aug_h), len(o_times)))\n",
    "            \n",
    "            for k in range(W2.shape[0]):  # For each hidden unit (+ bias)\n",
    "                for j in range(W2.shape[1]):  # For each output unit\n",
    "                    # Compute derivative of spike timing w.r.t. weight\n",
    "                    deriv = d_spike_timing_dw(W2[k, j], aug_h[k], 2, 0, 1)\n",
    "                    dW2[k, j] = delta_o[j] * deriv\n",
    "                    # Store for backprop\n",
    "                    dspike_dw_hidden[k, j] = deriv\n",
    "\n",
    "            # Backprop to hidden layer\n",
    "            delta_h = np.zeros_like(h_times)\n",
    "            for k in range(len(h_times)):  # For each hidden unit\n",
    "                delta_h[k] = 0.0\n",
    "                for j in range(W2.shape[1]):  # Sum over all output units\n",
    "                    # Gradient flows back through the weight W2[k,j]\n",
    "                    delta_h[k] += delta_o[j] * W2[k, j] * dspike_dw_hidden[k, j]\n",
    "\n",
    "            # Gradients for W1 (hidden layer)\n",
    "            aug_x = np.concatenate((xi, [0.0]))  # Add bias\n",
    "            dW1 = np.zeros_like(W1)\n",
    "            for i in range(W1.shape[0]):  # For each input (+ bias)\n",
    "                for k in range(W1.shape[1]):  # For each hidden unit\n",
    "                    dW1[i, k] = delta_h[k] * d_spike_timing_dw(\n",
    "                        W1[i, k], aug_x[i], 1, 0, 1)\n",
    "\n",
    "            acc_dW1 += dW1\n",
    "            acc_dW2 += dW2\n",
    "\n",
    "        # Average & clip\n",
    "        acc_dW1 /= N\n",
    "        acc_dW2 /= N\n",
    "        g1 = np.clip(acc_dW1, -max_grad, max_grad)\n",
    "        g2 = np.clip(acc_dW2, -max_grad, max_grad)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = correct_predictions / N\n",
    "        \n",
    "        # Debug: gradient norms\n",
    "        print(f\"Epoch {ep+1}: ||g1||={np.linalg.norm(g1):.4f}, ||g2||={np.linalg.norm(g2):.4f}, acc={accuracy:.3f}\")\n",
    "\n",
    "        # Momentum (skip first 5 iters)\n",
    "        if ep >= 5:\n",
    "            vW1 = beta*vW1 + (1-beta)*g1\n",
    "            vW2 = beta*vW2 + (1-beta)*g2\n",
    "            upd1, upd2 = vW1, vW2\n",
    "        else:\n",
    "            upd1, upd2 = g1, g2\n",
    "\n",
    "        # Update & clamp\n",
    "        W1 -= lr * upd1\n",
    "        W2 -= lr * upd2\n",
    "        W1 = np.clip(W1, w_min, w_max)\n",
    "        W2 = np.clip(W2, w_min, w_max)\n",
    "\n",
    "        print(f\"  avg loss={(epoch_loss/N):.4f}\")\n",
    "        \n",
    "        # Print sample outputs to monitor progress\n",
    "        if ep % 5 == 0:\n",
    "            h_sample = layer_forward(X[0], W1, 1)\n",
    "            o_sample = layer_forward(h_sample, W2, 2)\n",
    "            print(f\"  Sample output: {o_sample}, separation: {np.max(o_sample) - np.min(o_sample):.4f}\")\n",
    "\n",
    "    return W1, W2\n",
    "\n",
    "# Function to create better targets based on actual output ranges\n",
    "def create_adaptive_targets(X, W1, W2, num_classes=3):\n",
    "    \"\"\"Create targets that are achievable given the current network outputs\"\"\"\n",
    "    \n",
    "    # Get typical output range\n",
    "    all_outputs = []\n",
    "    for xi in X:\n",
    "        h_times = layer_forward(xi, W1, 1)\n",
    "        o_times = layer_forward(h_times, W2, 2)\n",
    "        all_outputs.append(o_times)\n",
    "    \n",
    "    all_outputs = np.array(all_outputs)\n",
    "    min_out = np.min(all_outputs)\n",
    "    max_out = np.max(all_outputs)\n",
    "    range_out = max_out - min_out\n",
    "    \n",
    "    # Create targets with good separation\n",
    "    target_range = max(range_out * 1.5, 0.2)  # At least 0.2ms separation\n",
    "    \n",
    "    # For 3 classes: early, middle, late\n",
    "    if num_classes == 3:\n",
    "        early_time = min_out - target_range * 0.3\n",
    "        middle_time = (min_out + max_out) / 2\n",
    "        late_time = max_out + target_range * 0.3\n",
    "        \n",
    "        targets = {\n",
    "            0: np.array([late_time, early_time, early_time]),    # Class 0: first output latest\n",
    "            1: np.array([early_time, late_time, early_time]),    # Class 1: second output latest  \n",
    "            2: np.array([early_time, early_time, late_time])     # Class 2: third output latest\n",
    "        }\n",
    "    \n",
    "    return targets\n",
    "\n",
    "# Enhanced main function with adaptive targets\n",
    "def main_improved():\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Your data\n",
    "    x0 = np.array([0.9, 0.7, 0.3, 0.4])\n",
    "    x1 = np.array([0.6, 0.7, 0.8, 0.9])\n",
    "    X = [x0 if i % 2 == 0 else x1 for i in range(8)]\n",
    "    \n",
    "    # Class labels (0 or 2)\n",
    "    class_labels = [2 if i % 2 == 0 else 0 for i in range(8)]\n",
    "    \n",
    "    # Better weight initialization\n",
    "    W1_0 = np.random.randn(5, 10) * 0.5  # Slightly larger initialization\n",
    "    W2_0 = np.random.randn(11, 3) * 0.5\n",
    "\n",
    "    print(\"=== Creating Adaptive Targets ===\")\n",
    "    target_templates = create_adaptive_targets(X, W1_0, W2_0)\n",
    "    print(\"Target templates:\")\n",
    "    for class_idx, target in target_templates.items():\n",
    "        print(f\"  Class {class_idx}: {target}\")\n",
    "    \n",
    "    # Create Y based on class labels\n",
    "    Y = [target_templates[class_labels[i]] for i in range(len(X))]\n",
    "    \n",
    "    print(\"\\n=== Initial Analysis ===\")\n",
    "    analyze_weights_and_outputs(X, Y, W1_0, W2_0)\n",
    "\n",
    "    # Train with improved loss function\n",
    "    W1_tr, W2_tr = train_snn_backprop_improved(\n",
    "        X, Y, W1_0, W2_0,\n",
    "        epochs=30, lr=0.25, max_grad=15.0, \n",
    "        separation_margin=0.05\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== Final Analysis ===\")\n",
    "    analyze_weights_and_outputs(X, Y, W1_tr, W2_tr)\n",
    "    \n",
    "    # Test predictions\n",
    "    print(\"\\n=== Test Predictions ===\")\n",
    "    all_correct = True\n",
    "    for i, (xi, yi) in enumerate(zip(X, Y)):\n",
    "        h_times = layer_forward(xi, W1_tr, 1)\n",
    "        o_times = layer_forward(h_times, W2_tr, 2)\n",
    "\n",
    "        pred_class = np.argmax(o_times)\n",
    "        true_class = np.argmax(yi)\n",
    "        is_correct = pred_class == true_class\n",
    "        all_correct &= is_correct\n",
    "\n",
    "        print(f\"Sample {i+1} (true class {true_class}):\")\n",
    "        print(f\"  Input: {xi}\")\n",
    "        print(f\"  Output spike times: {o_times}\")\n",
    "        print(f\"  Target spike times: {yi}\")\n",
    "        print(f\"  Predicted class: {pred_class}, Correct: {is_correct}\")\n",
    "        print(f\"  Output separation: {np.max(o_times) - np.min(o_times):.4f}\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"Overall accuracy: {np.sum(np.fromiter((np.argmax(layer_forward(layer_forward(xi, W1_tr, 1), W2_tr, 2)) == np.argmax(yi) for xi, yi in zip(X, Y)), dtype=int)) / len(X):.3f}\")\n",
    "\n",
    "\n",
    "    return W1_tr, W2_tr\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    W1_final, W2_final = main_improved()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c46f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74644b94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15302c14",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac396af2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8122b1ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec7c7042",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
