{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f373296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron Input Layer neuron 0 firing at :0.5\n",
      "Neuron at layer 1: 0\n",
      "Neuron at output layer: 0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "input_layer = 1\n",
    "hidden_layer = 1\n",
    "output_layer = 1 \n",
    "m = 5\n",
    "c = 3\n",
    "inputs = [0.5] * input_layer\n",
    "run_time = 10 \n",
    "l1a = [1.0] * input_layer\n",
    "l1b = [0.0] * input_layer\n",
    "\n",
    "l2a = [1.0] * hidden_layer\n",
    "l2b = [0.0] * hidden_layer\n",
    "\n",
    "l3a = [1.0] * output_layer\n",
    "l3b = [0.0] * output_layer\n",
    "\n",
    "def create_new_neurons_network():\n",
    "    count = 0\n",
    "    neurons_input = []\n",
    "    for i, val in enumerate(inputs):\n",
    "        n = Neuron(layer=0, number=i)  # will add later to add a and b and such\n",
    "        n.set_firetime(val)\n",
    "        neurons_input.append(n)\n",
    "        print('Neuron Input Layer neuron ' + str(neurons_input[i].number) + ' firing at :' + str(neurons_input[i].firetime))\n",
    "\n",
    "    count = 0\n",
    "    neurons_hidden = []\n",
    "    for i in range (hidden_layer):\n",
    "        n = Neuron(layer=1, number=i)\n",
    "        neurons_hidden.append(n)\n",
    "        print(\"Neuron at layer 1: \" + str(neurons_hidden[i].number))\n",
    "\n",
    "    count = 0\n",
    "    neurons_output = []\n",
    "    for i in range (hidden_layer):\n",
    "        n = Neuron(layer=2, number=i)\n",
    "        neurons_output.append(n)\n",
    "        print(\"Neuron at output layer: \" + str(neurons_output[i].number))\n",
    "\n",
    "def run_simulation(inputs, runtime, dx):\n",
    "    # create the assocated neurons for each layer with proper details\n",
    "    create_new_neurons_network() # creates all the neurons right now 1-1-1 network\n",
    "\n",
    "\n",
    "    for i in run_time * dx: # loops though as each time step of a simulation   \n",
    "\n",
    "        #check all neurons if firing time has been reached\n",
    "            # if firing time has been reached: \n",
    "\n",
    "        pass\n",
    "\n",
    "    #     pass\n",
    "\n",
    "    return \"---\"\n",
    "    \n",
    "\n",
    "print(run_simulation(inputs, 10, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "34adcf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron: \n",
    "    def __init__(self, layer, number, a=1, b=0, c=3):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        self.threshold = 10 # will be threshold and will be used to count inputs pretty mcuh. will turn into function later\n",
    "        self.layer = layer\n",
    "        self.number = number\n",
    "        self.fired = False\n",
    "        self.spikes = 0\n",
    "        self.firetime = 10\n",
    "\n",
    "    def set_firetime(self, time):\n",
    "        self.firetime = time\n",
    "\n",
    "    def check(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d3ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math Section for Skuld model v2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "a = 1 # the main part of what i will be changing for weights changes the size of the sigmoid without changing near zero\n",
    "b = 0  # bias will add to updating with ^ later\n",
    "m = 5 # the rate of change of the sigmoid \n",
    "c = 3 # a constant I used, same as but but shift the sigmod to a place where i 0 is close to 0 (actuyll 0.04 but whatever)\n",
    "layer_bias = 0.5\n",
    "\n",
    "\n",
    "def ians_sigmoid(x, a, b, m, c, layer=0):\n",
    "    return 1/ ((1/a) + np.exp(((-x*m) + b + c + layer * layer_bias)))\n",
    "#print(ians_sigmoid(0.8, a, b, m, c))\n",
    "\n",
    "def calc_loss(output, desired):\n",
    "    # can change but not a requirement yet\n",
    "    return (0.5 * ((output - desired) ** 2))\n",
    "\n",
    "\n",
    "def d_loss_d_weight_2(n1, n2, desired):\n",
    "    # check the removal of the layer bias fo rthis one and go back to check the others as well\n",
    "    return ((n2 - desired) * (n2) * (1-(n2)) * n1) # removedall layer_bias can check layer if correct call\n",
    "\n",
    "def d_loss_d_weight_1(n1, n2, desired, w2, input):\n",
    "    # check the removal of the layer bias fo rthis one and go back to check the others as well\n",
    "    return ((n2 - desired) * (n2) * (1-(n2)) * n1 * w2 * (1- n1) * input)\n",
    "\n",
    "\n",
    "def d_loss_d_bias_2(n2, desired):\n",
    "    return (n2 - desired) * (n2 - layer_bias) * (1 - (n2 - layer_bias))\n",
    "\n",
    "def d_loss_d_bias_1(n1, n2, delta2, desired, a2):\n",
    "    #delta2 = (n2 - desired) * (n2 - layer_bias) * (1 - (n2 - layer_bias))\n",
    "    return delta2 * a2 * (n1 - layer_bias) * (1 - (n1 - layer_bias))\n",
    "\n",
    "\n",
    "def update_param(lr, grad, w):\n",
    "    w -= lr * grad\n",
    "    return w\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def forward_pass(input, a1, a2, b1, b2):\n",
    "    sig_r1 = ians_sigmoid(input, a1, b1, m, c)\n",
    "    delay_1 = sig_r1 + input\n",
    "    sig_r2 = ians_sigmoid(delay_1, a2, b2, m, c, layer=1)\n",
    "    delay_2 = sig_r2 + delay_1\n",
    "\n",
    "    return ([delay_1, delay_2], [sig_r1, sig_r2])\n",
    "\n",
    "\n",
    "def run_basic(input, a1, a2, b1, b2, desired, lr):   # will need to check work on bias/b and make sure everything is correct in this\n",
    "\n",
    "    result = forward_pass(input, a1, a2, b1, b2)\n",
    "    output = result[0][1]\n",
    "    n1 = result[0][0]\n",
    "    n2 = result[0][1]\n",
    "\n",
    "    #loss = calc_loss(output, desired)\n",
    "\n",
    "    delta_a2 = - d_loss_d_weight_2(n1, n2, desired)\n",
    "\n",
    "    delta_a1 = - d_loss_d_weight_1(n1, n2, desired, a2, input) # trying to just input a as a the weight directly\n",
    "\n",
    "    new_a1 = update_param(lr, delta_a1, a1)\n",
    "    new_a2 = update_param(lr, delta_a2, a2)\n",
    "\n",
    "\n",
    "    delta_b2 = - d_loss_d_bias_2(n2, desired)\n",
    "    delta_b1 = - d_loss_d_bias_1(n1, n2, delta_b2, desired, b2) # trying to just input a as a the weight directly\n",
    "\n",
    "\n",
    "    new_b1 = update_param(lr, delta_b1, b1)\n",
    "    new_b2 = update_param(lr, delta_b2, b2)\n",
    "\n",
    "    return new_a1, new_a2, new_b1, new_b2, result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7860c0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 and a2:  0.436536882181106 2.2752835659918036\n",
      "1.691\n",
      "a1 and a2:  0.4052599108097197 2.163596489302757\n",
      "1.615\n",
      "a1 and a2:  0.38862941829910197 2.103789094709322\n",
      "1.569\n",
      "a1 and a2:  0.37918364455493797 2.0696598046602377\n",
      "1.543\n",
      "a1 and a2:  0.37358046499156766 2.049353852917697\n",
      "1.527\n",
      "a1 and a2:  0.37016458164606647 2.0369512221193515\n",
      "1.517\n",
      "a1 and a2:  0.36804614816893894 2.0292502376179065\n",
      "1.511\n",
      "a1 and a2:  0.3667181059852291 2.0244188287959313\n",
      "1.507\n",
      "a1 and a2:  0.3658798610867362 2.0213678229054217\n",
      "1.504\n",
      "a1 and a2:  0.3653484765691714 2.0194331171881283\n",
      "1.503\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "input = 0.5\n",
    "lr = 1.3\n",
    "a1 = 0.5\n",
    "a2 = 2.5\n",
    "b1 = 0\n",
    "b2 = 0\n",
    "desired = 1.5\n",
    "# weird thing with moving the lr too much need to keep low nery steep start with changing lower m maybe?\n",
    "for i in range(10):\n",
    "    a1, a2, b1, b2, r = run_basic(input, a1, a2, b1, b2, desired, lr)\n",
    "    print(\"a1 and a2: \", a1, a2)\n",
    "    #print(\"b1 and b2: \", b1, b2)\n",
    "    print(np.round(r[0][1], 3))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2449905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brian Simulation: \n",
    "from brian2 import *\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "from brian2 import prefs, set_device\n",
    "# Tell Brian2 to use the Cython code generator:\n",
    "prefs.codegen.target = 'cython'\n",
    "\n",
    "# Optionally compile but keep Python interface:\n",
    "set_device('runtime')  # default; compiles operations to .so but stays in Python process\n",
    "\n",
    "# suppress overflow warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "numpy.seterr(over='ignore', under='ignore')\n",
    "logging.getLogger('brian2').setLevel(logging.ERROR)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Spike timing and derivative\n",
    "\n",
    "start_scope()\n",
    "defaultclock.dt = 0.001*ms\n",
    "\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(id=1, time=1, layer=1, result=1)\n",
    "def calc_spike_delay(id, time):\n",
    "    # get specific neuron synapics id to get specific a b and voltages values\n",
    "    x = (time % 1)\n",
    "    z = 10 * (x - 0.5)  # worked at 30 for some reason \n",
    "    sigmoid_val = 1.0 / (1.0 + np.exp(-w * z))\n",
    "    return sigmoid_val\n",
    "\n",
    "\n",
    "\n",
    "# @implementation('numpy', discard_units=True)\n",
    "# @check_units(w=1, global_clock=1, layer=1, sum=1, spikes_received=1, result=1)\n",
    "# def d_spike_timing_dw(w, time):\n",
    "#     x = (time % 1)\n",
    "#     z = 5.0 * (x - 0.5)\n",
    "#     sig = 1.0 / (1.0 + np.exp(-w * z))\n",
    "#     return sig * (1.0 - sig) * z\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Forward pass: 4->10->3 using two-stage mini_urd\n",
    "\n",
    "\n",
    "def mini1x1x1(inputs, w1, w2):\n",
    "    \"\"\"\n",
    "    Mini 1x1x1 network with a single input, hidden, and output neuron.\n",
    "    This is a minimal example to demonstrate the basic structure of a spiking neural network.\n",
    "    \"\"\"\n",
    "    # Define network sizes\n",
    "    n_input = 1\n",
    "    n_hidden = 1\n",
    "    n_output = 1\n",
    "    n_total = n_input + n_hidden + n_output\n",
    "\n",
    "    # Full neuron group\n",
    "    neurons = NeuronGroup(n_total, '''\n",
    "        v : 1\n",
    "        sum : 1\n",
    "        spikes_received : 1\n",
    "        scheduled_time : second\n",
    "        global_clock : 1\n",
    "        spiked : boolean\n",
    "    ''', threshold='v > 1', reset='''\n",
    "    v = 0\n",
    "    spiked = True\n",
    "    ''', method='exact')\n",
    "\n",
    "    neurons.v = 0\n",
    "    neurons.scheduled_time = 1e9 * second\n",
    "    neurons.global_clock = 0.0\n",
    "    neurons.sum = 0.0\n",
    "    neurons.spikes_received = 0.0\n",
    "\n",
    "    # Spike inputs (one per input neuron)     \n",
    "    stim = SpikeGeneratorGroup(n_input, indices=range(n_input), times=(inputs) * ms)\n",
    "\n",
    "    # Input → Hidden connections\n",
    "    syn_input = Synapses(stim, neurons[0:n_input], '''\n",
    "        layer : 1\n",
    "    ''', on_pre='''\n",
    "        spikes_received += 1\n",
    "        sum += t/ms\n",
    "        scheduled_time = ((sum/spikes_received) + layer) * ms \n",
    "    ''')\n",
    "    syn_input.connect(j='i')  # connect stim[i] to neurons[i]\n",
    "    syn_input.layer = 0\n",
    "    #syn_input.w = -42  # just to skip and return t in function\n",
    "    \n",
    "\n",
    "    # Hidden layer: input → hidden\n",
    "    syn_hidden = Synapses(neurons[0:n_input], neurons[n_input:n_input + n_hidden], '''\n",
    "        w : 1\n",
    "        layer : 1\n",
    "    ''', on_pre='''\n",
    "        spikes_received += 1\n",
    "        sum += spike_timing(w, global_clock)\n",
    "        scheduled_time = ((sum/spikes_received) + layer + 0.004) * ms \n",
    "    ''')\n",
    "    syn_hidden.connect()\n",
    "    syn_hidden.w = w1 \n",
    "    syn_hidden.layer = 1\n",
    "\n",
    "    # Output layer: hidden → output\n",
    "    syn_output = Synapses(neurons[n_input:n_input + n_hidden], neurons[n_input + n_hidden:n_total], '''\n",
    "        w : 1\n",
    "        layer : 1\n",
    "    ''', on_pre='''\n",
    "        spikes_received += 1\n",
    "        sum += spike_timing(w, global_clock)\n",
    "        scheduled_time = shifter((sum/spikes_received) + layer + 0.004) * ms\n",
    "        \n",
    "    \n",
    "    ''')\n",
    "    syn_output.connect()\n",
    "    syn_output.w = w2 \n",
    "    syn_output.layer = 2\n",
    "\n",
    "    neurons.run_regularly('''\n",
    "        v = (1.0 - spiked) * int(abs(t - scheduled_time) < 0.005*ms) * 1.2\n",
    "        global_clock += 0.001\n",
    "        \n",
    "    ''', dt=0.001*ms)\n",
    "\n",
    "        #v = int(abs(t - scheduled_time) < 0.005*ms) * 1.2\n",
    "\n",
    "    # Monitors\n",
    "    mon = StateMonitor(neurons, 'v', record=True, dt=0.01*ms)\n",
    "    mon_sum = StateMonitor(neurons, 'sum', record=True)\n",
    "    sp_mon = StateMonitor(neurons, 'spikes_received', record=True)\n",
    "    sch_time = StateMonitor(neurons, 'scheduled_time', record=True)\n",
    "\n",
    "\n",
    "    spikemon = SpikeMonitor(neurons)\n",
    "\n",
    "\n",
    "    run(5*ms)\n",
    "\n",
    "    # # Plot voltages\n",
    "    # figure(figsize=(10, 6))\n",
    "    # for i in range(n_total):  # All neurons\n",
    "    #     plot(mon.t/ms, mon.v[i], label=f'Neuron {i}')\n",
    "    # xlabel('Time (ms)')\n",
    "    # ylabel('Membrane potential')\n",
    "    # legend()\n",
    "    # title('SNN Spike Propagation Across All Layers')\n",
    "    # show()\n",
    "\n",
    "    # plot(mon_sum.t/ms, mon_sum.sum[3])  # or any neuron index\n",
    "    # print(mon_sum.sum[1])\n",
    "    # print(sp_mon.spikes_received[1])\n",
    "    # print(sch_time.scheduled_time[1])\n",
    "\n",
    "    for i in range(n_total):\n",
    "        times = spikemon.spike_trains()[i]\n",
    "        if len(times) > 0:\n",
    "            formatted_times = [f\"{t/ms:.3f} ms\" for t in times]\n",
    "            print(f\"Neuron {i} spike times: {formatted_times}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed228c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
