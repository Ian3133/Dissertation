{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4f373296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and global vars\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "input_layer = 3\n",
    "hidden_layer = 10\n",
    "output_layer = 3\n",
    "m = 0.5 \n",
    "c = 1   # play with values and such\n",
    "\n",
    "run_time = 6\n",
    "\n",
    "neurons_input = []\n",
    "neurons_hidden = []\n",
    "neurons_output = []\n",
    "\n",
    "syn_layer_1 = []\n",
    "syn_layer_2 = []\n",
    "syn_outputs = []\n",
    "\n",
    "current_time = 0\n",
    "time_step = 1\n",
    "inputs = [1.4, 0.8, 0.9, 1.0] # need to match input #\n",
    "\n",
    "a = 1 # the main part of what i will be changing for weights changes the size of the sigmoid without changing near zero\n",
    "b = 0  # bias will add to updating with ^ later\n",
    "m = 0.5 # the rate of change of the sigmoid \n",
    "c = 2 # a constant I used, same as but but shift the sigmod to a place where i 0 is close to 0 (actuyll 0.04 but whatever)\n",
    "layer_bias = -1 #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "99d3ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skuld Function Back Box\n",
    "\n",
    "def ians_sigmoid(x, a_a, b_b, m_m, c_c, layer=0):\n",
    "    return (1/ ((1/a_a) + np.exp(((-x*m_m) + b_b + c_c + layer * layer_bias))))* a_a\n",
    "\n",
    "def calc_loss(output, desired):\n",
    "    return (0.5 * ((output - desired) ** 2))\n",
    "\n",
    "def d_loss_d_weight_2(n1, n2, desired):\n",
    "    # check the removal of the layer bias fo rthis one and go back to check the others as well\n",
    "    return ((n2 - desired) * (n2) * (1-(n2)) * n1) # removedall layer_bias can check layer if correct call\n",
    "\n",
    "def d_loss_d_weight_1(n1, n2, desired, w2, input):\n",
    "    # check the removal of the layer bias fo rthis one and go back to check the others as well\n",
    "    return ((n2 - desired) * (n2) * (1-(n2)) * n1 * w2 * (1- n1) * input)\n",
    "\n",
    "def d_loss_d_bias_2(n2, desired):\n",
    "    return (n2 - desired) * (n2 - layer_bias) * (1 - (n2 - layer_bias))\n",
    "\n",
    "def d_loss_d_bias_1(n1, n2, delta2, desired, a2):\n",
    "    return delta2 * a2 * (n1 - layer_bias) * (1 - (n1 - layer_bias))\n",
    "\n",
    "def update_param(lr, grad, w):\n",
    "    w -= lr * grad\n",
    "    return w\n",
    "\n",
    "class Neuron: \n",
    "    def __init__(self, layer, number):\n",
    "\n",
    "        self.layer = layer\n",
    "        self.number = number\n",
    "    \n",
    "\n",
    "        self.current_layer = 0\n",
    "        self.next_layer = 0\n",
    "        self.past_layer = 1\n",
    "        self.input_syn = 0\n",
    "        self.output_syn = 0\n",
    "        \n",
    "        \n",
    "        self.spikes = 0\n",
    "        #self.firetime = -1\n",
    "        self.fired = False\n",
    "\n",
    "        self.set_outputs(layer)\n",
    "\n",
    "        if self.layer == 0:\n",
    "            self.threshold = 1.0\n",
    "        else: \n",
    "            self.threshold = 1.0  #2/3 * (self.past_layer)   #+ (self.current_layer + 1) # previous layer # of n /2 seem like a good fit  # will change to fun that reflect # of inputs and layer -- number of inputs\n",
    "        self.voltage = 0\n",
    "\n",
    "        #self.collected = 0\n",
    "        self.scheduled_spike = -10 # change to just runtime or somthng else\n",
    "        self.spike_time = 10.0\n",
    "        \n",
    "\n",
    "    def set_outputs(self, layer):\n",
    "        '''Called with the creation of neuron create all the correct assocations for later here'''\n",
    "        global input_layer, output_layer, syn_layer_1, syn_layer_2, hidden_layer, syn_outputs, past_layer\n",
    "        if layer == 0:\n",
    "            self.next_layer = hidden_layer\n",
    "            #self.input_syn = 0 # remains nothing\n",
    "            self.output_syn = syn_layer_1\n",
    "        elif layer == 1:\n",
    "            self.current_layer = hidden_layer\n",
    "            self.next_layer = output_layer\n",
    "            self.past_layer = input_layer\n",
    "            self.input_syn = syn_layer_1\n",
    "            self.output_syn = syn_layer_2\n",
    "        elif layer == 2:\n",
    "            self.current_layer = output_layer\n",
    "            self.next_layer = output_layer # same amount of outputs\n",
    "            self.past_layer = hidden_layer\n",
    "            self.input_syn = syn_layer_2\n",
    "            self.output_syn = syn_outputs\n",
    "  \n",
    "\n",
    "    def send_to_syn(self, time, delay):\n",
    "        '''Sends out the times to the synapses of when they should arive at their next neuron'''\n",
    "        global l1_a, l2_a, l1_b, l2_b, m, c\n",
    "        self.fired = True\n",
    "        #print(self.layer, self.number, time, delay)\n",
    "        start = int(self.number * self.next_layer)\n",
    "        for syn in self.output_syn[start:(start+(self.next_layer))]:\n",
    "            #print('input: ', syn.input_neuron, \"output \", syn.output_neuron, \"on layer \", syn.layer)\n",
    "            # if self.layer == 1:\n",
    "            #     a = l1_a[syn.input_neuron][syn.output_neuron]\n",
    "            #     b = l1_b[syn.input_neuron][syn.output_neuron]\n",
    "            # if self.layer == 2:\n",
    "            #     a = l2_a[syn.input_neuron][syn.output_neuron]\n",
    "            #     b = l2_b[syn.input_neuron][syn.output_neuron]\n",
    "            syn.spike_time = ians_sigmoid(time, syn.a, syn.b, m, c, layer=syn.layer) + delay\n",
    "            #print(ians_sigmoid(time, 1, 0, m, c, layer=syn.layer) + delay)\n",
    "            #print(ians_sigmoid(time, 2, 0, m, c, layer=syn.layer) + delay)\n",
    "            #print(syn.spike_time, syn.layer)\n",
    "            #print(\"syn a and b\", a, b)\n",
    "            #print(\"syna and b\", syn.a, syn.b)\n",
    "            #print(\"syn spike time & delay \", syn.spike_time, delay)\n",
    "            #print(\"spike time send to syn \",syn.input_neuron,syn.output_neuron, \"at time \", syn.spike_time)\n",
    "            pass\n",
    "        # for all sync going out from this one: \n",
    "            # set call ian_sig and set that synapaces time to reach at calculated time\n",
    "\n",
    "\n",
    "    def check_arival(self):\n",
    "        '''Check first if this neuron has alreay sent or not. If it hasn't then it goes to check the synapses to see if one has arrived'''\n",
    "        if self.fired:\n",
    "            return\n",
    "        else:\n",
    "            self.check_syn_arival()\n",
    "\n",
    "\n",
    "    def check_syn_arival(self):\n",
    "        '''used in check_arival it will see if neruon is ready to act now basied on arriving spikes'''\n",
    "        global current_time\n",
    "        #print(self.layer)\n",
    "        if self.layer == 0: # only for input layer\n",
    "            if self.scheduled_spike <= current_time: # if fired already checked\n",
    "                self.voltage += 1\n",
    "                #print(\"input voltage set at time \", current_time)\n",
    "        else:\n",
    "\n",
    "            start = self.number * (self.current_layer -1)\n",
    "            for syn in self.input_syn[start: : self.current_layer]: # goes over all incoming synapaces\n",
    "                if (syn.message_complete) == False: # if syn is has not yet given this neuron its message\n",
    "                    #print(self.layer, syn.layer)\n",
    "                    #print(syn.check_spike(), current_time, syn.layer)\n",
    "                    # print(syn.check_spike(), current_time, syn.layer)\n",
    "                    if syn.check_spike() <= current_time: # will check if current step has been reached\n",
    "                        #print(syn.check_spike(), current_time)\n",
    "                        #print(self.layer, syn.layer)\n",
    "                        #print(\"got Here\")\n",
    "                        #print(syn.check_spike(), current_time, self.layer)\n",
    "                        # print(\"layer: \", self.layer)\n",
    "                        # print(\"recived spike at: \",current_time)\n",
    "                        syn.message_complete = True\n",
    "                        #update neruons voltage\n",
    "                        self.voltage += 1.2\n",
    "\n",
    "        self.check_threshold_voltage()\n",
    "        \n",
    "                    \n",
    "                    \n",
    "    def check_threshold_voltage(self):\n",
    "        global time_step\n",
    "        if self.voltage >= self.threshold:\n",
    "            #print(self.layer, self.voltage, self.threshold)\n",
    "            #print(\"self.voltage: \", self.voltage)\n",
    "            #print(\"threshold: \", self.threshold)\n",
    "            #print(current_time)\n",
    "            self.spike_time = current_time\n",
    "            #print(self.spike_time)\n",
    "            #print(self.layer, self.spike_time)\n",
    "            #print(\"spike time: \", current_time)\n",
    "            self.send_to_syn(current_time, current_time)  # CHANGE IF LAYER NOT == 0?\n",
    "        # else:\n",
    "        #     if current_time >= (self.layer):\n",
    "        #         self.voltage += (time_step*self.past_layer) * 0.5 # will change such and whatnot just playing to start# \n",
    "\n",
    "class synapse:\n",
    "    def __init__(self, input_neuron, output_neuron, layer, a, b):\n",
    "        global run_time\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.input_neuron = input_neuron\n",
    "        self.output_neuron = output_neuron\n",
    "        self.layer = layer\n",
    "        self.spike_time = 10.0\n",
    "        self.message_complete = False\n",
    "        self.grad_a = 0\n",
    "        self.grad_b = 0\n",
    "\n",
    "    def set_spiketime(self, time):\n",
    "        self.spike_time = float(time)\n",
    "\n",
    "\n",
    "    def check_spike(self):\n",
    "        return float(self.spike_time)\n",
    "\n",
    "def genesis():\n",
    "    create_new_neurons_network()\n",
    "    create_synapses()\n",
    "    return\n",
    "\n",
    "def create_new_neurons_network():\n",
    "    count = 0\n",
    "    for i in range(len(inputs)):\n",
    "        n = Neuron(layer=0, number=i)  # will add later to add a and b and such\n",
    "        #n.set_firetime(val)\n",
    "        neurons_input.append(n)\n",
    "        n.scheduled_spike = inputs[i] \n",
    "        #print(n.scheduled_spike)\n",
    "        #print('Neuron Input neuron ' + str(neurons_input[i].number), \"scheduled time: \", n.scheduled_spike)\n",
    "\n",
    "    count = 0\n",
    "    for i in range (hidden_layer):\n",
    "        n = Neuron(layer=1, number=i)\n",
    "        neurons_hidden.append(n)\n",
    "        #print(\"Neuron at layer 1: \" + str(neurons_hidden[i].number))\n",
    "\n",
    "    count = 0\n",
    "    for i in range (output_layer):\n",
    "        n = Neuron(layer=2, number=i)\n",
    "        neurons_output.append(n)\n",
    "        #print(\"Neuron at output layer: \" + str(neurons_output[i].number))\n",
    "\n",
    "def create_synapses():\n",
    "    for input_n in neurons_input:\n",
    "        for hidden_n in neurons_hidden:\n",
    "            #print(input_n.number)\n",
    "            #print(hidden_n.number)\n",
    "            # create new object of synapics \n",
    "            #give the object to both neurons so one can output to and the other can edit it\n",
    "            syn = synapse(input_neuron=input_n.number, output_neuron=hidden_n.number, layer=0, a= 1 + random.uniform(-0.1, 0.1), b= random.uniform(-0.1, 0.1)) \n",
    "            syn_layer_1.append(syn)\n",
    "\n",
    "    for hidden_n in neurons_hidden:\n",
    "        for output_n in neurons_output:\n",
    "            #print(\"h\", hidden_n.number)\n",
    "            #print(\"0\" , output_n.number)\n",
    "            # create new object of synapics \n",
    "            #give the object to both neurons so one can output to and the other can edit it\n",
    "            syn = synapse(input_neuron=hidden_n.number, output_neuron=output_n.number, layer=1, a= 1 + random.uniform(-0.1, 0.1), b= random.uniform(-0.1, 0.1)) \n",
    "            syn_layer_2.append(syn)\n",
    "\n",
    "    \n",
    "    for count in range(output_layer): # will check layer \n",
    "            syn = synapse(input_neuron=count, output_neuron=count, layer=2, a=a, b=b) \n",
    "            syn_outputs.append(syn)\n",
    "\n",
    "\n",
    "    return 0\n",
    "\n",
    "def run_simulation(runtime, dx):\n",
    "    global current_time, time_step\n",
    "    time_step = 1.0/dx\n",
    "    \n",
    "    current_time = 0\n",
    "\n",
    "    for i in range(runtime*dx):\n",
    "       \n",
    "        for n1 in neurons_input:\n",
    "            n1.check_arival()\n",
    "            pass \n",
    "\n",
    "        for n2 in neurons_hidden:\n",
    "            n2.check_arival()\n",
    "            pass \n",
    "\n",
    "        for n3 in neurons_output:\n",
    "            n3.check_arival()\n",
    "            pass\n",
    "\n",
    "        current_time += time_step\n",
    "\n",
    "\n",
    "    return \n",
    "\n",
    "def reset_network():\n",
    "    global current_time\n",
    "    current_time = 0\n",
    "    for n in neurons_input: \n",
    "        n.voltage = 0\n",
    "        n.fired = False\n",
    "        n.spike_time = run_time\n",
    "    for n in neurons_hidden:\n",
    "        n.voltage = 0\n",
    "        n.fired = False\n",
    "        n.spike_time = run_time\n",
    "    for n in neurons_output:\n",
    "        n.voltage = 0\n",
    "        n.fired = False\n",
    "        n.spike_time = run_time\n",
    "    for s in syn_layer_1:\n",
    "        s.spike_time = run_time\n",
    "        s.message_complete = False\n",
    "    for s in syn_layer_2:\n",
    "        s.spike_time = run_time\n",
    "        s.message_complete = False\n",
    "\n",
    "def Skuld_learn(inputs, x,y,z, desired, lr):\n",
    "    \"\"\"description here\n",
    "    \"\"\"\n",
    "    global m, c, layer_bias\n",
    "    \n",
    "    # genesis()\n",
    "\n",
    "\n",
    "    for idx, n in enumerate(neurons_input):\n",
    "        n.scheduled_spike = float(inputs[idx])\n",
    "\n",
    "\n",
    "\n",
    "    run_simulation(run_time, 100)\n",
    "\n",
    "    # for i in range(input_layer):\n",
    "    #     print(neurons_input[i].spike_time)\n",
    "\n",
    "    avg_input  = sum(n.spike_time for n in neurons_input ) / input_layer\n",
    "    #print(neurons_input)\n",
    "\n",
    "    avg_output = 0\n",
    "    for i in range(output_layer): # goes overall outputs to get the average output\n",
    "        avg_output += neurons_output[i].spike_time\n",
    "    avg_output = avg_output/output_layer\n",
    "\n",
    "    avg_hidden = 0\n",
    "    for i in range(hidden_layer): # goes overall outputs to get the average output\n",
    "        avg_hidden += neurons_hidden[i].spike_time\n",
    "    avg_hidden= avg_hidden/hidden_layer\n",
    "\n",
    "\n",
    "    # calcs loss\n",
    "    #loss = calc_loss(avg_output, desired)\n",
    "\n",
    "        # === Backward pass ===\n",
    "    # 1) grab each output spike time into a vector\n",
    "    output_times = np.array([n.spike_time for n in neurons_output])      # shape (z,)\n",
    "    desired_times = np.array(desired)                                    # shape (z,)\n",
    "\n",
    "    # 2) compute per‑neuron delta; dividing by z reproduces your old avg logic\n",
    "    #    so that sum(dL_dO) == (avg_output - avg(desired))\n",
    "    dL_dO = (output_times - desired_times) / output_layer                # shape (z,)\n",
    "\n",
    "    for syn in syn_layer_2:\n",
    "        # 3) pick the delta for the neuron this synapse feeds into:\n",
    "        delta_o = dL_dO[syn.output_neuron]\n",
    "\n",
    "        # chain through average (identical to before, since we already divided by z)\n",
    "        dL_dδ = delta_o  \n",
    "\n",
    "        # derivative of f wrt a and b\n",
    "        E    = -m * avg_hidden + syn.b + c + 2 * layer_bias\n",
    "        expE = np.exp(E)\n",
    "        u    = (1 / syn.a) + expE\n",
    "\n",
    "        # ∂f/∂a and ∂f/∂b for f = a / u\n",
    "        df_da = 1/u + 1/(u * u * syn.a)\n",
    "        df_db = - syn.a * expE / (u * u)\n",
    "\n",
    "        syn.grad_a = dL_dδ * df_da\n",
    "        syn.grad_b = dL_dδ * df_db\n",
    "\n",
    "        syn.a -= lr * syn.grad_a\n",
    "        syn.b -= lr * syn.grad_b\n",
    "\n",
    "    # backprop into the hidden‐layer “average”\n",
    "    # we sum up all z of those output deltas back into a single scalar\n",
    "    dL_dh = np.sum(dL_dO)   # this generalizes dL_dh = dL_dO * z\n",
    "\n",
    "    # hidden layer update remains the same, but now will also scale if you change y\n",
    "    for syn in syn_layer_1:\n",
    "        dL_dδ = dL_dh * (1 / hidden_layer)\n",
    "\n",
    "        E    = -m * avg_input + syn.b + c + 1 * layer_bias\n",
    "        expE = np.exp(E)\n",
    "        u    = (1 / syn.a) + expE\n",
    "\n",
    "        df_da = 1/u + 1/(u * u * syn.a)\n",
    "        df_db = - syn.a * expE / (u * u)\n",
    "\n",
    "        syn.grad_a = dL_dδ * df_da\n",
    "        syn.grad_b = dL_dδ * df_db\n",
    "\n",
    "        syn.a -= lr * syn.grad_a\n",
    "        syn.b -= lr * syn.grad_b\n",
    "    \n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "4ef1b655",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[247], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m15\u001b[39m):\n\u001b[0;32m      6\u001b[0m     reset_network()\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mSkuld_learn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[243], line 291\u001b[0m, in \u001b[0;36mSkuld_learn\u001b[1;34m(inputs, x, y, z, desired, lr)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# genesis()\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(neurons_input):\n\u001b[1;32m--> 291\u001b[0m     n\u001b[38;5;241m.\u001b[39mscheduled_spike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    295\u001b[0m run_simulation(run_time, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;66;03m# for i in range(input_layer):\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;66;03m#     print(neurons_input[i].spike_time)\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# # testing here\n",
    "\n",
    "inputs = [0.5] * 4 # need to match input #     # # need to investiat my it slows down so mcuh\n",
    "genesis()\n",
    "for i in range(15):\n",
    "    reset_network()\n",
    "    print(Skuld_learn(inputs, input_layer, hidden_layer, output_layer, 5.0, 0.1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9a2a0fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[245], line 59\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xi, yi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_train, y_train):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m#print[inputs.shape]\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m#print(inputs.shape)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m#print(inputs)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m#print(yi)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     reset_network()\n\u001b[1;32m---> 59\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mSkuld_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhidden_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesired\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m#print(output)\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(neurons_output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mspike_time, neurons_output[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mspike_time, neurons_output[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mspike_time)\n",
      "Cell \u001b[1;32mIn[243], line 291\u001b[0m, in \u001b[0;36mSkuld_learn\u001b[1;34m(inputs, x, y, z, desired, lr)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# genesis()\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(neurons_input):\n\u001b[1;32m--> 291\u001b[0m     n\u001b[38;5;241m.\u001b[39mscheduled_spike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    295\u001b[0m run_simulation(run_time, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;66;03m# for i in range(input_layer):\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;66;03m#     print(neurons_input[i].spike_time)\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_layer  = 4    \n",
    "hidden_layer = 10\n",
    "output_layer = 3\n",
    "lr = 0.005\n",
    "#inputs = [0.5, 0.5, 0.9, 1.2]\n",
    "\n",
    "# 1) Load Iris and normalize features to [0,1]\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "X = X * (1.5 - 0.5) + 0.5  # set x to range of 0.5 - 1.5\n",
    "#print (X)\n",
    "\n",
    "X_times = np.round(X, 3) # round inputs to 3 decimal places\n",
    "#print(X_times)\n",
    "\n",
    "# 1) define your times\n",
    "correct_time   = 5.0\n",
    "incorrect_time = 3.0\n",
    "num_outputs    = 3    # Iris has 3 classes\n",
    "\n",
    "# 2) build a (n_samples, 3) array filled with incorrect_time\n",
    "Y_times = np.full((len(y), num_outputs), incorrect_time)\n",
    "\n",
    "# 3) for each sample i, set the true‐class column to correct_time\n",
    "Y_times[np.arange(len(y)), y] = correct_time\n",
    "\n",
    "#print(Y_times[:5])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_times, Y_times,\n",
    "    test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "#print(y_train, y_test)\n",
    "inputs = X_train[0].tolist()\n",
    "# print(X_train[0].tolist())\n",
    "\n",
    "genesis()\n",
    "reset_network()\n",
    "\n",
    "# # 6) TRAIN: multiple epochs over all training examples\n",
    "epochs = 50\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    for xi, yi in zip(X_train, y_train):\n",
    "        #print[inputs.shape]\n",
    "\n",
    "        #print(inputs.shape)\n",
    "        #print(inputs)\n",
    "        #print(yi)\n",
    "        reset_network()\n",
    "        output = Skuld_learn(\n",
    "            inputs         =  inputs,\n",
    "            x         = input_layer,\n",
    "            y     = hidden_layer,\n",
    "            z        = output_layer,\n",
    "            lr             = lr,\n",
    "            desired   = [1.6, 1.5, 1.5]\n",
    "        )\n",
    "        \n",
    "        #print(output)\n",
    "    print(neurons_output[0].spike_time, neurons_output[1].spike_time, neurons_output[2].spike_time)\n",
    "# # 7) TEST on hold‑out set\n",
    "# print(\"\\n=== Iris SNN Test ===\")\n",
    "# correct = 0\n",
    "# for xi, yi_label in zip(X_test, y_test):\n",
    "#     reset_network()\n",
    "#     out_times = Skuld_learn(\n",
    "#         inputs         = xi,\n",
    "#         x         = input_layer,\n",
    "#         y     = hidden_layer,\n",
    "#         z        = output_layer,\n",
    "#         lr             = lr,\n",
    "#         desired   = yi\n",
    "#     )\n",
    "#     # ALWAYS treat out_times as an array of spike‐times:\n",
    "#     pred = int(np.argmin(out_times))\n",
    "#     correct += (pred == yi_label)\n",
    "# acc = correct / len(X_test)\n",
    "# print(f\"         test accuracy = {acc * 100:.2f}%\\n\")\n",
    "\n",
    "# # … [final test run] …\n",
    "# print(\"=== Final Test Run ===\")\n",
    "# correct = 0\n",
    "# for xi, yi_label in zip(X_test, y_test):\n",
    "#     reset_network()\n",
    "#     out_times = Skuld_learn(\n",
    "#         inputs         = xi,\n",
    "#         x         = input_layer,\n",
    "#         y     = hidden_layer,\n",
    "#         z        = output_layer,\n",
    "#         lr             = 0.0,\n",
    "#         desired   = yi\n",
    "#     )\n",
    "#     pred = int(np.argmin(out_times))\n",
    "#     correct += (pred == yi_label)\n",
    "#     print(f\"in={np.round(xi,2)} → out={np.round(out_times,2)} pred={pred}, true={yi_label}\")\n",
    "\n",
    "# final_acc = correct / len(X_test)\n",
    "# print(f\"\\nFinal Accuracy: {final_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9326e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6aefaba1",
   "metadata": {},
   "source": [
    "Only commented out Scratch below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_new_111(desired, lr):   # will need to check work on bias/b and make sure everything is correct in this\n",
    "\n",
    "#     #desired = desired -.032\n",
    "#     run_simulation(run_time, 1000)\n",
    "    \n",
    "#     n1 = neurons_hidden[0].spike_time\n",
    "#     n2 = neurons_output[0].spike_time\n",
    "#     #print(\"n1, n2 : \", n1, n2)\n",
    "#     #loss = calc_loss(output, desired)\n",
    "\n",
    "#     delta_a2 = - d_loss_d_weight_2(n1, n2, desired)\n",
    "\n",
    "#     syn_a1 = syn_layer_1[0].a\n",
    "#     syn_a2 = syn_layer_2[0].a\n",
    "\n",
    "#     delta_a1 = - d_loss_d_weight_1(n1, n2, desired, syn_a2, inputs[0]) # trying to just input a as a the weight directly\n",
    "\n",
    "#     new_a1 = update_param(lr, delta_a1, syn_a1)\n",
    "#     new_a2 = update_param(lr, delta_a2, syn_a2)\n",
    "\n",
    "#     syn_b1 = syn_layer_1[0].b\n",
    "#     syn_b2 = syn_layer_2[0].b\n",
    "\n",
    "#     delta_b2 = d_loss_d_bias_2(n2, desired) # b is not - but left as + here\n",
    "#     delta_b1 = d_loss_d_bias_1(n1, n2, delta_b2, desired, syn_b2) # trying to just input a as a the weight directly\n",
    "\n",
    "\n",
    "#     new_b1 = update_param(lr, delta_b1, syn_b1)\n",
    "#     new_b2 = update_param(lr, delta_b2, syn_b2)\n",
    "\n",
    "#     return new_a1, new_a2, new_b1, new_b2, n1, n2\n",
    "\n",
    "\n",
    "# #run_new_111(input, 1.5, 0.1)\n",
    "\n",
    "\n",
    "\n",
    "# genesis()\n",
    "\n",
    "# for i in range(100):\n",
    "   \n",
    "#     reset_network() # needs to add reset for all that isn't the genesis call\n",
    "   \n",
    "#     sa1, sa2, sb1, sb2, n1, n2 = run_new_111(desired=0.5, lr=.1) # basic range should work just need to find the range and such but can do later then \n",
    "#                                 # desired has to be between 1.532 and 3.335\n",
    "#                                 # also need to fully reset when values overeach to get that 1.532 and 3.335\n",
    "#                                 # limited ranged based on limit else it crashes and resets to at near start spike time\n",
    "#                                 # need roundeding else it falls off for speed\n",
    "#     # l1_a[0][0] = sa1\n",
    "#     # l2_a[0][0] = sa2\n",
    "#     # l1_b[0][0] = sb1\n",
    "#     # l2_b[0][0] = sb2\n",
    "#     syn_layer_1[0].a = np.round(sa1, 5)\n",
    "#     syn_layer_2[0].a = np.round(sa2, 5)\n",
    "#     syn_layer_1[0].b = np.round(sb1, 5)\n",
    "#     syn_layer_2[0].b = np.round(sb2, 5)\n",
    "\n",
    "#     print(\"a1 and a2: \", sa1, sa2)\n",
    "#     print(\"b1 and b2: \", sb1, sb2)\n",
    "#     print(np.round(n2, 3))\n",
    "\n",
    "# print(\"a1 and a2: \", sa1, sa2)\n",
    "# print(\"b1 and b2: \", sb1, sb2)\n",
    "\n",
    "# # print(l1_a)\n",
    "# # print(l1_b)\n",
    "# # print(l2_a)\n",
    "# # print(l2_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291febc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_synapses()      # create synapses objects once\n",
    "# for epoch in range(10):\n",
    "#    # clear out last run’s flags & times\n",
    "#     sa1, sa2, sb1, sb2, n1, n2 = run_new_111(1.5, 0.1)\n",
    "#     # write back into synapse objects:\n",
    "#     syn_layer_1[0].a = sa1\n",
    "#     syn_layer_2[0].a = sa2\n",
    "#     syn_layer_1[0].b = sb1\n",
    "#     syn_layer_2[0].b = sb2\n",
    "#     print(f\"Epoch {epoch}: a1={sa1:.4f}, a2={sa2:.4f}, n2={n2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c1d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_spike_raster(inputs,\n",
    "#                       syn_layer_1,\n",
    "#                       syn_layer_2,\n",
    "#                       syn_outputs):\n",
    "#     \"\"\"\n",
    "#     inputs: list of input‐neuron spike times\n",
    "#     syn_layer_1: list of synapse objects for layer 1 (must have .spike_time)\n",
    "#     syn_layer_2: list of synapse objects for layer 2\n",
    "#     syn_outputs: list of synapse objects for output layer\n",
    "#     \"\"\"\n",
    "#     # collect times & y‐positions\n",
    "#     times = []\n",
    "#     rows  = []\n",
    "#     labels = []\n",
    "\n",
    "#     # row 0 = input spikes\n",
    "#     for t in inputs:\n",
    "#         times.append(t)\n",
    "#         rows.append(0)\n",
    "#         labels.append(\"input\")\n",
    "\n",
    "#     # row 1 = layer‐1 synapses\n",
    "#     for idx, s in enumerate(syn_layer_1):\n",
    "#         times.append(s.spike_time)\n",
    "#         rows.append(1)\n",
    "#         labels.append(f\"syn1_{idx}\")\n",
    "\n",
    "#     # row 2 = layer‐2 synapses\n",
    "#     for idx, s in enumerate(syn_layer_2):\n",
    "#         times.append(s.spike_time)\n",
    "#         rows.append(2)\n",
    "#         labels.append(f\"syn2_{idx}\")\n",
    "\n",
    "#     # row 3 = output synapses\n",
    "#     for idx, s in enumerate(syn_outputs):\n",
    "#         times.append(s.spike_time)\n",
    "#         rows.append(3)\n",
    "#         labels.append(f\"out_{idx}\")\n",
    "\n",
    "#     # now plot\n",
    "#     plt.figure(figsize=(8, 3))\n",
    "#     plt.scatter(times, rows, marker='|', s=200)\n",
    "#     plt.yticks([0,1,2,3], ['input','syn1','syn2','output'])\n",
    "#     plt.xlabel(\"Time\")\n",
    "#     plt.title(\"Spike / Synapse firing times\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# # (assuming you kept your syn_layer_1, syn_layer_2, syn_outputs in scope)\n",
    "# final_time = run_simulation(inputs, run_time, 10000)\n",
    "# print(\"final spike at\", final_time)\n",
    "\n",
    "# plot_spike_raster(\n",
    "#     inputs,\n",
    "#     syn_layer_1,\n",
    "#     syn_layer_2,\n",
    "#     syn_outputs\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train\n",
    " \n",
    "# input = 0.5  # all inputs have to be larger then 0.5?\n",
    "# lr = 0.1\n",
    "# a1 = 1.1\n",
    "# a2 = 0.9\n",
    "# b1 = -0.1\n",
    "# b2 = 0.0\n",
    "# desired = 1.0\n",
    "# # weird thing with moving the lr too much need to keep low nery steep start with changing lower m maybe?\n",
    "# for i in range(1000):\n",
    "#     a1, a2, b1, b2, r = run_basic(input, a1, a2, b1, b2, desired, lr)\n",
    "#     # print(\"a1 and a2: \", a1, a2)\n",
    "#     # print(\"b1 and b2: \", b1, b2)\n",
    "#     print(np.round(r[0][1], 3))\n",
    "# print(\"a1 and a2: \", a1, a2)\n",
    "# print(\"b1 and b2: \", b1, b2)\n",
    "# print(np.round(r[0][1], 3))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2449905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Brian Simulation: \n",
    "# from brian2 import *\n",
    "# import numpy as np\n",
    "# import logging\n",
    "# import warnings\n",
    "# from brian2 import prefs, set_device\n",
    "# # Tell Brian2 to use the Cython code generator:\n",
    "# prefs.codegen.target = 'cython'\n",
    "\n",
    "# # Optionally compile but keep Python interface:\n",
    "# set_device('runtime')  # default; compiles operations to .so but stays in Python process\n",
    "\n",
    "# # suppress overflow warnings\n",
    "# warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "# numpy.seterr(over='ignore', under='ignore')\n",
    "# logging.getLogger('brian2').setLevel(logging.ERROR)\n",
    "\n",
    "# # ----------------------------------------------------------------------------\n",
    "# # Spike timing and derivative\n",
    "# layer_bias = 0.5\n",
    "# start_scope()\n",
    "# defaultclock.dt = 0.001*ms\n",
    "\n",
    "# @implementation('numpy', discard_units=True)\n",
    "# @check_units(time=1, a=1, b=1, m=1, c=1, layer=1, result=1)\n",
    "# def ians_sigmoid(time, a, b, m, c, layer):\n",
    "#     print(time)\n",
    "#     global layer_bias\n",
    "#     print(\"result of ians_sig: \", 1/ ((1/a) + np.exp(((-time*m) + b + c + layer * layer_bias))))\n",
    "#     return 1/ ((1/a) + np.exp(((-time*m) + b + c + layer * layer_bias)))\n",
    "\n",
    "\n",
    "\n",
    "# def mini1x1x1(inputs):\n",
    "#     \"\"\"\n",
    "#     Mini 1x1x1 network with a single input, hidden, and output neuron.\n",
    "#     This is a minimal example to demonstrate the basic structure of a spiking neural network.\n",
    "#     \"\"\"\n",
    "#     # Define network sizes\n",
    "#     n_input = 1\n",
    "#     n_hidden = 1\n",
    "#     n_output = 1\n",
    "#     n_total = n_input + n_hidden + n_output\n",
    "\n",
    "#     # Full neuron group\n",
    "#     neurons = NeuronGroup(n_total, '''\n",
    "#         v : 1\n",
    "#         sum : 1\n",
    "#         spikes_received : 1\n",
    "#         scheduled_time : second\n",
    "#         global_clock : 1\n",
    "#         spiked : boolean\n",
    "#     ''', threshold='v > 0.5', reset='''\n",
    "#     v = 0\n",
    "#     ''', method='exact')\n",
    "#     neurons.v = 0\n",
    "#     neurons.scheduled_time = 1e9 * second\n",
    "#     neurons.global_clock = 0.0\n",
    "#     neurons.sum = 0.0\n",
    "#     neurons.spikes_received = 0.0\n",
    "\n",
    "#     # Spike inputs (one per input neuron)     \n",
    "#     stim = SpikeGeneratorGroup(n_input, indices=range(n_input), times=(inputs) * ms)\n",
    "\n",
    "#     # Input → Hidden connections\n",
    "#     syn_input = Synapses(stim, neurons[0:n_input], '''\n",
    "#         layer : 1\n",
    "#         a : 1\n",
    "#         b : 1\n",
    "#     ''', on_pre='''\n",
    "#         spikes_received += 1\n",
    "#         scheduled_time = (ians_sigmoid(t/ms, a, b, 3, 5, 0) + t/ms) * ms \n",
    "#     ''') \n",
    "#     syn_input.connect(j='i')  # connect stim[i] to neurons[i]\n",
    "#     syn_input.layer = 0\n",
    "#     syn_input.a = 5.0\n",
    "#     syn_input.b = 0.0\n",
    "\n",
    "\n",
    "#     # Hidden layer: input → hidden\n",
    "#     syn_hidden = Synapses(neurons[0:n_input], neurons[n_input:n_input + n_hidden], '''\n",
    "#         w : 1\n",
    "#         layer : 1\n",
    "#     ''', on_pre='''\n",
    "#         spikes_received += 1\n",
    "#         scheduled_time = (ians_sigmoid(t/ms, a, b, 3, 5, 0) + t/ms) * ms \n",
    "#     ''')\n",
    "#     syn_hidden.connect()\n",
    "#     #syn_hidden.w = w1 \n",
    "#     syn_hidden.layer = 1\n",
    "\n",
    "#     # Output layer: hidden → output\n",
    "#     # syn_output = Synapses(neurons[n_input:n_input + n_hidden], neurons[n_input + n_hidden:n_total], '''\n",
    "#     #     w : 1\n",
    "#     #     layer : 1\n",
    "#     # ''', on_pre='''\n",
    "#     #     spikes_received += 1\n",
    "#     #     v += 1\n",
    "    \n",
    "#     # ''')\n",
    "#     # syn_output.connect()\n",
    "#     # #syn_output.w = w2 \n",
    "#     # syn_output.layer = 2\n",
    "\n",
    "#     window = 0.02*ms\n",
    "\n",
    "#     neurons.run_regularly('''\n",
    "                          \n",
    "#         v = int(abs(t - scheduled_time) < 0.005*ms) * 1.2\n",
    "#         in_window = (scheduled_time >= (t - 0.02*ms)) * (scheduled_time <= (t + 0.02*ms))\n",
    "   \n",
    "#         fire_flag = int(in_window * (1 - spiked))\n",
    "        \n",
    "#         v      = fire_flag * 2\n",
    "#         spiked = spiked or (fire_flag > 0)\n",
    "  \n",
    "#     ''', dt=0.001*ms)\n",
    "\n",
    "#         #v = int(abs(t - scheduled_time) < 0.005*ms) * 1.2\n",
    "\n",
    "#     # Monitors\n",
    "#     mon = StateMonitor(neurons, 'v', record=True, dt=0.0001*ms)\n",
    "#     mon_sum = StateMonitor(neurons, 'sum', record=True)\n",
    "#     sp_mon = StateMonitor(neurons, 'spikes_received', record=True)\n",
    "#     sch_time = StateMonitor(neurons, 'scheduled_time', record=True)\n",
    "\n",
    "\n",
    "#     spikemon = SpikeMonitor(neurons)\n",
    "\n",
    "\n",
    "#     run(5*ms)\n",
    "\n",
    "#     # Plot voltages\n",
    "#     figure(figsize=(10, 6))\n",
    "#     for i in range(n_total):  # All neurons\n",
    "#         plot(mon.t/ms, mon.v[i], label=f'Neuron {i}')\n",
    "#     xlabel('Time (ms)')\n",
    "#     ylabel('Membrane potential')\n",
    "#     legend()\n",
    "#     title('SNN Spike Propagation Across All Layers')\n",
    "#     show()\n",
    "\n",
    "#     # plot(mon_sum.t/ms, mon_sum.sum[3])  # or any neuron index\n",
    "#     # print(mon_sum.sum[1])\n",
    "#     # print(sp_mon.spikes_received[1])\n",
    "#     # print(sch_time.scheduled_time[1])\n",
    "\n",
    "#     for i in range(n_total):\n",
    "#         times = spikemon.spike_trains()[i]\n",
    "#         if len(times) > 0:\n",
    "#             formatted_times = [f\"{t/ms:.3f} ms\" for t in times]\n",
    "#             print(f\"Neuron {i} spike times: {formatted_times}\")\n",
    "\n",
    "# input = [0.5]\n",
    "\n",
    "# mini1x1x1(input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
