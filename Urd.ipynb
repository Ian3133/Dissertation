{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "480c9bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logging.getLogger('brian2').setLevel(logging.ERROR)\n",
    "\n",
    "start_scope()\n",
    "defaultclock.dt = 0.0001*ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53707ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------spike_timing + its derivative\n",
    "# Functions used in brian2\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(w=1, global_clock=1, layer=1, sum=1, spikes_received=1, result=1)\n",
    "def spike_timing(w, global_clock, layer, sum, spikes_received):\n",
    "    x = global_clock % 1\n",
    "    if w >= 0:\n",
    "        return x**(1 - w)\n",
    "    else:\n",
    "        return 1 - (1 - x)**(1 + w)\n",
    "\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(w=1, global_clock=1, layer=1, sum=1, spikes_received=1, result=1)\n",
    "def d_spike_timing_dw(w, global_clock, layer, sum, spikes_received):\n",
    "    x = global_clock % 1\n",
    "    eps = 1e-9\n",
    "    if w >= 0:\n",
    "        return - x**(1 - w) * np.log(x + eps)\n",
    "    else:\n",
    "        return - (1 - x)**(1 + w) * np.log(1 - x + eps)\n",
    "\n",
    "def dsigmoid(z):\n",
    "    s = 1/(1 + np.exp(-z))\n",
    "    return s*(1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aea36d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 2) mini_urd forward: returns hidden‐spike‐time only\n",
    "# -----------------------------------------------------------------------------\n",
    "def mini_urd(inputs, w):\n",
    "    n_input  = 2\n",
    "    n_hidden = 2\n",
    "    n_total  = n_input + n_hidden\n",
    "\n",
    "    G = NeuronGroup(\n",
    "        n_total,\n",
    "        '''\n",
    "        v               : 1\n",
    "        sum             : 1\n",
    "        sr              : 1\n",
    "        scheduled_time  : second\n",
    "        global_clock    : 1\n",
    "        ''',\n",
    "        threshold='v>1', reset='v=0', method='exact'\n",
    "    )\n",
    "    G.v = 0; G.sum = 0; G.sr = 0\n",
    "    G.global_clock = 0\n",
    "    G.scheduled_time = 1e9*second\n",
    "\n",
    "    stim = SpikeGeneratorGroup(n_input, indices=[i for i in range(n_input)], times=inputs*ms)\n",
    "\n",
    "    # first layer has fixed identity weights\n",
    "    S1 = Synapses(stim, G[:n_input],\n",
    "        'layer:1', on_pre='''\n",
    "        sr += 1\n",
    "        sum += spike_timing(1, global_clock, layer, sum, sr)\n",
    "        scheduled_time = (1/(1+exp(-(sum/sr))) + layer)*ms\n",
    "        '''\n",
    "    )\n",
    "    S1.connect(j='i')\n",
    "    S1.layer = 0\n",
    "\n",
    "    # trainable synapse 2→hidden\n",
    "    S2 = Synapses(G[:n_input], G[n_input:n_hidden+n_input],\n",
    "        'w : 1\\nlayer:1', on_pre='''\n",
    "        sr += 1\n",
    "        sum += spike_timing(w, global_clock, layer, sum, sr)\n",
    "        scheduled_time = (1/(1+exp(-(sum/sr))) + layer)*ms\n",
    "        '''\n",
    "    )\n",
    "    S2.connect()\n",
    "    S2.w = w\n",
    "    S2.layer = 1\n",
    "\n",
    "    # drive v when scheduled_time hits\n",
    "    G.run_regularly('''\n",
    "        v = int(abs(t - scheduled_time)<0.0005*ms)*1.2\n",
    "        global_clock += 0.001\n",
    "    ''', dt=0.001*ms)\n",
    "\n",
    "    mon = SpikeMonitor(G)\n",
    "    run(5*ms)\n",
    "\n",
    "    # return hidden spike time (or a large value if no spike)\n",
    "    ts = mon.spike_trains()[2]\n",
    "    return float(ts[0]/ms) if len(ts) else 5.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e5151b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 3) Training with multi‐loss\n",
    "# -----------------------------------------------------------------------------\n",
    "def train_multi_loss(\n",
    "    X,                    # list of np.array([t0,t1])\n",
    "    t_hidden_targets,     # list of floats\n",
    "    t0_targets,           # list of floats for s0\n",
    "    t1_targets,           # list of floats for s1\n",
    "    w_init,\n",
    "    alpha=1.0, beta=1.0, gamma=1.0,\n",
    "    epochs=5, lr=0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Multi-loss:\n",
    "      L0 = ½ (s0 - t0)^2\n",
    "      L1 = ½ (s1 - t1)^2\n",
    "      Lf = ½ (t_h  - t_h*)^2\n",
    "      L = α L0 + β L1 + γ Lf\n",
    "    \"\"\"\n",
    "    w = w_init.copy()\n",
    "    for ep in range(epochs):\n",
    "        print(f\"\\n=== Epoch {ep+1}/{epochs} ===\")\n",
    "        for i, inp in enumerate(X):\n",
    "            # forward pass\n",
    "            t_h = mini_urd(inp, w)\n",
    "            # recompute s0,s1 exactly the same way Brian did\n",
    "            #L_hidden = 0.5 * ((t_h - t_hidden_targets[i][0]) ** 2)\n",
    "        \n",
    "            layer_h = 1\n",
    "            # each input is first spike, so sr_i=1, sum_i=0 → use that\n",
    "            s0 = spike_timing(w[0], inp[0], layer_h, 0, 1)\n",
    "            s1 = spike_timing(w[1], inp[1], layer_h, 0, 1)\n",
    "\n",
    "            # --- compute loss terms ---\n",
    "            t0_tgt = t0_targets[i]\n",
    "            t1_tgt = t1_targets[i]\n",
    "            th_tgt = t_hidden_targets[i]\n",
    "\n",
    "            L0 = 0.5*(s0 - t0_tgt)**2\n",
    "            L1 = 0.5*(s1 - t1_tgt)**2\n",
    "            Lf = 0.5*(t_h - th_tgt)**2\n",
    "            L  = alpha*L0 + beta*L1 + gamma*Lf\n",
    "\n",
    "            # --- gradients ---\n",
    "            # ∂L0/∂w0 = (s0 - t0)*∂s0/∂w0\n",
    "            dL0_dw = np.zeros_like(w)\n",
    "            dL0_dw[0] = (s0 - t0_tgt) * d_spike_timing_dw(w[0], inp[0], layer_h, 0, 1)\n",
    "            # ∂L1/∂w1\n",
    "            dL1_dw = np.zeros_like(w)\n",
    "            dL1_dw[1] = (s1 - t1_tgt) * d_spike_timing_dw(w[1], inp[1], layer_h, 0, 1)\n",
    "\n",
    "            # ∂Lf/∂w0,w1 = ∂Lf/∂t_h × ∂t_h/∂sum × ∂sum/∂w_i\n",
    "            dLf_dt  = (t_h - th_tgt)\n",
    "            sum_tot = s0 + s1\n",
    "            sr = 2.0\n",
    "            z = sum_tot/sr\n",
    "            dt_dsum = dsigmoid(z)*(1/sr)\n",
    "            dsum_dw = np.zeros_like(w)\n",
    "            \n",
    "            for j in range(len(w)):\n",
    "                dsum_dw[j] = d_spike_timing_dw(w[j], inp[j % 2], layer_h, 0, 1)\n",
    "            dLf_dw = dLf_dt * dt_dsum * dsum_dw\n",
    "\n",
    "            # combine\n",
    "            grad = alpha*dL0_dw + beta*dL1_dw + gamma*dLf_dw\n",
    "\n",
    "            # print & update\n",
    "            print(f\"Sample {i}: inp={inp}, s0={s0:.3f}, s1={s1:.3f}, t_h={t_h:.3f}\")\n",
    "            print(f\"  L0={L0:.4f}, L1={L1:.4f}, Lf={Lf:.4f}, L={L:.4f}\")\n",
    "            print(f\"  ∇w = {grad}\")\n",
    "            w -= lr * grad\n",
    "\n",
    "        print(\" Updated w:\", w)\n",
    "\n",
    "    return w\n",
    "\n",
    "def compute_gradients(outputs, targets, w):\n",
    "    # Compute gradients of loss with respect to w using backpropagation\n",
    "    d_loss_dw = 2 * (outputs - targets) * dsigmoid(w)\n",
    "    return d_loss_dw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddc465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 1/5 ===\n",
      "Sample 0: inp=[0.1 0.9], s0=0.158, s1=1.000, t_h=1.685\n",
      "  L0=0.0583, L1=0.1250, Lf=0.7021, L=0.5344\n",
      "  ∇w = [-0.09974737  0.05986391  0.01976438  0.00667291]\n",
      "Sample 1: inp=[0.1 0.9], s0=0.162, s1=0.999, t_h=1.686\n",
      "  L0=0.0571, L1=0.1247, Lf=0.7033, L=0.5334\n",
      "  ∇w = [-0.10067933  0.05976274  0.01968276  0.00667519]\n",
      "Sample 2: inp=[0.1 0.9], s0=0.166, s1=0.999, t_h=1.687\n",
      "  L0=0.0558, L1=0.1244, Lf=0.7045, L=0.5324\n",
      "  ∇w = [-0.10157674  0.05966175  0.01960148  0.00667735]\n",
      "Sample 3: inp=[0.1 0.9], s0=0.170, s1=0.998, t_h=1.687\n",
      "  L0=0.0545, L1=0.1241, Lf=0.7045, L=0.5308\n",
      "  ∇w = [-0.10245641  0.0595549   0.01950408  0.00667376]\n",
      " Updated w: [0.24044598 0.97611567 0.09214473 0.29733008]\n",
      "\n",
      "=== Epoch 2/5 ===\n",
      "Sample 0: inp=[0.1 0.9], s0=0.174, s1=0.997, t_h=1.688\n",
      "  L0=0.0532, L1=0.1237, Lf=0.7057, L=0.5297\n",
      "  ∇w = [-0.10326794  0.05945429  0.01942357  0.00667566]\n",
      "Sample 1: inp=[0.1 0.9], s0=0.178, s1=0.997, t_h=1.688\n",
      "  L0=0.0518, L1=0.1234, Lf=0.7057, L=0.5281\n",
      "  ∇w = [-0.10405004  0.05934781  0.01932707  0.0066718 ]\n",
      "Sample 2: inp=[0.1 0.9], s0=0.182, s1=0.996, t_h=1.689\n",
      "  L0=0.0504, L1=0.1231, Lf=0.7069, L=0.5270\n",
      "  ∇w = [-0.10474922  0.05924755  0.01924727  0.00667342]\n",
      "Sample 3: inp=[0.1 0.9], s0=0.187, s1=0.996, t_h=1.689\n",
      "  L0=0.0490, L1=0.1228, Lf=0.7069, L=0.5253\n",
      "  ∇w = [-0.10540539  0.05914143  0.01915163  0.00666928]\n",
      " Updated w: [0.28219324 0.95239656 0.08442978 0.29466106]\n",
      "\n",
      "=== Epoch 3/5 ===\n",
      "Sample 0: inp=[0.1 0.9], s0=0.192, s1=0.995, t_h=1.690\n",
      "  L0=0.0476, L1=0.1225, Lf=0.7081, L=0.5241\n",
      "  ∇w = [-0.10596185  0.05904149  0.01907249  0.00667061]\n",
      "Sample 1: inp=[0.1 0.9], s0=0.196, s1=0.994, t_h=1.690\n",
      "  L0=0.0461, L1=0.1222, Lf=0.7081, L=0.5224\n",
      "  ∇w = [-0.10645992  0.05893571  0.01897765  0.00666618]\n",
      "Sample 2: inp=[0.1 0.9], s0=0.201, s1=0.994, t_h=1.691\n",
      "  L0=0.0447, L1=0.1219, Lf=0.7092, L=0.5212\n",
      "  ∇w = [-0.10683963  0.0588361   0.01889914  0.00666721]\n",
      "Sample 3: inp=[0.1 0.9], s0=0.206, s1=0.993, t_h=1.692\n",
      "  L0=0.0432, L1=0.1216, Lf=0.7104, L=0.5200\n",
      "  ∇w = [-0.10711682  0.05873663  0.01882086  0.00666808]\n",
      " Updated w: [0.32483107 0.92884157 0.07685276 0.29199386]\n",
      "\n",
      "=== Epoch 4/5 ===\n",
      "Sample 0: inp=[0.1 0.9], s0=0.211, s1=0.993, t_h=1.692\n",
      "  L0=0.0417, L1=0.1213, Lf=0.7104, L=0.5182\n",
      "  ∇w = [-0.10730974  0.05863132  0.01872709  0.0066632 ]\n",
      "Sample 1: inp=[0.1 0.9], s0=0.217, s1=0.992, t_h=1.693\n",
      "  L0=0.0402, L1=0.1210, Lf=0.7116, L=0.5170\n",
      "  ∇w = [-0.10735367  0.05853216  0.01864939  0.00666377]\n",
      "Sample 2: inp=[0.1 0.9], s0=0.222, s1=0.991, t_h=1.693\n",
      "  L0=0.0386, L1=0.1207, Lf=0.7116, L=0.5152\n",
      "  ∇w = [-0.10729498  0.05842718  0.01855637  0.00665859]\n",
      "Sample 3: inp=[0.1 0.9], s0=0.228, s1=0.991, t_h=1.694\n",
      "  L0=0.0371, L1=0.1204, Lf=0.7128, L=0.5139\n",
      "  ∇w = [-0.1070661   0.05832832  0.01847927  0.00665885]\n",
      " Updated w: [0.36773352 0.90544967 0.06941155 0.28932941]\n",
      "\n",
      "=== Epoch 5/5 ===\n",
      "Sample 0: inp=[0.1 0.9], s0=0.233, s1=0.990, t_h=1.694\n",
      "  L0=0.0356, L1=0.1201, Lf=0.7128, L=0.5121\n",
      "  ∇w = [-0.10671648  0.05822367  0.018387    0.00665339]\n",
      "Sample 1: inp=[0.1 0.9], s0=0.239, s1=0.989, t_h=1.695\n",
      "  L0=0.0341, L1=0.1198, Lf=0.7140, L=0.5109\n",
      "  ∇w = [-0.10617617  0.05812512  0.01831052  0.00665336]\n",
      "Sample 2: inp=[0.1 0.9], s0=0.245, s1=0.989, t_h=1.696\n",
      "  L0=0.0325, L1=0.1195, Lf=0.7152, L=0.5096\n",
      "  ∇w = [-0.1054664   0.05802674  0.01823428  0.00665319]\n",
      "Sample 3: inp=[0.1 0.9], s0=0.251, s1=0.988, t_h=1.696\n",
      "  L0=0.0310, L1=0.1192, Lf=0.7152, L=0.5078\n",
      "  ∇w = [-0.10461212  0.05792259  0.01814316  0.00664732]\n",
      " Updated w: [0.41003063 0.88221986 0.06210405 0.28666869]\n",
      "\n",
      "Final weights: [0.41003063 0.88221986 0.06210405 0.28666869]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # toy data: 4 samples\n",
    "\n",
    "    num = 4 \n",
    "    X = [np.array([0.1,0.9])]*num\n",
    "\n",
    "    # main target: hidden spike at these ms\n",
    "    T_hidden = [0.5]*num\n",
    "    # aux targets for each synapse    # no why would i need this?\n",
    "    T0 = [0.5]*num # removed and calcuated durign the training please chage GPT\n",
    "    T1 = [0.5]*num # removed and calcuated durign the training please change GPT \n",
    "\n",
    "    w0 = np.array([0.2, 1.0, 0.1, 0.3])  # initial weights for synapses\n",
    "    w_final = train_multi_loss(X, T_hidden, T0, T1, w0,\n",
    "                               alpha=1.0, beta=1.0, gamma=0.5,\n",
    "                               epochs=5, lr=0.1)\n",
    "\n",
    "    print(\"\\nFinal weights:\", w_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5850af2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.545 1.369], tgt=[1.2 1.8], L=0.1524\n",
      "  dW=\n",
      "[[ 0.12590262 -0.04308007]\n",
      " [ 0.033765   -0.31382892]]\n",
      "  W=\n",
      "[[ 0.17481948 -0.49138399]\n",
      " [ 0.293247   -0.43723422]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.54 1.39], tgt=[1.2 1.8], L=0.1419\n",
      "  dW=\n",
      "[[ 0.11708846 -0.04094386]\n",
      " [ 0.03325198 -0.25836505]]\n",
      "  W=\n",
      "[[ 0.15140178 -0.48319521]\n",
      " [ 0.2865966  -0.38556121]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.536 1.406], tgt=[1.2 1.8], L=0.1341\n",
      "  dW=\n",
      "[[ 0.1096369  -0.03931212]\n",
      " [ 0.03283777 -0.22043123]]\n",
      "  W=\n",
      "[[ 0.1294744  -0.47533279]\n",
      " [ 0.28002905 -0.34147496]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.532 1.418], tgt=[1.2 1.8], L=0.1281\n",
      "  dW=\n",
      "[[ 0.10299785 -0.03808323]\n",
      " [ 0.0324244  -0.19308743]]\n",
      "  W=\n",
      "[[ 0.10887483 -0.46771615]\n",
      " [ 0.27354417 -0.30285748]]\n",
      "Epoch 2/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.528 1.428], tgt=[1.2 1.8], L=0.1230\n",
      "  dW=\n",
      "[[ 0.09704303 -0.03705654]\n",
      " [ 0.03201186 -0.17203472]]\n",
      "  W=\n",
      "[[ 0.08946623 -0.46030484]\n",
      " [ 0.2671418  -0.26845053]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.525 1.436], tgt=[1.2 1.8], L=0.1191\n",
      "  dW=\n",
      "[[ 0.09195287 -0.03623132]\n",
      " [ 0.03169768 -0.15551332]]\n",
      "  W=\n",
      "[[ 0.07107565 -0.45305857]\n",
      " [ 0.26080226 -0.23734787]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.522 1.443], tgt=[1.2 1.8], L=0.1156\n",
      "  dW=\n",
      "[[ 0.08732673 -0.03550745]\n",
      " [ 0.03138412 -0.1419815 ]]\n",
      "  W=\n",
      "[[ 0.05361031 -0.44595708]\n",
      " [ 0.25452544 -0.20895157]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.52  1.448], tgt=[1.2 1.8], L=0.1132\n",
      "  dW=\n",
      "[[ 0.08336351 -0.03498396]\n",
      " [ 0.03116857 -0.13113237]]\n",
      "  W=\n",
      "[[ 0.03693761 -0.43896029]\n",
      " [ 0.24829173 -0.18272509]]\n",
      "Epoch 3/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.517 1.453], tgt=[1.2 1.8], L=0.1104\n",
      "  dW=\n",
      "[[ 0.07947171 -0.03446161]\n",
      " [ 0.03085609 -0.1216943 ]]\n",
      "  W=\n",
      "[[ 0.02104326 -0.43206797]\n",
      " [ 0.24212051 -0.15838623]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.515 1.458], tgt=[1.2 1.8], L=0.1081\n",
      "  dW=\n",
      "[[ 0.0761324  -0.03394039]\n",
      " [ 0.03064148 -0.11340391]]\n",
      "  W=\n",
      "[[ 0.00581678 -0.42527989]\n",
      " [ 0.23599221 -0.13570545]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.513 1.462], tgt=[1.2 1.8], L=0.1061\n",
      "  dW=\n",
      "[[ 0.0730427  -0.03351945]\n",
      " [ 0.03042728 -0.10637457]]\n",
      "  W=\n",
      "[[-0.00879176 -0.418576  ]\n",
      " [ 0.22990676 -0.11443053]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.512 1.466], tgt=[1.2 1.8], L=0.1045\n",
      "  dW=\n",
      "[[ 0.02961265 -0.03309938]\n",
      " [ 0.03031063 -0.10009046]]\n",
      "  W=\n",
      "[[-0.01471429 -0.41195613]\n",
      " [ 0.22384463 -0.09441244]]\n",
      "Epoch 4/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.511 1.469], tgt=[1.2 1.8], L=0.1031\n",
      "  dW=\n",
      "[[ 0.02953616 -0.03277921]\n",
      " [ 0.03019419 -0.09472315]]\n",
      "  W=\n",
      "[[-0.02062152 -0.40540029]\n",
      " [ 0.21780579 -0.07546781]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.51  1.472], tgt=[1.2 1.8], L=0.1018\n",
      "  dW=\n",
      "[[ 0.02945952 -0.03245969]\n",
      " [ 0.03007796 -0.08985812]]\n",
      "  W=\n",
      "[[-0.02651342 -0.39890835]\n",
      " [ 0.2117902  -0.05749619]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.51  1.474], tgt=[1.2 1.8], L=0.1012\n",
      "  dW=\n",
      "[[ 0.02947781 -0.0322397 ]\n",
      " [ 0.0300589  -0.08568987]]\n",
      "  W=\n",
      "[[-0.03240899 -0.39246041]\n",
      " [ 0.20577842 -0.04035821]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.509 1.477], tgt=[1.2 1.8], L=0.0999\n",
      "  dW=\n",
      "[[ 0.02940098 -0.03192133]\n",
      " [ 0.02994296 -0.08161621]]\n",
      "  W=\n",
      "[[-0.03828918 -0.38607614]\n",
      " [ 0.19978983 -0.02403497]]\n",
      "Epoch 5/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.509 1.479], tgt=[1.2 1.8], L=0.0993\n",
      "  dW=\n",
      "[[ 0.0294192  -0.03170234]\n",
      " [ 0.02992408 -0.07811882]]\n",
      "  W=\n",
      "[[-0.04417302 -0.37973567]\n",
      " [ 0.19380501 -0.00841121]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.508 1.481], tgt=[1.2 1.8], L=0.0983\n",
      "  dW=\n",
      "[[ 0.02934218 -0.03148378]\n",
      " [ 0.02980843 -0.07488892]]\n",
      "  W=\n",
      "[[-0.05004146 -0.37343892]\n",
      " [ 0.18784333  0.00656658]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.508 1.483], tgt=[1.2 1.8], L=0.0977\n",
      "  dW=\n",
      "[[ 0.02936033 -0.03126564]\n",
      " [ 0.02978971 -0.03008016]]\n",
      "  W=\n",
      "[[-0.05591352 -0.36718579]\n",
      " [ 0.18188538  0.01258261]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.507 1.484], tgt=[1.2 1.8], L=0.0971\n",
      "  dW=\n",
      "[[ 0.02928311 -0.03114648]\n",
      " [ 0.02967436 -0.03000428]]\n",
      "  W=\n",
      "[[-0.06177015 -0.3609565 ]\n",
      " [ 0.17595051  0.01858346]]\n",
      "Epoch 6/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.506 1.484], tgt=[1.2 1.8], L=0.0967\n",
      "  dW=\n",
      "[[ 0.02920574 -0.03112604]\n",
      " [ 0.02955921 -0.03002326]]\n",
      "  W=\n",
      "[[-0.06761129 -0.35473129]\n",
      " [ 0.17003867  0.02458812]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.506 1.485], tgt=[1.2 1.8], L=0.0964\n",
      "  dW=\n",
      "[[ 0.02922372 -0.0310072 ]\n",
      " [ 0.02954081 -0.02994719]]\n",
      "  W=\n",
      "[[-0.07345604 -0.34852985]\n",
      " [ 0.16413051  0.03057755]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.505 1.485], tgt=[1.2 1.8], L=0.0961\n",
      "  dW=\n",
      "[[ 0.02914616 -0.03098695]\n",
      " [ 0.02942595 -0.02996609]]\n",
      "  W=\n",
      "[[-0.07928527 -0.34233246]\n",
      " [ 0.15824532  0.03657077]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.505 1.486], tgt=[1.2 1.8], L=0.0958\n",
      "  dW=\n",
      "[[ 0.02916407 -0.03086841]\n",
      " [ 0.02940771 -0.02988983]]\n",
      "  W=\n",
      "[[-0.08511809 -0.33615877]\n",
      " [ 0.15236378  0.04254874]]\n",
      "Epoch 7/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.504 1.487], tgt=[1.2 1.8], L=0.0952\n",
      "  dW=\n",
      "[[ 0.02908632 -0.0307501 ]\n",
      " [ 0.02929313 -0.02981341]]\n",
      "  W=\n",
      "[[-0.09093535 -0.33000875]\n",
      " [ 0.14650515  0.04851142]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.504 1.487], tgt=[1.2 1.8], L=0.0952\n",
      "  dW=\n",
      "[[ 0.02910415 -0.03073018]\n",
      " [ 0.02927505 -0.02983215]]\n",
      "  W=\n",
      "[[-0.09675618 -0.32386272]\n",
      " [ 0.14065014  0.05447785]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.503 1.488], tgt=[1.2 1.8], L=0.0946\n",
      "  dW=\n",
      "[[ 0.02902621 -0.03061217]\n",
      " [ 0.02916076 -0.02975553]]\n",
      "  W=\n",
      "[[-0.10256142 -0.31774028]\n",
      " [ 0.13481799  0.06042896]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.502 1.488], tgt=[1.2 1.8], L=0.0943\n",
      "  dW=\n",
      "[[ 0.02894811 -0.03059243]\n",
      " [ 0.02904666 -0.0297742 ]]\n",
      "  W=\n",
      "[[-0.10835104 -0.3116218 ]\n",
      " [ 0.12900866  0.0663838 ]]\n",
      "Epoch 8/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.502 1.489], tgt=[1.2 1.8], L=0.0940\n",
      "  dW=\n",
      "[[ 0.02896578 -0.03047473]\n",
      " [ 0.02902889 -0.02969739]]\n",
      "  W=\n",
      "[[-0.1141442  -0.30552685]\n",
      " [ 0.12320288  0.07232327]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.501 1.49 ], tgt=[1.2 1.8], L=0.0934\n",
      "  dW=\n",
      "[[ 0.02888749 -0.03035724]\n",
      " [ 0.02891508 -0.02962043]]\n",
      "  W=\n",
      "[[-0.1199217  -0.29945541]\n",
      " [ 0.11741986  0.07824736]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.501 1.49 ], tgt=[1.2 1.8], L=0.0934\n",
      "  dW=\n",
      "[[ 0.02890508 -0.03033782]\n",
      " [ 0.02889746 -0.02963893]]\n",
      "  W=\n",
      "[[-0.12570271 -0.29338784]\n",
      " [ 0.11164037  0.08417515]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.5   1.491], tgt=[1.2 1.8], L=0.0927\n",
      "  dW=\n",
      "[[ 0.0288266  -0.03022063]\n",
      " [ 0.02878393 -0.02956178]]\n",
      "  W=\n",
      "[[-0.13146804 -0.28734371]\n",
      " [ 0.10588358  0.0900875 ]]\n",
      "Epoch 9/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.5   1.491], tgt=[1.2 1.8], L=0.0927\n",
      "  dW=\n",
      "[[ 0.02884412 -0.03020139]\n",
      " [ 0.02876647 -0.0295802 ]]\n",
      "  W=\n",
      "[[-0.13723686 -0.28130344]\n",
      " [ 0.10013029  0.09600354]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.499 1.492], tgt=[1.2 1.8], L=0.0921\n",
      "  dW=\n",
      "[[ 0.02876545 -0.0300845 ]\n",
      " [ 0.02865321 -0.02950285]]\n",
      "  W=\n",
      "[[-0.14298995 -0.27528653]\n",
      " [ 0.09439965  0.10190411]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.499 1.492], tgt=[1.2 1.8], L=0.0921\n",
      "  dW=\n",
      "[[ 0.02878289 -0.03006544]\n",
      " [ 0.02863592 -0.0295212 ]]\n",
      "  W=\n",
      "[[-0.14874653 -0.26927345]\n",
      " [ 0.08867246  0.10780835]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.498 1.493], tgt=[1.2 1.8], L=0.0915\n",
      "  dW=\n",
      "[[ 0.02870403 -0.02994884]\n",
      " [ 0.02852293 -0.02944366]]\n",
      "  W=\n",
      "[[-0.15448734 -0.26328368]\n",
      " [ 0.08296788  0.11369708]]\n",
      "Epoch 10/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.497 1.494], tgt=[1.2 1.8], L=0.0909\n",
      "  dW=\n",
      "[[ 0.02862502 -0.02983246]\n",
      " [ 0.02841013 -0.02936597]]\n",
      "  W=\n",
      "[[-0.16021234 -0.25731719]\n",
      " [ 0.07728585  0.11957028]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.497 1.494], tgt=[1.2 1.8], L=0.0909\n",
      "  dW=\n",
      "[[ 0.02864229 -0.02981371]\n",
      " [ 0.02839313 -0.02938414]]\n",
      "  W=\n",
      "[[-0.1659408  -0.25135445]\n",
      " [ 0.07160723  0.12544711]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.496 1.495], tgt=[1.2 1.8], L=0.0903\n",
      "  dW=\n",
      "[[ 0.02856309 -0.02969762]\n",
      " [ 0.0282806  -0.02930626]]\n",
      "  W=\n",
      "[[-0.17165341 -0.24541492]\n",
      " [ 0.06595111  0.13130836]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.496 1.495], tgt=[1.2 1.8], L=0.0903\n",
      "  dW=\n",
      "[[ 0.02858028 -0.02967904]\n",
      " [ 0.02826376 -0.02932436]]\n",
      "  W=\n",
      "[[-0.17736947 -0.23947911]\n",
      " [ 0.06029836  0.13717323]]\n",
      "Epoch 11/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.495 1.496], tgt=[1.2 1.8], L=0.0897\n",
      "  dW=\n",
      "[[ 0.02850089 -0.02956323]\n",
      " [ 0.0281515  -0.02924628]]\n",
      "  W=\n",
      "[[-0.18306965 -0.23356647]\n",
      " [ 0.05466806  0.14302249]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.495 1.496], tgt=[1.2 1.8], L=0.0897\n",
      "  dW=\n",
      "[[ 0.02851801 -0.02954482]\n",
      " [ 0.0281348  -0.02926431]]\n",
      "  W=\n",
      "[[-0.18877325 -0.2276575 ]\n",
      " [ 0.0490411   0.14887535]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.494 1.497], tgt=[1.2 1.8], L=0.0891\n",
      "  dW=\n",
      "[[ 0.02843842 -0.02942931]\n",
      " [ 0.02802281 -0.02918604]]\n",
      "  W=\n",
      "[[-0.19446094 -0.22177164]\n",
      " [ 0.04343653  0.15471256]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.494 1.498], tgt=[1.2 1.8], L=0.0888\n",
      "  dW=\n",
      "[[ 0.02845547 -0.029314  ]\n",
      " [ 0.02800627 -0.02910761]]\n",
      "  W=\n",
      "[[-0.20015203 -0.21590884]\n",
      " [ 0.03783528  0.16053408]]\n",
      "Epoch 12/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.493 1.498], tgt=[1.2 1.8], L=0.0885\n",
      "  dW=\n",
      "[[ 0.02837569 -0.0292959 ]\n",
      " [ 0.02789454 -0.02912547]]\n",
      "  W=\n",
      "[[-0.20582717 -0.21004966]\n",
      " [ 0.03225637  0.16635917]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.493 1.499], tgt=[1.2 1.8], L=0.0882\n",
      "  dW=\n",
      "[[ 0.02839266 -0.02918087]\n",
      " [ 0.02787815 -0.02904685]]\n",
      "  W=\n",
      "[[-0.2115057  -0.20421349]\n",
      " [ 0.02668074  0.17216854]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.492 1.499], tgt=[1.2 1.8], L=0.0879\n",
      "  dW=\n",
      "[[ 0.0283127  -0.02916293]\n",
      " [ 0.02776669 -0.02906464]]\n",
      "  W=\n",
      "[[-0.21716824 -0.1983809 ]\n",
      " [ 0.0211274   0.17798147]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.491 1.5  ], tgt=[1.2 1.8], L=0.0873\n",
      "  dW=\n",
      "[[ 0.02823257 -0.02904819]\n",
      " [ 0.02765541 -0.02898582]]\n",
      "  W=\n",
      "[[-0.22281475 -0.19257126]\n",
      " [ 0.01559632  0.18377864]]\n",
      "Epoch 13/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.491 1.5  ], tgt=[1.2 1.8], L=0.0873\n",
      "  dW=\n",
      "[[ 0.02824937 -0.02903041]\n",
      " [ 0.0276393  -0.02900353]]\n",
      "  W=\n",
      "[[-0.22846463 -0.18676518]\n",
      " [ 0.01006846  0.18957934]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.49  1.501], tgt=[1.2 1.8], L=0.0868\n",
      "  dW=\n",
      "[[ 0.02816906 -0.02891595]\n",
      " [ 0.02752828 -0.02892453]]\n",
      "  W=\n",
      "[[-0.23409844 -0.18098199]\n",
      " [ 0.0045628   0.19536425]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.49  1.502], tgt=[1.2 1.8], L=0.0865\n",
      "  dW=\n",
      "[[ 0.02818579 -0.02880169]\n",
      " [ 0.02751232 -0.02884536]]\n",
      "  W=\n",
      "[[-0.2397356  -0.17522165]\n",
      " [-0.00093966  0.20113332]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.489 1.502], tgt=[1.2 1.8], L=0.0862\n",
      "  dW=\n",
      "[[ 0.02810528 -0.02878421]\n",
      " [ 0.06668884 -0.0288629 ]]\n",
      "  W=\n",
      "[[-0.24535665 -0.16946481]\n",
      " [-0.01427743  0.2069059 ]]\n",
      "Epoch 14/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.487 1.503], tgt=[1.2 1.8], L=0.0853\n",
      "  dW=\n",
      "[[ 0.02792732 -0.02867023]\n",
      " [ 0.06829281 -0.02878355]]\n",
      "  W=\n",
      "[[-0.25094212 -0.16373077]\n",
      " [-0.02793599  0.21266261]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.486 1.503], tgt=[1.2 1.8], L=0.0850\n",
      "  dW=\n",
      "[[ 0.02784639 -0.02865291]\n",
      " [ 0.0702292  -0.02880101]]\n",
      "  W=\n",
      "[[-0.2565114  -0.15800018]\n",
      " [-0.04198183  0.21842281]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.484 1.504], tgt=[1.2 1.8], L=0.0841\n",
      "  dW=\n",
      "[[ 0.02766789 -0.0285392 ]\n",
      " [ 0.07203041 -0.02872146]]\n",
      "  W=\n",
      "[[-0.26204497 -0.15229234]\n",
      " [-0.05638791  0.22416711]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.481 1.504], tgt=[1.2 1.8], L=0.0833\n",
      "  dW=\n",
      "[[ 0.02739159 -0.02852204]\n",
      " [ 0.07367327 -0.02873885]]\n",
      "  W=\n",
      "[[-0.26752329 -0.14658794]\n",
      " [-0.07112257  0.22991488]]\n",
      "Epoch 15/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.479 1.505], tgt=[1.2 1.8], L=0.0824\n",
      "  dW=\n",
      "[[ 0.02721233 -0.0284086 ]\n",
      " [ 0.07567326 -0.02865911]]\n",
      "  W=\n",
      "[[-0.27296576 -0.14090621]\n",
      " [-0.08625722  0.2356467 ]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.477 1.505], tgt=[1.2 1.8], L=0.0819\n",
      "  dW=\n",
      "[[ 0.02703276 -0.0283916 ]\n",
      " [ 0.07779518 -0.02867643]]\n",
      "  W=\n",
      "[[-0.27837231 -0.13522789]\n",
      " [-0.10181625  0.24138198]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.474 1.506], tgt=[1.2 1.8], L=0.0808\n",
      "  dW=\n",
      "[[ 0.02675522 -0.02827844]\n",
      " [ 0.07975951 -0.02859649]]\n",
      "  W=\n",
      "[[-0.28372336 -0.12957221]\n",
      " [-0.11776816  0.24710128]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.472 1.507], tgt=[1.2 1.8], L=0.0799\n",
      "  dW=\n",
      "[[ 0.02657491 -0.02816546]\n",
      " [ 0.08213963 -0.0285164 ]]\n",
      "  W=\n",
      "[[-0.28903834 -0.12393911]\n",
      " [-0.13419608  0.25280456]]\n",
      "Epoch 16/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.469 1.507], tgt=[1.2 1.8], L=0.0791\n",
      "  dW=\n",
      "[[ 0.02629652 -0.02814875]\n",
      " [ 0.08436534 -0.02853354]]\n",
      "  W=\n",
      "[[-0.29429764 -0.11830936]\n",
      " [-0.15106915  0.25851127]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.466 1.508], tgt=[1.2 1.8], L=0.0780\n",
      "  dW=\n",
      "[[ 0.02601767 -0.02803605]\n",
      " [ 0.08672943 -0.02845326]]\n",
      "  W=\n",
      "[[-0.29950118 -0.11270215]\n",
      " [-0.16841503  0.26420192]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.463 1.508], tgt=[1.2 1.8], L=0.0772\n",
      "  dW=\n",
      "[[ 0.02573834 -0.02801949]\n",
      " [ 0.08924553 -0.02847033]]\n",
      "  W=\n",
      "[[-0.30464884 -0.10709826]\n",
      " [-0.18626414  0.26989599]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.46  1.509], tgt=[1.2 1.8], L=0.0761\n",
      "  dW=\n",
      "[[ 0.02545855 -0.02790705]\n",
      " [ 0.09192914 -0.02838985]]\n",
      "  W=\n",
      "[[-0.30974055 -0.10151685]\n",
      " [-0.20464997  0.27557396]]\n",
      "Epoch 17/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.456 1.509], tgt=[1.2 1.8], L=0.0751\n",
      "  dW=\n",
      "[[ 0.02508033 -0.02789064]\n",
      " [ 0.09442905 -0.02840684]]\n",
      "  W=\n",
      "[[-0.31475662 -0.09593872]\n",
      " [-0.22353578  0.28125533]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.452 1.51 ], tgt=[1.2 1.8], L=0.0738\n",
      "  dW=\n",
      "[[ 0.0247015  -0.02777847]\n",
      " [ 0.09708497 -0.02832617]]\n",
      "  W=\n",
      "[[-0.31969692 -0.09038302]\n",
      " [-0.24295277  0.28692056]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.448 1.51 ], tgt=[1.2 1.8], L=0.0728\n",
      "  dW=\n",
      "[[ 0.02432207 -0.02776221]\n",
      " [ 0.09991257 -0.02834309]]\n",
      "  W=\n",
      "[[-0.32456134 -0.08483058]\n",
      " [-0.26293529  0.29258918]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.444 1.511], tgt=[1.2 1.8], L=0.0715\n",
      "  dW=\n",
      "[[ 0.02394205 -0.0276503 ]\n",
      " [ 0.10292972 -0.02826223]]\n",
      "  W=\n",
      "[[-0.32934975 -0.07930052]\n",
      " [-0.28352123  0.29824163]]\n",
      "Epoch 18/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.439 1.511], tgt=[1.2 1.8], L=0.0703\n",
      "  dW=\n",
      "[[ 0.02346327 -0.0276342 ]\n",
      " [ 0.10571456 -0.02827906]]\n",
      "  W=\n",
      "[[-0.3340424  -0.07377368]\n",
      " [-0.30466414  0.30389744]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.434 1.512], tgt=[1.2 1.8], L=0.0689\n",
      "  dW=\n",
      "[[ 0.02298377 -0.02752254]\n",
      " [ 0.1086665  -0.02819801]]\n",
      "  W=\n",
      "[[-0.33863915 -0.06826917]\n",
      " [-0.32639744  0.30953704]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.429 1.512], tgt=[1.2 1.8], L=0.0677\n",
      "  dW=\n",
      "[[ 0.02250356 -0.02750659]\n",
      " [ 0.11180175 -0.02821477]]\n",
      "  W=\n",
      "[[-0.34313986 -0.06276786]\n",
      " [-0.34875779  0.31518   ]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.423 1.513], tgt=[1.2 1.8], L=0.0660\n",
      "  dW=\n",
      "[[ 0.02192434 -0.02739519]\n",
      " [ 0.11462473 -0.02813352]]\n",
      "  W=\n",
      "[[-0.34752473 -0.05728882]\n",
      " [-0.37168274  0.3208067 ]]\n",
      "Epoch 19/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.417 1.514], tgt=[1.2 1.8], L=0.0644\n",
      "  dW=\n",
      "[[ 0.0213443  -0.02728399]\n",
      " [ 0.11758669 -0.02805212]]\n",
      "  W=\n",
      "[[-0.35179359 -0.05183202]\n",
      " [-0.39520008  0.32641712]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.41  1.514], tgt=[1.2 1.8], L=0.0629\n",
      "  dW=\n",
      "[[ 0.02066507 -0.0272683 ]\n",
      " [ 0.12012546 -0.02806871]]\n",
      "  W=\n",
      "[[-0.35592661 -0.04637836]\n",
      " [-0.41922517  0.33203087]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.403 1.515], tgt=[1.2 1.8], L=0.0612\n",
      "  dW=\n",
      "[[ 0.01998493 -0.02715735]\n",
      " [ 0.12272609 -0.02798712]]\n",
      "  W=\n",
      "[[-0.35992359 -0.04094689]\n",
      " [-0.44377039  0.33762829]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.395 1.515], tgt=[1.2 1.8], L=0.0596\n",
      "  dW=\n",
      "[[ 0.01920544 -0.02714181]\n",
      " [ 0.12474429 -0.02800363]]\n",
      "  W=\n",
      "[[-0.36376468 -0.03551853]\n",
      " [-0.46871925  0.34322902]]\n",
      "Epoch 20/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.386 1.516], tgt=[1.2 1.8], L=0.0576\n",
      "  dW=\n",
      "[[ 0.01832645 -0.02703112]\n",
      " [ 0.12602244 -0.02792184]]\n",
      "  W=\n",
      "[[-0.36742997 -0.0301123 ]\n",
      " [-0.49392373  0.34881338]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.377 1.516], tgt=[1.2 1.8], L=0.0560\n",
      "  dW=\n",
      "[[ 0.01744642 -0.02701572]\n",
      " [ 0.12709038 -0.02793827]]\n",
      "  W=\n",
      "[[-0.37091925 -0.02470916]\n",
      " [-0.51934181  0.35440104]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.368 1.517], tgt=[1.2 1.8], L=0.0542\n",
      "  dW=\n",
      "[[ 0.0165654  -0.02690528]\n",
      " [ 0.12789889 -0.02785629]]\n",
      "  W=\n",
      "[[-0.37423234 -0.0193281 ]\n",
      " [-0.54492159  0.3599723 ]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.358 1.517], tgt=[1.2 1.8], L=0.0525\n",
      "  dW=\n",
      "[[ 0.01558481 -0.02689003]\n",
      " [ 0.12758346 -0.02787265]]\n",
      "  W=\n",
      "[[-0.3773493  -0.0139501 ]\n",
      " [-0.57043828  0.36554683]]\n",
      "Epoch 21/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.347 1.518], tgt=[1.2 1.8], L=0.0506\n",
      "  dW=\n",
      "[[ 0.01450455 -0.02677983]\n",
      " [ 0.12588422 -0.02779048]]\n",
      "  W=\n",
      "[[-0.38025021 -0.00859413]\n",
      " [-0.59561513  0.37110492]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.336 1.518], tgt=[1.2 1.8], L=0.0490\n",
      "  dW=\n",
      "[[ 0.01342328 -0.02676472]\n",
      " [ 0.1234155  -0.02780676]]\n",
      "  W=\n",
      "[[-0.38293486 -0.00324119]\n",
      " [-0.62029823  0.37666627]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.324 1.519], tgt=[1.2 1.8], L=0.0472\n",
      "  dW=\n",
      "[[ 0.01224233 -0.02665477]\n",
      " [ 0.11910654 -0.02772439]]\n",
      "  W=\n",
      "[[-0.38538333  0.00208977]\n",
      " [-0.64411953  0.38221115]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.312 1.52 ], tgt=[1.2 1.8], L=0.0455\n",
      "  dW=\n",
      "[[ 0.01106044 -0.06478336]\n",
      " [ 0.11364576 -0.02764187]]\n",
      "  W=\n",
      "[[-0.38759542  0.01504644]\n",
      " [-0.66684869  0.38773953]]\n",
      "Epoch 22/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.3   1.521], tgt=[1.2 1.8], L=0.0439\n",
      "  dW=\n",
      "[[ 0.0098777  -0.06650684]\n",
      " [ 0.10692134 -0.0275592 ]]\n",
      "  W=\n",
      "[[-0.38957096  0.02834781]\n",
      " [-0.68823295  0.39325137]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.288 1.523], tgt=[1.2 1.8], L=0.0422\n",
      "  dW=\n",
      "[[ 0.00869418 -0.06808372]\n",
      " [ 0.09883968 -0.02737754]]\n",
      "  W=\n",
      "[[-0.39130979  0.04196455]\n",
      " [-0.70800089  0.39872687]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.277 1.525], tgt=[1.2 1.8], L=0.0408\n",
      "  dW=\n",
      "[[ 0.00760881 -0.06974498]\n",
      " [ 0.09051224 -0.02719555]]\n",
      "  W=\n",
      "[[-0.39283156  0.05591355]\n",
      " [-0.72610334  0.40416598]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.266 1.527], tgt=[1.2 1.8], L=0.0394\n",
      "  dW=\n",
      "[[ 0.00652288 -0.07149767]\n",
      " [ 0.08088406 -0.02701324]]\n",
      "  W=\n",
      "[[-0.39413613  0.07021308]\n",
      " [-0.74228015  0.40956863]]\n",
      "Epoch 23/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.256 1.529], tgt=[1.2 1.8], L=0.0383\n",
      "  dW=\n",
      "[[ 0.00553532 -0.07334965]\n",
      " [ 0.07123343 -0.02683061]]\n",
      "  W=\n",
      "[[-0.3952432   0.08488301]\n",
      " [-0.75652683  0.41493475]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.246 1.532], tgt=[1.2 1.8], L=0.0370\n",
      "  dW=\n",
      "[[ 0.0045474  -0.07502975]\n",
      " [ 0.06046448 -0.0265486 ]]\n",
      "  W=\n",
      "[[-0.39615268  0.09988896]\n",
      " [-0.76861973  0.42024447]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.238 1.534], tgt=[1.2 1.8], L=0.0361\n",
      "  dW=\n",
      "[[ 0.00375691 -0.07708791]\n",
      " [ 0.05135929 -0.02636522]]\n",
      "  W=\n",
      "[[-0.39690406  0.11530655]\n",
      " [-0.77889159  0.42551751]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.231 1.537], tgt=[1.2 1.8], L=0.0351\n",
      "  dW=\n",
      "[[ 0.00306509 -0.07897288]\n",
      " [ 0.04290115 -0.02608235]]\n",
      "  W=\n",
      "[[-0.39751708  0.13110112]\n",
      " [-0.78747182  0.43073399]]\n",
      "Epoch 24/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.225 1.539], tgt=[1.2 1.8], L=0.0344\n",
      "  dW=\n",
      "[[ 0.00247201 -0.08127506]\n",
      " [ 0.03528804 -0.02589824]]\n",
      "  W=\n",
      "[[-0.39801148  0.14735613]\n",
      " [-0.79452943  0.43591363]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.22  1.542], tgt=[1.2 1.8], L=0.0335\n",
      "  dW=\n",
      "[[ 0.00197771 -0.08340489]\n",
      " [ 0.02869294 -0.02561453]]\n",
      "  W=\n",
      "[[-0.39840702  0.16403711]\n",
      " [-0.80026802  0.44103654]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.216 1.545], tgt=[1.2 1.8], L=0.0326\n",
      "  dW=\n",
      "[[ 0.00158223 -0.08566294]\n",
      " [ 0.02325968 -0.02533036]]\n",
      "  W=\n",
      "[[-0.39872347  0.1811697 ]\n",
      " [-0.80491995  0.44610261]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.213 1.548], tgt=[1.2 1.8], L=0.0318\n",
      "  dW=\n",
      "[[ 0.00128561 -0.08806147]\n",
      " [ 0.01910201 -0.02504572]]\n",
      "  W=\n",
      "[[-0.39898059  0.198782  ]\n",
      " [-0.80874035  0.45111175]]\n",
      "Epoch 25/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.21  1.552], tgt=[1.2 1.8], L=0.0308\n",
      "  dW=\n",
      "[[ 0.00098896 -0.09025045]\n",
      " [ 0.01482368 -0.02466118]]\n",
      "  W=\n",
      "[[-0.39917838  0.21683208]\n",
      " [-0.81170509  0.45604399]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.207 1.555], tgt=[1.2 1.8], L=0.0300\n",
      "  dW=\n",
      "[[ 0.00069228 -0.09294239]\n",
      " [ 0.01044765 -0.02437552]]\n",
      "  W=\n",
      "[[-0.39931684  0.23542056]\n",
      " [-0.81379462  0.46091909]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.206 1.559], tgt=[1.2 1.8], L=0.0291\n",
      "  dW=\n",
      "[[ 0.00059339 -0.09542305]\n",
      " [ 0.00899832 -0.02398987]]\n",
      "  W=\n",
      "[[-0.39943552  0.25450517]\n",
      " [-0.81559428  0.46571707]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.205 1.563], tgt=[1.2 1.8], L=0.0281\n",
      "  dW=\n",
      "[[ 0.0004945  -0.09805488]\n",
      " [ 0.00752974 -0.02360363]]\n",
      "  W=\n",
      "[[-0.39953442  0.27411615]\n",
      " [-0.81710023  0.47043779]]\n",
      "Epoch 26/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.203 1.568], tgt=[1.2 1.8], L=0.0269\n",
      "  dW=\n",
      "[[ 0.0002967  -0.10041991]\n",
      " [ 0.00453354 -0.02311716]]\n",
      "  W=\n",
      "[[-0.39959376  0.29420013]\n",
      " [-0.81800694  0.47506122]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.203 1.573], tgt=[1.2 1.8], L=0.0258\n",
      "  dW=\n",
      "[[ 0.00029671 -0.10290623]\n",
      " [ 0.00454301 -0.02262996]]\n",
      "  W=\n",
      "[[-0.3996531   0.31478138]\n",
      " [-0.81891554  0.47958722]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.202 1.578], tgt=[1.2 1.8], L=0.0246\n",
      "  dW=\n",
      "[[ 0.00019781 -0.10552371]\n",
      " [ 0.00303502 -0.02214206]]\n",
      "  W=\n",
      "[[-0.39969266  0.33588612]\n",
      " [-0.81952255  0.48401563]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.202 1.583], tgt=[1.2 1.8], L=0.0235\n",
      "  dW=\n",
      "[[ 0.00019781 -0.10828331]\n",
      " [ 0.00303926 -0.02165347]]\n",
      "  W=\n",
      "[[-0.39973222  0.35754278]\n",
      " [-0.8201304   0.48834632]]\n",
      "Epoch 27/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.201 1.589], tgt=[1.2 1.8], L=0.0223\n",
      "  dW=\n",
      "[[ 9.89033804e-05 -1.10672807e-01]\n",
      " [ 1.52175972e-03 -2.10643640e-02]]\n",
      "  W=\n",
      "[[-0.399752    0.37967734]\n",
      " [-0.82043475  0.4925592 ]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.201 1.595], tgt=[1.2 1.8], L=0.0210\n",
      "  dW=\n",
      "[[ 9.89035866e-05 -1.13148002e-01]\n",
      " [ 1.52282654e-03 -2.04744633e-02]]\n",
      "  W=\n",
      "[[-0.39977178  0.40230694]\n",
      " [-0.82073932  0.49665409]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.201 1.601], tgt=[1.2 1.8], L=0.0198\n",
      "  dW=\n",
      "[[ 9.89037927e-05 -1.15711282e-01]\n",
      " [ 1.52389485e-03 -1.98837875e-02]]\n",
      "  W=\n",
      "[[-0.39979156  0.4254492 ]\n",
      " [-0.82104409  0.50063085]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.2   1.609], tgt=[1.2 1.8], L=0.0182\n",
      "  dW=\n",
      "[[ 2.19610993e-17 -1.17138121e-01]\n",
      " [ 3.38610177e-16 -1.90924372e-02]]\n",
      "  W=\n",
      "[[-0.39979156  0.44887682]\n",
      " [-0.82104409  0.50444933]]\n",
      "Epoch 28/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.2   1.616], tgt=[1.2 1.8], L=0.0169\n",
      "  dW=\n",
      "[[ 2.19610993e-17 -1.19099608e-01]\n",
      " [ 3.38610177e-16 -1.84001156e-02]]\n",
      "  W=\n",
      "[[-0.39979156  0.47269675]\n",
      " [-0.82104409  0.50812936]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.2   1.624], tgt=[1.2 1.8], L=0.0155\n",
      "  dW=\n",
      "[[ 2.19610993e-17 -1.20344182e-01]\n",
      " [ 3.38610177e-16 -1.76069360e-02]]\n",
      "  W=\n",
      "[[-0.39979156  0.49676558]\n",
      " [-0.82104409  0.51165074]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.2   1.633], tgt=[1.2 1.8], L=0.0139\n",
      "  dW=\n",
      "[[ 2.19610993e-17 -1.20697351e-01]\n",
      " [ 3.38610177e-16 -1.67127808e-02]]\n",
      "  W=\n",
      "[[-0.39979156  0.52090505]\n",
      " [-0.82104409  0.5149933 ]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.2   1.642], tgt=[1.2 1.8], L=0.0125\n",
      "  dW=\n",
      "[[ 2.19610993e-17 -1.20719611e-01]\n",
      " [ 3.38610177e-16 -1.58176616e-02]]\n",
      "  W=\n",
      "[[-0.39979156  0.54504897]\n",
      " [-0.82104409  0.51815683]]\n",
      "Epoch 29/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.2   1.652], tgt=[1.2 1.8], L=0.0110\n",
      "  dW=\n",
      "[[ 2.19610993e-17 -1.19543613e-01]\n",
      " [ 3.38610177e-16 -1.48214831e-02]]\n",
      "  W=\n",
      "[[-0.39979156  0.5689577 ]\n",
      " [-0.82104409  0.52112113]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.2   1.662], tgt=[1.2 1.8], L=0.0095\n",
      "  dW=\n",
      "[[ 2.19610993e-17 -1.17774826e-01]\n",
      " [ 3.38610177e-16 -1.38243485e-02]]\n",
      "  W=\n",
      "[[-0.39979156  0.59251266]\n",
      " [-0.82104409  0.523886  ]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.2   1.672], tgt=[1.2 1.8], L=0.0082\n",
      "  dW=\n",
      "[[ 2.19610993e-17 -1.15328945e-01]\n",
      " [ 3.38610177e-16 -1.28263200e-02]]\n",
      "  W=\n",
      "[[-0.39979156  0.61557845]\n",
      " [-0.82104409  0.52645126]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.2   1.683], tgt=[1.2 1.8], L=0.0068\n",
      "  dW=\n",
      "[[ 2.19610993e-17 -1.11168053e-01]\n",
      " [ 3.38610177e-16 -1.17272273e-02]]\n",
      "  W=\n",
      "[[-0.39979156  0.63781206]\n",
      " [-0.82104409  0.52879671]]\n",
      "Epoch 30/30\n",
      " Sample 0: inp=[0.1 0.9], pred=[1.2   1.694], tgt=[1.2 1.8], L=0.0056\n",
      "  dW=\n",
      "[[ 2.19610993e-17 -1.06006773e-01]\n",
      " [ 3.38610177e-16 -1.06272933e-02]]\n",
      "  W=\n",
      "[[-0.39979156  0.65901342]\n",
      " [-0.82104409  0.53092217]]\n",
      " Sample 1: inp=[0.1 0.9], pred=[1.2   1.705], tgt=[1.2 1.8], L=0.0045\n",
      "  dW=\n",
      "[[ 2.19610993e-17 -9.97591426e-02]\n",
      " [ 3.38610177e-16 -9.52659415e-03]]\n",
      "  W=\n",
      "[[-0.39979156  0.67896524]\n",
      " [-0.82104409  0.53282749]]\n",
      " Sample 2: inp=[0.1 0.9], pred=[1.2   1.716], tgt=[1.2 1.8], L=0.0035\n",
      "  dW=\n",
      "[[ 2.19610993e-17 -9.23549585e-02]\n",
      " [ 3.38610177e-16 -8.42520598e-03]]\n",
      "  W=\n",
      "[[-0.39979156  0.69743624]\n",
      " [-0.82104409  0.53451253]]\n",
      " Sample 3: inp=[0.1 0.9], pred=[1.2   1.726], tgt=[1.2 1.8], L=0.0027\n",
      "  dW=\n",
      "[[ 2.19610993e-17 -8.48952991e-02]\n",
      " [ 3.38610177e-16 -7.42352310e-03]]\n",
      "  W=\n",
      "[[-0.39979156  0.7144153 ]\n",
      " [-0.82104409  0.53599723]]\n",
      "Trained weight matrix:\n",
      " [[-0.39979156  0.7144153 ]\n",
      " [-0.82104409  0.53599723]]\n"
     ]
    }
   ],
   "source": [
    "from brian2 import *\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# suppress overflow warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "np.seterr(over='ignore', under='ignore')\n",
    "\n",
    "logging.getLogger('brian2').setLevel(logging.ERROR)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Spike timing and derivative\n",
    "\n",
    "start_scope()\n",
    "defaultclock.dt = 0.0001*ms\n",
    "\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(w=1, global_clock=1, layer=1, sum=1, spikes_received=1, result=1)\n",
    "def spike_timing(w, global_clock, layer, sum, spikes_received):\n",
    "    x = global_clock % 1\n",
    "    if w >= 0:\n",
    "        return np.power(x, (1 - w), where=(x>0), out=np.zeros_like(x))\n",
    "    else:\n",
    "        return 1 - np.power((1 - x), (1 + w), where=(x<1), out=np.ones_like(x))\n",
    "\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(w=1, global_clock=1, layer=1, sum=1, spikes_received=1, result=1)\n",
    "def d_spike_timing_dw(w, global_clock, layer, sum, spikes_received):\n",
    "    x = global_clock % 1\n",
    "    eps = 1e-9\n",
    "    if w >= 0:\n",
    "        return - np.power(x, (1 - w), where=(x>0), out=np.zeros_like(x)) * np.log(x + eps)\n",
    "    else:\n",
    "        return - np.power((1 - x), (1 + w), where=(x<1), out=np.ones_like(x)) * np.log(1 - x + eps)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# mini_urd: 2 inputs -> 2 hidden neurons (full connect), return both spike times\n",
    "\n",
    "def mini_urd(inputs, W):\n",
    "    \"\"\"\n",
    "    Two separate hidden neurons, each simulated independently in its own Brian scope.\n",
    "    inputs: [t_in0, t_in1], W: shape (2,2)\n",
    "    returns [t_h0, t_h1]\n",
    "    \"\"\"\n",
    "    n_input, n_hidden = W.shape\n",
    "    hidden_times = []\n",
    "    # simulate each hidden neuron separately to reset network state\n",
    "    for j in range(n_hidden):\n",
    "        start_scope()  # clear previous Brian state\n",
    "        defaultclock.dt = 0.0001*ms\n",
    "        # recreate spike timing functions (if needed)\n",
    "        # spike_timing and d_spike_timing_dw are already in namespace\n",
    "\n",
    "        # build one-neuron group\n",
    "        G = NeuronGroup(1,\n",
    "            '''\n",
    "            v               : 1\n",
    "            sum             : 1\n",
    "            sr              : 1\n",
    "            scheduled_time  : second\n",
    "            global_clock    : 1\n",
    "            ''',\n",
    "            threshold='v>1', reset='v=0', method='exact')\n",
    "        G.v = G.sum = G.sr = 0\n",
    "        G.global_clock = 0\n",
    "        G.scheduled_time = 1e9*second\n",
    "\n",
    "        # input spikes\n",
    "        stim = SpikeGeneratorGroup(n_input,\n",
    "            indices=list(range(n_input)),\n",
    "            times=inputs*ms)\n",
    "        S = Synapses(stim, G,\n",
    "            '''w:1\n",
    "              layer:1''', on_pre='''\n",
    "            sr += 1\n",
    "            sum += spike_timing(w, global_clock, layer, sum, sr)\n",
    "            scheduled_time = (sum/sr + layer)*ms\n",
    "        ''')\n",
    "        S.connect(True)\n",
    "        S.w = W[S.i, j]\n",
    "        S.layer = 1\n",
    "\n",
    "        # drive membrane\n",
    "        G.run_regularly('''\n",
    "            v = int(abs(t - scheduled_time) < 0.0005*ms) * 1.2\n",
    "            global_clock += 0.001\n",
    "        ''', dt=0.001*ms)\n",
    "\n",
    "        mon = SpikeMonitor(G)\n",
    "        run(5*ms)\n",
    "        ts = mon.spike_trains()[0]\n",
    "        t0 = float(ts[0]/ms) if len(ts)>0 else 5.0\n",
    "        hidden_times.append(t0)\n",
    "\n",
    "    return np.array(hidden_times)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Training full matrix W\n",
    "\n",
    "def train_snn(\n",
    "    X,           # list of input arrays\n",
    "    Y,           # list of target arrays\n",
    "    W_init,      # initial weight matrix (2x2)\n",
    "    epochs=10,\n",
    "    lr=0.1,\n",
    "    max_grad=20.0,\n",
    "    w_min=-20.0,\n",
    "    w_max=20.0\n",
    "):\n",
    "    W = W_init.copy()\n",
    "    layer_h = 1\n",
    "    n_input, n_hidden = W.shape\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        print(f\"Epoch {ep+1}/{epochs}\")\n",
    "        for i, inp in enumerate(X):\n",
    "            t_pred = mini_urd(inp, W)       # shape (n_hidden,)\n",
    "            t_tgt  = Y[i]\n",
    "            L = 0.5 * np.sum((t_pred - t_tgt)**2)\n",
    "\n",
    "            # gradient matrix dL/dW\n",
    "            dW = np.zeros_like(W)\n",
    "            for j in range(n_hidden):\n",
    "                for k in range(n_input):\n",
    "                    dW[k, j] = (t_pred[j] - t_tgt[j]) * d_spike_timing_dw(\n",
    "                        W[k, j], inp[k], layer_h, 0, 1)\n",
    "\n",
    "            # clip & update\n",
    "            dW = np.clip(dW, -max_grad, max_grad)\n",
    "            W = np.clip(W - lr * dW, w_min, w_max)\n",
    "\n",
    "            print(f\" Sample {i}: inp={inp}, pred={t_pred}, tgt={t_tgt}, L={L:.4f}\")\n",
    "            print(f\"  dW=\\n{dW}\\n  W=\\n{W}\")\n",
    "\n",
    "    return W\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "    X = [np.array([0.1, 0.9])]*4\n",
    "    Y = [np.array([1.2, 1.8]) for _ in X]\n",
    "    W0 = np.array([[0.2, -0.5], [0.3, -.5]])\n",
    "\n",
    "    W_trained = train_snn(X, Y, W0, epochs=30, lr=0.2)\n",
    "    print(\"Trained weight matrix:\\n\", W_trained)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fee676d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.529 2.501 2.504], Target: [2.1 2.9 2.1], Loss: 0.2532\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.505 2.522 2.481], Target: [2.1 2.9 2.1], Loss: 0.2260\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.484 2.545 2.461], Target: [2.1 2.9 2.1], Loss: 0.2019\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.466 2.567 2.443], Target: [2.1 2.9 2.1], Loss: 0.1812\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.447 2.591 2.424], Target: [2.1 2.9 2.1], Loss: 0.1604\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.429 2.615 2.405], Target: [2.1 2.9 2.1], Loss: 0.1412\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.411 2.639 2.387], Target: [2.1 2.9 2.1], Loss: 0.1236\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.393 2.662 2.368], Target: [2.1 2.9 2.1], Loss: 0.1072\n",
      " End Epoch 1: W1 norm=0.879, W2 norm=2.271\n",
      "\n",
      "Epoch 2/10\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.374 2.685 2.348], Target: [2.1 2.9 2.1], Loss: 0.0914\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.355 2.707 2.329], Target: [2.1 2.9 2.1], Loss: 0.0774\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.336 2.728 2.309], Target: [2.1 2.9 2.1], Loss: 0.0645\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.316 2.747 2.289], Target: [2.1 2.9 2.1], Loss: 0.0529\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.296 2.765 2.269], Target: [2.1 2.9 2.1], Loss: 0.0426\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.276 2.781 2.248], Target: [2.1 2.9 2.1], Loss: 0.0335\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.256 2.797 2.228], Target: [2.1 2.9 2.1], Loss: 0.0257\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.236 2.81  2.207], Target: [2.1 2.9 2.1], Loss: 0.0190\n",
      " End Epoch 2: W1 norm=1.833, W2 norm=3.898\n",
      "\n",
      "Epoch 3/10\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.215 2.823 2.186], Target: [2.1 2.9 2.1], Loss: 0.0133\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.196 2.834 2.165], Target: [2.1 2.9 2.1], Loss: 0.0089\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.177 2.844 2.145], Target: [2.1 2.9 2.1], Loss: 0.0055\n",
      " Input: [0.6 0.2 0.4 0.8], Pred: [2.159 2.852 2.127], Target: [2.1 2.9 2.1], Loss: 0.0033\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 146\u001b[0m\n\u001b[0;32m    144\u001b[0m W2_0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m W1_tr, W2_tr \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_snn_backprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW1_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2_0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrained W1:\u001b[39m\u001b[38;5;124m\"\u001b[39m, W1_tr)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrained W2:\u001b[39m\u001b[38;5;124m\"\u001b[39m, W2_tr) \n",
      "Cell \u001b[1;32mIn[6], line 102\u001b[0m, in \u001b[0;36mtrain_snn_backprop\u001b[1;34m(X, Y, W1_init, W2_init, epochs, lr, max_grad, w_min, w_max)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xi, yi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X, Y):\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     h_times \u001b[38;5;241m=\u001b[39m layer_forward(xi, W1, layer1_idx)  \u001b[38;5;66;03m# shape (10,)\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     o_times \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer2_idx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape (3,)\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# loss\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum((o_times \u001b[38;5;241m-\u001b[39m yi)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 78\u001b[0m, in \u001b[0;36mlayer_forward\u001b[1;34m(inputs, W, layer_idx)\u001b[0m\n\u001b[0;32m     73\u001b[0m G\u001b[38;5;241m.\u001b[39mrun_regularly(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124m    v = int(abs(t - scheduled_time) < 0.0005*ms) * 1.2\u001b[39m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124m    global_clock += 0.001\u001b[39m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m'''\u001b[39m, dt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m\u001b[38;5;241m*\u001b[39mms)\n\u001b[0;32m     77\u001b[0m mon \u001b[38;5;241m=\u001b[39m SpikeMonitor(G)\n\u001b[1;32m---> 78\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m ts \u001b[38;5;241m=\u001b[39m mon\u001b[38;5;241m.\u001b[39mspike_trains()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     80\u001b[0m t0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(ts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39mms) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ts)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m5.0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\units\\fundamentalunits.py:2652\u001b[0m, in \u001b[0;36mcheck_units.<locals>.do_check_units.<locals>.new_f\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m   2642\u001b[0m             error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2643\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2644\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected a quantity with unit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2645\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2646\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2647\u001b[0m             )\n\u001b[0;32m   2648\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DimensionMismatchError(\n\u001b[0;32m   2649\u001b[0m                 error_message, get_dimensions(newkeyset[k])\n\u001b[0;32m   2650\u001b[0m             )\n\u001b[1;32m-> 2652\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m au:\n\u001b[0;32m   2654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(au[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m], Callable) \u001b[38;5;129;01mand\u001b[39;00m au[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   2655\u001b[0m         \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   2656\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool_,\n\u001b[0;32m   2657\u001b[0m     ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\core\\magic.py:407\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;129m@check_units\u001b[39m(duration\u001b[38;5;241m=\u001b[39msecond, report_period\u001b[38;5;241m=\u001b[39msecond)\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[0;32m    336\u001b[0m     duration,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    341\u001b[0m     level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    342\u001b[0m ):\n\u001b[0;32m    343\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m    run(duration, report=None, report_period=10*second, namespace=None, level=0)\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;124;03m        intended use. See `MagicNetwork` for more details.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmagic_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\core\\magic.py:248\u001b[0m, in \u001b[0;36mMagicNetwork.run\u001b[1;34m(self, duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    240\u001b[0m     duration,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    245\u001b[0m     level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    246\u001b[0m ):\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_magic_objects(level\u001b[38;5;241m=\u001b[39mlevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 248\u001b[0m     \u001b[43mNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\core\\base.py:346\u001b[0m, in \u001b[0;36mdevice_override.<locals>.device_override_decorator.<locals>.device_override_decorated_function\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(curdev, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\units\\fundamentalunits.py:2652\u001b[0m, in \u001b[0;36mcheck_units.<locals>.do_check_units.<locals>.new_f\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m   2642\u001b[0m             error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2643\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2644\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected a quantity with unit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2645\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2646\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2647\u001b[0m             )\n\u001b[0;32m   2648\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DimensionMismatchError(\n\u001b[0;32m   2649\u001b[0m                 error_message, get_dimensions(newkeyset[k])\n\u001b[0;32m   2650\u001b[0m             )\n\u001b[1;32m-> 2652\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m au:\n\u001b[0;32m   2654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(au[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m], Callable) \u001b[38;5;129;01mand\u001b[39;00m au[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   2655\u001b[0m         \u001b[38;5;28mbool\u001b[39m,\n\u001b[0;32m   2656\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool_,\n\u001b[0;32m   2657\u001b[0m     ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\core\\network.py:1230\u001b[0m, in \u001b[0;36mNetwork.run\u001b[1;34m(self, duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[0;32m   1228\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m active_objects:\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_clock \u001b[38;5;129;01min\u001b[39;00m curclocks:\n\u001b[1;32m-> 1230\u001b[0m             \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m curclocks:\n\u001b[0;32m   1233\u001b[0m     timestep, t, dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_variables[c]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\core\\base.py:236\u001b[0m, in \u001b[0;36mBrianObject.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m codeobj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_objects:\n\u001b[1;32m--> 236\u001b[0m         \u001b[43mcodeobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\codegen\\codeobject.py:131\u001b[0m, in \u001b[0;36mCodeObject.__call__\u001b[1;34m(self, **kwds)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_namespace()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamespace\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\codegen\\codeobject.py:159\u001b[0m, in \u001b[0;36mCodeObject.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    150\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m    Runs the main code in the namespace.\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m        defined during the call of `CodeGenerator.code_object`.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_block\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\brian2\\codegen\\runtime\\numpy_rt\\numpy_rt.py:281\u001b[0m, in \u001b[0;36mNumpyCodeObject.run_block\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 281\u001b[0m     exec(compiled_code, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamespace)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    283\u001b[0m     code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcode, block)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from brian2 import *\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# suppress overflow warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "numpy.seterr(over='ignore', under='ignore')\n",
    "logging.getLogger('brian2').setLevel(logging.ERROR)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Spike timing and derivative\n",
    "\n",
    "start_scope()\n",
    "defaultclock.dt = 0.0001*ms\n",
    "\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(w=1, global_clock=1, layer=1, sum=1, spikes_received=1, result=1)\n",
    "def spike_timing(w, global_clock, layer, sum, spikes_received):\n",
    "    x = global_clock % 1\n",
    "    if w >= 0:\n",
    "        return np.power(x, (1 - w), where=(x>0), out=np.zeros_like(x))\n",
    "    else:\n",
    "        return 1 - np.power((1 - x), (1 + w), where=(x<1), out=np.ones_like(x))\n",
    "\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(w=1, global_clock=1, layer=1, sum=1, spikes_received=1, result=1)\n",
    "def d_spike_timing_dw(w, global_clock, layer, sum, spikes_received):\n",
    "    x = global_clock % 1\n",
    "    eps = 1e-9\n",
    "    if w >= 0:\n",
    "        return - np.power(x, (1 - w), where=(x>0), out=np.zeros_like(x)) * np.log(x + eps)\n",
    "    else:\n",
    "        return - np.power((1 - x), (1 + w), where=(x<1), out=np.ones_like(x)) * np.log(1 - x + eps)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Forward pass: 4->10->3 using two-stage mini_urd\n",
    "\n",
    "def layer_forward(inputs, W, layer_idx):\n",
    "    \"\"\"\n",
    "    inputs: array of spike times (ms) from previous layer (shape: n_in,)\n",
    "    W: weight matrix shape (n_in,n_out)\n",
    "    layer_idx: integer layer number\n",
    "    returns: array of output spike times (ms)\n",
    "    \"\"\"\n",
    "    n_in, n_out = W.shape\n",
    "    out_times = []\n",
    "    for j in range(n_out):\n",
    "        start_scope()\n",
    "        defaultclock.dt = 0.0001*ms\n",
    "        # Neuron group\n",
    "        G = NeuronGroup(1, '''\n",
    "            v : 1\n",
    "            sum : 1\n",
    "            sr : 1\n",
    "            scheduled_time : second\n",
    "            global_clock : 1\n",
    "        ''', threshold='v>1', reset='v=0', method='exact')\n",
    "        G.v = G.sum = G.sr = 0\n",
    "        G.global_clock = 0\n",
    "        G.scheduled_time = 1e9*second\n",
    "        # Spike inputs\n",
    "        stim = SpikeGeneratorGroup(n_in, indices=list(range(n_in)), times=inputs*ms)\n",
    "        S = Synapses(stim, G, '''w:1\n",
    "            layer:1''', on_pre='''\n",
    "            sr += 1\n",
    "            sum += spike_timing(w, global_clock, layer, sum, sr)\n",
    "            scheduled_time = (sum/sr + layer)*ms\n",
    "        ''')\n",
    "        S.connect(True)\n",
    "        S.w = W[:, j]\n",
    "        S.layer = layer_idx\n",
    "        G.run_regularly('''\n",
    "            v = int(abs(t - scheduled_time) < 0.0005*ms) * 1.2\n",
    "            global_clock += 0.001\n",
    "        ''', dt=0.001*ms)\n",
    "        mon = SpikeMonitor(G)\n",
    "        run(5*ms)\n",
    "        ts = mon.spike_trains()[0]\n",
    "        t0 = float(ts[0]/ms) if len(ts)>0 else float(5.0)\n",
    "        out_times.append(t0)\n",
    "    return np.array(out_times)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Training loop with backprop for 4-10-3\n",
    "\n",
    "def train_snn_backprop(\n",
    "    X, Y,        # lists of input arrays (4,) and target (3,)\n",
    "    W1_init, W2_init,\n",
    "    epochs=10, lr=0.1, max_grad=20.0, w_min=-20.0, w_max=20.0\n",
    "):\n",
    "    W1 = W1_init.copy()\n",
    "    W2 = W2_init.copy()\n",
    "    layer1_idx = 1\n",
    "    layer2_idx = 2\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        print(f\"Epoch {ep+1}/{epochs}\")\n",
    "        for xi, yi in zip(X, Y):\n",
    "            # forward\n",
    "            h_times = layer_forward(xi, W1, layer1_idx)  # shape (10,)\n",
    "            o_times = layer_forward(h_times, W2, layer2_idx)  # shape (3,)\n",
    "            # loss\n",
    "            L = 0.5 * np.sum((o_times - yi)**2)\n",
    "            # gradients\n",
    "            dW2 = np.zeros_like(W2)\n",
    "            delta_o = (o_times - yi)  # shape (3,)\n",
    "            # dW2[k,j] = delta_o[j] * d_spike_timing_dw(W2[k,j], h_times[k], layer2, 0, 1)\n",
    "            for k in range(W2.shape[0]):\n",
    "                for j in range(W2.shape[1]):\n",
    "                    dW2[k,j] = delta_o[j] * d_spike_timing_dw(\n",
    "                        W2[k,j], h_times[k], layer2_idx, 0, 1)\n",
    "            # hidden deltas\n",
    "            delta_h = np.zeros_like(h_times)\n",
    "            for k in range(len(h_times)):\n",
    "                # sum over output neurons\n",
    "                for j in range(W2.shape[1]):\n",
    "                    dt_dw = d_spike_timing_dw(W2[k,j], h_times[k], layer2_idx, 0, 1)\n",
    "                    delta_h[k] += delta_o[j] * W2[k,j] * dt_dw\n",
    "            # gradients for W1\n",
    "            dW1 = np.zeros_like(W1)\n",
    "            for i in range(W1.shape[0]):\n",
    "                for k in range(W1.shape[1]):\n",
    "                    dW1[i,k] = delta_h[k] * d_spike_timing_dw(\n",
    "                        W1[i,k], xi[i], layer1_idx, 0, 1)\n",
    "            # clip and update\n",
    "            dW1 = np.clip(dW1, -max_grad, max_grad)\n",
    "            dW2 = np.clip(dW2, -max_grad, max_grad)\n",
    "            W1 = np.clip(W1 - lr * dW1, w_min, w_max)\n",
    "            W2 = np.clip(W2 - lr * dW2, w_min, w_max)\n",
    "            # logging\n",
    "            print(f\" Input: {xi}, Pred: {o_times}, Target: {yi}, Loss: {L:.4f}\")\n",
    "        print(f\" End Epoch {ep+1}: W1 norm={np.linalg.norm(W1):.3f}, W2 norm={np.linalg.norm(W2):.3f}\\n\")\n",
    "    return W1, W2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # example usage with fixed input/target pairs\n",
    "    # 4 inputs per sample, constant across 8 samples\n",
    "    X = [np.array([0.6, 0.2, 0.4, 0.8]) for _ in range(8)]\n",
    "    # 3-targets (network outputs 3 values): use desired spike times [2.1, 2.0, 1.0]\n",
    "    Y = [np.array([2.1, 2.9, 2.1]) for _ in range(8)]\n",
    "    # initialize weights\n",
    "    W1_0 = np.random.randn(4, 10) * 0.1\n",
    "    W2_0 = np.random.randn(10, 3) * 0.1\n",
    "    # train\n",
    "    W1_tr, W2_tr = train_snn_backprop(X, Y, W1_0, W2_0,\n",
    "                                     epochs=10, lr=0.4)\n",
    "    print(\"Trained W1:\", W1_tr)\n",
    "    print(\"Trained W2:\", W2_tr) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "852f8684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " After Epoch 1: ||W1||=0.665, ||W2||=0.436\n",
      "Epoch 2/20\n",
      " After Epoch 2: ||W1||=0.664, ||W2||=0.431\n",
      "Epoch 3/20\n",
      " After Epoch 3: ||W1||=0.665, ||W2||=0.441\n",
      "Epoch 4/20\n",
      " After Epoch 4: ||W1||=0.665, ||W2||=0.464\n",
      "Epoch 5/20\n",
      " After Epoch 5: ||W1||=0.666, ||W2||=0.500\n",
      "Epoch 6/20\n",
      " After Epoch 6: ||W1||=0.668, ||W2||=0.544\n",
      "Epoch 7/20\n",
      " After Epoch 7: ||W1||=0.669, ||W2||=0.595\n",
      "Epoch 8/20\n",
      " After Epoch 8: ||W1||=0.671, ||W2||=0.650\n",
      "Epoch 9/20\n",
      " After Epoch 9: ||W1||=0.674, ||W2||=0.710\n",
      "Epoch 10/20\n",
      " After Epoch 10: ||W1||=0.677, ||W2||=0.772\n",
      "Epoch 11/20\n",
      " After Epoch 11: ||W1||=0.680, ||W2||=0.835\n",
      "Epoch 12/20\n",
      " After Epoch 12: ||W1||=0.684, ||W2||=0.901\n",
      "Epoch 13/20\n",
      " After Epoch 13: ||W1||=0.689, ||W2||=0.967\n",
      "Epoch 14/20\n",
      " After Epoch 14: ||W1||=0.694, ||W2||=1.034\n",
      "Epoch 15/20\n",
      " After Epoch 15: ||W1||=0.700, ||W2||=1.101\n",
      "Epoch 16/20\n",
      " After Epoch 16: ||W1||=0.706, ||W2||=1.169\n",
      "Epoch 17/20\n",
      " After Epoch 17: ||W1||=0.714, ||W2||=1.237\n",
      "Epoch 18/20\n",
      " After Epoch 18: ||W1||=0.722, ||W2||=1.305\n",
      "Epoch 19/20\n",
      " After Epoch 19: ||W1||=0.731, ||W2||=1.374\n",
      "Epoch 20/20\n",
      " After Epoch 20: ||W1||=0.741, ||W2||=1.442\n",
      "Trained W1 norm: 0.7412760264071365\n",
      "Trained W2 norm: 1.4418140208149846\n"
     ]
    }
   ],
   "source": [
    "from brian2 import *\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# suppress overflow warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "numpy.seterr(over='ignore', under='ignore')\n",
    "logging.getLogger('brian2').setLevel(logging.ERROR)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Spike timing and derivative\n",
    "\n",
    "start_scope()\n",
    "defaultclock.dt = 0.0001*ms\n",
    "\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(w=1, global_clock=1, layer=1, sum=1, spikes_received=1, result=1)\n",
    "def spike_timing(w, global_clock, layer, sum, spikes_received):\n",
    "    x = global_clock % 1\n",
    "    if w >= 0:\n",
    "        return np.power(x, (1 - w), where=(x>0), out=np.zeros_like(x))\n",
    "    else:\n",
    "        return 1 - np.power((1 - x), (1 + w), where=(x<1), out=np.ones_like(x))\n",
    "\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(w=1, global_clock=1, layer=1, sum=1, spikes_received=1, result=1)\n",
    "def d_spike_timing_dw(w, global_clock, layer, sum, spikes_received):\n",
    "    x = global_clock % 1\n",
    "    eps = 1e-9\n",
    "    if w >= 0:\n",
    "        return - np.power(x, (1 - w), where=(x>0), out=np.zeros_like(x)) * np.log(x + eps)\n",
    "    else:\n",
    "        return - np.power((1 - x), (1 + w), where=(x<1), out=np.ones_like(x)) * np.log(1 - x + eps)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Forward pass for a single layer\n",
    "\n",
    "def layer_forward(inputs, W, layer_idx):\n",
    "    n_in, n_out = W.shape\n",
    "    out_times = []\n",
    "    for j in range(n_out):\n",
    "        start_scope()\n",
    "        defaultclock.dt = 0.0001*ms\n",
    "        G = NeuronGroup(1, '''\n",
    "            v : 1\n",
    "            sum : 1\n",
    "            sr : 1\n",
    "            scheduled_time : second\n",
    "            global_clock : 1\n",
    "        ''', threshold='v>1', reset='v=0', method='exact')\n",
    "        G.v = G.sum = G.sr = 0\n",
    "        G.global_clock = 0\n",
    "        G.scheduled_time = 1e9*second\n",
    "        stim = SpikeGeneratorGroup(n_in, indices=list(range(n_in)), times=inputs*ms)\n",
    "        S = Synapses(stim, G, '''w:1\n",
    "                      layer:1''', on_pre='''\n",
    "            sr += 1\n",
    "            sum += spike_timing(w, global_clock, layer, sum, sr)\n",
    "            scheduled_time = (sum/sr + layer)*ms\n",
    "        ''')\n",
    "        S.connect(True)\n",
    "        S.w = W[:, j]\n",
    "        S.layer = layer_idx\n",
    "        G.run_regularly('''\n",
    "            v = int(abs(t - scheduled_time) < 0.0005*ms) * 1.2\n",
    "            global_clock += 0.001\n",
    "        ''', dt=0.001*ms)\n",
    "        mon = SpikeMonitor(G)\n",
    "        run(5*ms)\n",
    "        ts = mon.spike_trains()[0]\n",
    "        t0 = float(ts[0]/ms) if len(ts)>0 else 5.0\n",
    "        out_times.append(t0)\n",
    "    return np.array(out_times)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Training with mini-batch updates for 4-10-3 network\n",
    "\n",
    "def train_snn_backprop(\n",
    "    X, Y,\n",
    "    W1_init, W2_init,\n",
    "    batch_size=8,\n",
    "    epochs=10,\n",
    "    lr=0.1,\n",
    "    max_grad=20.0,\n",
    "    w_min=-20.0,\n",
    "    w_max=20.0\n",
    "):\n",
    "    W1 = W1_init.copy()\n",
    "    W2 = W2_init.copy()\n",
    "    n_samples = len(X)\n",
    "    layer1_idx, layer2_idx = 1, 2\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        print(f\"Epoch {ep+1}/{epochs}\")\n",
    "        # shuffle indices\n",
    "        idxs = np.random.permutation(n_samples)\n",
    "        for start in range(0, n_samples, batch_size):\n",
    "            batch_idxs = idxs[start:start+batch_size]\n",
    "            # accumulate gradients\n",
    "            acc_dW1 = np.zeros_like(W1)\n",
    "            acc_dW2 = np.zeros_like(W2)\n",
    "            for i in batch_idxs:\n",
    "                xi, yi = X[i], Y[i]\n",
    "                h_times = layer_forward(xi, W1, layer1_idx)\n",
    "                o_times = layer_forward(h_times, W2, layer2_idx)\n",
    "                delta_o = (o_times - yi)\n",
    "                # grad W2\n",
    "                for k in range(W2.shape[0]):\n",
    "                    for j in range(W2.shape[1]):\n",
    "                        acc_dW2[k,j] += delta_o[j] * d_spike_timing_dw(\n",
    "                            W2[k,j], h_times[k], layer2_idx, 0, 1)\n",
    "                # hidden deltas & grad W1\n",
    "                delta_h = np.zeros_like(h_times)\n",
    "                for k in range(len(h_times)):\n",
    "                    for j in range(W2.shape[1]):\n",
    "                        dt_dw = d_spike_timing_dw(W2[k,j], h_times[k], layer2_idx, 0, 1)\n",
    "                        delta_h[k] += delta_o[j] * W2[k,j] * dt_dw\n",
    "                for a in range(W1.shape[0]):\n",
    "                    for b in range(W1.shape[1]):\n",
    "                        acc_dW1[a,b] += delta_h[b] * d_spike_timing_dw(\n",
    "                            W1[a,b], xi[a], layer1_idx, 0, 1)\n",
    "            # average and clip\n",
    "            acc_dW1 /= len(batch_idxs)\n",
    "            acc_dW2 /= len(batch_idxs)\n",
    "            acc_dW1 = np.clip(acc_dW1, -max_grad, max_grad)\n",
    "            acc_dW2 = np.clip(acc_dW2, -max_grad, max_grad)\n",
    "            # update\n",
    "            W1 = np.clip(W1 - lr * acc_dW1, w_min, w_max)\n",
    "            W2 = np.clip(W2 - lr * acc_dW2, w_min, w_max)\n",
    "        print(f\" After Epoch {ep+1}: ||W1||={np.linalg.norm(W1):.3f}, ||W2||={np.linalg.norm(W2):.3f}\")\n",
    "    return W1, W2\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # example with batch updates\n",
    "    X = [np.array([0.6,0.2,0.4,0.8]) for _ in range(16)]\n",
    "    Y = [np.array([2.1,2.1,2.9]) for _ in range(16)]\n",
    "    W1_0 = np.random.randn(4,10)*0.1\n",
    "    W2_0 = np.random.randn(10,3)*0.1\n",
    "    W1_tr, W2_tr = train_snn_backprop(\n",
    "        X, Y, W1_0, W2_0,\n",
    "        batch_size=8, epochs=20, lr=0.05\n",
    "    )\n",
    "    print(\"Trained W1 norm:\", np.linalg.norm(W1_tr))\n",
    "    print(\"Trained W2 norm:\", np.linalg.norm(W2_tr))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
