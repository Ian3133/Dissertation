{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b7c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning, module='brian2.codegen.generators.base')\n",
    "\n",
    "start_scope()\n",
    "\n",
    "defaultclock.dt = 0.0001*ms  \n",
    "\n",
    "# Custom timing function\n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(w=1, global_clock=1, layer=1, result=1, sum=1, spikes_received=1)\n",
    "def spike_timing(w, global_clock, layer, sum, spikes_received): \n",
    "    #print(global_clock)\n",
    "    x = global_clock % 1\n",
    "    if w >= 0:\n",
    "        return (x ** (1 - w)) \n",
    "    else:\n",
    "        return (1 - (1 - x) ** (1 + w)) \n",
    "    \n",
    "@implementation('numpy', discard_units=True)\n",
    "@check_units(layer=1, result=1, sum=1, spikes_received=1)\n",
    "def math1(layer, sum, spikes_received): \n",
    "    return (sum/spikes_received )+ layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d72e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Urd, Verdande, Skuld \n",
    "\n",
    "# did not apply the specficyed weifhts to the first layer yet will maybe do after\n",
    "def run_Urd(inputs, weights_1, weights_2, weights_3):\n",
    "    '''4-10-3 SNN'''\n",
    "    # will add check of weights # so it all works\n",
    "    n_input = 4 \n",
    "    n_hidden = 10\n",
    "    n_output = 3\n",
    "    n_total = n_input + n_hidden + n_output\n",
    "\n",
    "    neurons = NeuronGroup(n_total, '''\n",
    "        v : 1\n",
    "        sum : 1\n",
    "        spikes_received : 1\n",
    "        scheduled_time : second\n",
    "        global_clock : 1\n",
    "    ''', threshold='v > 1', reset='v = 0', method='exact')\n",
    "    neurons.v = 0\n",
    "    neurons.scheduled_time = 1e9 * second\n",
    "    neurons.global_clock = 0.0\n",
    "    neurons.sum = 0.0\n",
    "    neurons.spikes_received = 0.0\n",
    "\n",
    "\n",
    "    indicess = [i for i in range(n_input)]\n",
    "    stim = SpikeGeneratorGroup(n_input, indices=indicess, times=(inputs*ms))\n",
    "\n",
    "    syn_input = Synapses(stim, neurons[0:n_input], '''\n",
    "        w : 1\n",
    "        layer : 1\n",
    "    ''', on_pre='''\n",
    "        spikes_received += 1\n",
    "        sum += spike_timing(w, global_clock, layer, spikes_received, sum)\n",
    "        scheduled_time = ((sum/spikes_received) + layer) * ms \n",
    "    ''')\n",
    "    syn_input.connect(j='i')\n",
    "    syn_input.w = weights_1\n",
    "    syn_input.layer = 0\n",
    "\n",
    "    syn_hidden = Synapses(neurons[0:n_input], neurons[n_input:n_input+n_hidden], '''\n",
    "        w : 1\n",
    "        layer : 1\n",
    "    ''', on_pre='''\n",
    "        spikes_received += 1\n",
    "        sum += spike_timing(w, global_clock, layer, spikes_received, sum)\n",
    "        scheduled_time = ((sum/spikes_received) + layer) * ms \n",
    "    ''')\n",
    "    for inp in range(n_input):\n",
    "        for hid in range(n_hidden):\n",
    "            syn_hidden.connect(i=inp, j=hid)\n",
    "\n",
    "    syn_hidden.w = weights_2\n",
    "    syn_hidden.layer = 1\n",
    "\n",
    "\n",
    "    syn_output = Synapses(\n",
    "        neurons[n_input:n_input+n_hidden], \n",
    "        neurons[n_input+n_hidden:n_total], \n",
    "        '''\n",
    "        w : 1\n",
    "        layer : 1\n",
    "        ''',\n",
    "        on_pre='''\n",
    "        spikes_received += 1\n",
    "        sum += spike_timing(w, global_clock, layer, spikes_received, sum)\n",
    "        scheduled_time = ((sum/spikes_received) + layer) * ms \n",
    "        '''\n",
    "    )\n",
    "\n",
    "    for hid in range(n_hidden):\n",
    "        for out in range(n_output):\n",
    "            syn_output.connect(i=hid, j=out)\n",
    "\n",
    "    # Set weights in correct order\n",
    "    syn_output.w[:] = weights_3\n",
    "    syn_output.layer = 2\n",
    "\n",
    "    print(syn_output.i[:], syn_output.j[:])\n",
    "    #weights_into_output_1 = weights_3[1::3]\n",
    "\n",
    "\n",
    "\n",
    "    neurons.run_regularly('''\n",
    "        v = int(abs(t - scheduled_time) < 0.0005*ms) * 1.2\n",
    "        global_clock += 0.001\n",
    "    ''', dt=0.001*ms)\n",
    "\n",
    "\n",
    "    spikemon = SpikeMonitor(neurons)\n",
    "\n",
    "    run(5*ms)\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for i in range(n_total):\n",
    "        times = spikemon.spike_trains()[i]\n",
    "        if len(times) > 0:\n",
    "            result.append(round(times[0]/ms, 3))\n",
    "        else:\n",
    "            result.append(None)  # or some other placeholder like float('nan')\n",
    "            \n",
    "    return result\n",
    "\n",
    "\n",
    "def calc_cost(outputs, desired_outputs):\n",
    "    return 0.5 * ((outputs - desired_outputs) ** 2)\n",
    "\n",
    "\n",
    "w_1 = [0] * 4 #np.random.uniform(  0.05, .95, size=4) #[0.5] * 4\n",
    "w_2 = [0] * 40 #np.random.uniform( -.95, .95, size=40) #[0.5] * 40\n",
    "w_3 = [0] * 30 #np.random.uniform( -.95, .95, size=30) #[0.5] * 30 \n",
    "\n",
    "\n",
    "\n",
    "def update_weights_input_neuron(hidden_activations, weights, actual_output, desired_output, learning_rate=0.2):\n",
    "\n",
    "    \"\"\"\n",
    "    Update all weights going into a single output neuron using gradient descent.\n",
    "\n",
    "    Args:\n",
    "        hidden_activations (np.ndarray): Activations from hidden neurons (shape: [n_hidden]).\n",
    "        weights (np.ndarray): Current weights into the output neuron (shape: [n_hidden]).\n",
    "        actual_output (float): Current output of this neuron.\n",
    "        desired_output (float): Target output for this neuron.\n",
    "        learning_rate (float): Learning rate.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Updated weights (shape: [n_hidden]).\n",
    "    \"\"\"\n",
    "    error = actual_output - desired_output\n",
    "    gradients = error * hidden_activations\n",
    "    updated_weights = weights - learning_rate * gradients\n",
    "    updated_weights = np.clip(updated_weights, -0.999999, 0.999999)\n",
    "    return updated_weights\n",
    "\n",
    "\n",
    "def update_single_hidden_neuron_weights(input_activations, weights_to_hidden, downstream_weights, output_errors, hidden_activation, learning_rate=0.2):\n",
    "    \"\"\"\n",
    "    Updates the weights into a single hidden neuron.\n",
    "\n",
    "    Args:\n",
    "        input_activations (np.ndarray): Input activations (shape: [n_input]).\n",
    "        weights_to_hidden (np.ndarray): Weights into this hidden neuron (shape: [n_input]).\n",
    "        downstream_weights (np.ndarray): Weights from this hidden neuron to each output neuron (shape: [n_output]).\n",
    "        output_errors (np.ndarray): Errors at each output neuron (shape: [n_output]).\n",
    "        hidden_activation (float): Activation value of this hidden neuron.\n",
    "        learning_rate (float): Learning rate.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Updated weights for this hidden neuron (shape: [n_input]).\n",
    "    \"\"\"\n",
    "    propagated_error = np.dot(output_errors, downstream_weights)\n",
    "    derivative = hidden_activation * (1 - hidden_activation)\n",
    "    local_gradient = propagated_error * derivative\n",
    "    gradients = local_gradient * input_activations\n",
    "    updated_weights = weights_to_hidden - learning_rate * gradients\n",
    "    updated_weights = np.clip(updated_weights, -0.999999, 0.999999)\n",
    "    return updated_weights\n",
    "\n",
    "\n",
    "def update_hidden_layer_weights(spike_times, output_errors):\n",
    "    lr = 0.2\n",
    "\n",
    "    input_activations = np.array(spike_times[:4])\n",
    "    hidden_activations = np.array(spike_times[4:14])\n",
    "\n",
    "    for i in range(10):  # 10 hidden neurons\n",
    "        start_idx = i * 4\n",
    "        end_idx = (i + 1) * 4\n",
    "\n",
    "        weights_to_hidden_i = w_2[start_idx:end_idx]\n",
    "        hidden_activation = hidden_activations[i]\n",
    "\n",
    "        # FIXED: Correct indexing for downstream weights\n",
    "        # Each hidden neuron i connects to all 3 outputs with weights at positions:\n",
    "        # i*3, i*3+1, i*3+2\n",
    "        downstream_weights = np.array([\n",
    "            w_3[i * 3 + 0],  # weight from hidden neuron i to output 0\n",
    "            w_3[i * 3 + 1],  # weight from hidden neuron i to output 1  \n",
    "            w_3[i * 3 + 2],  # weight from hidden neuron i to output 2\n",
    "        ])\n",
    "        \n",
    "        # Debug: Print the indices being used\n",
    "        print(f\"  Weight indices for neuron {i}: [{i*3}, {i*3+1}, {i*3+2}]\")\n",
    "        print(f\"  w_3 values at those indices: {w_3[i*3:i*3+3]}\")\n",
    "\n",
    "        propagated_error = np.dot(output_errors, downstream_weights)\n",
    "        derivative = hidden_activation * (1 - hidden_activation)\n",
    "        local_gradient = propagated_error * derivative\n",
    "        gradients = local_gradient * input_activations\n",
    "\n",
    "        # print(f\"\\nHidden Neuron {i}\")\n",
    "        # print(f\"  Hidden Activation: {hidden_activation}\")\n",
    "        # print(f\"  Downstream Weights: {downstream_weights}\")\n",
    "        # print(f\"  Propagated Error: {propagated_error}\")\n",
    "        # print(f\"  Local Gradient: {local_gradient}\")\n",
    "        # print(f\"  Gradients: {gradients}\")\n",
    "\n",
    "        updated_weights = weights_to_hidden_i - lr * gradients\n",
    "        updated_weights = np.clip(updated_weights, -0.999999, 0.999999)\n",
    "        w_2[start_idx:end_idx] = updated_weights\n",
    "\n",
    "    # print(\"hidden layer weights updated\")\n",
    "\n",
    "\n",
    "def update_last_layer_weights(spike_times, desired_outputs):\n",
    "\n",
    "    lr = 0.2 # will make more global later\n",
    "    \n",
    "    var = spike_times\n",
    "    hidden_activations = np.array(var[4:14])\n",
    "\n",
    "\n",
    "    weights_to_output_0 = w_3[0::3]\n",
    "    weights_to_output_1 = w_3[1::3]\n",
    "    weights_to_output_2 = w_3[2::3]\n",
    "\n",
    "    actual_output_0 = var[-3]\n",
    "    actual_output_1 = var[-2]\n",
    "    actual_output_2 = var[-1]\n",
    "\n",
    "\n",
    "    desired_output_0 = desired_outputs[0]\n",
    "    desired_output_1 = desired_outputs[1]\n",
    "    desired_output_2 = desired_outputs[2]\n",
    "\n",
    "\n",
    "    new_weights_0 = update_weights_input_neuron(\n",
    "        hidden_activations,\n",
    "        weights_to_output_0,\n",
    "        actual_output_0,\n",
    "        desired_output_0,\n",
    "        learning_rate=lr\n",
    "    )\n",
    "\n",
    "    new_weights_1 = update_weights_input_neuron(\n",
    "        hidden_activations,\n",
    "        weights_to_output_1,\n",
    "        actual_output_1,\n",
    "        desired_output_1,\n",
    "        learning_rate=lr\n",
    "    )\n",
    "\n",
    "    new_weights_2 = update_weights_input_neuron(\n",
    "        hidden_activations,\n",
    "        weights_to_output_2,\n",
    "        actual_output_2,\n",
    "        desired_output_2,\n",
    "        learning_rate=lr\n",
    "    )\n",
    "\n",
    "    w_3[0::3] = new_weights_0\n",
    "    w_3[1::3] = new_weights_1\n",
    "    w_3[2::3] = new_weights_2\n",
    "\n",
    "    print(\"weights updated\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeafe8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    Cannot use Cython, a test compilation failed: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/ (DistutilsPlatformError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6 7 7 7 8 8 8 9 9 9] [0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. 3 lines of abstract code, first line is: 'spikes_received += 1 (in-place)'\n",
      " [brian2.codegen.generators.base]\n",
      "INFO       Failed to vectorise code, falling back on Python loop: note that this will be very slow! Switch to another code generation target for best performance (e.g. cython). First line is: spikes_received += 1 (in-place) [brian2.codegen.generators.numpy_generator]\n",
      "WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. 3 lines of abstract code, first line is: 'spikes_received += 1 (in-place)'\n",
      " [brian2.codegen.generators.base]\n",
      "WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. 3 lines of abstract code, first line is: 'spikes_received += 1 (in-place)'\n",
      " [brian2.codegen.generators.base]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in iteration 0: name 'real_outputs' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. 3 lines of abstract code, first line is: 'spikes_received += 1 (in-place)'\n",
      " [brian2.codegen.generators.base]\n",
      "WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. 3 lines of abstract code, first line is: 'spikes_received += 1 (in-place)'\n",
      " [brian2.codegen.generators.base]\n",
      "WARNING    Came across an abstract code block that may not be well-defined: the outcome may depend on the order of execution. You can ignore this warning if you are sure that the order of operations does not matter. 3 lines of abstract code, first line is: 'spikes_received += 1 (in-place)'\n",
      " [brian2.codegen.generators.base]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6 7 7 7 8 8 8 9 9 9] [0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2]\n",
      "Error in iteration 1: name 'real_outputs' is not defined\n",
      "1 loop of training data completed\n",
      "1 loops completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data = [[0.1, 0.5, 0.1, 0.75], [0.3, 0.5, 0.21, 0.65]]\n",
    "result_data = [0, 1]\n",
    "\n",
    "def train_Urd(training_data, result_data, loops):\n",
    "    samples = len(training_data)\n",
    "\n",
    "    wanted_output = [[-.1, -.1, -.1] for _ in range(samples)]\n",
    "    \n",
    "    for i in range(samples):\n",
    "        if result_data[i] == 0:\n",
    "            wanted_output[i] = [0.99, 0.0, 0.0]\n",
    "        elif result_data[i] == 1:\n",
    "            wanted_output[i] = [0.0, 0.99, 0.0]\n",
    "        elif result_data[i] == 2:\n",
    "            wanted_output[i] = [0.0, 0.0, 0.99]\n",
    "\n",
    "    for j in range(loops):\n",
    "        for i in range(samples):\n",
    "            try:\n",
    "                var = run_Urd(training_data[i], w_1, w_2, w_3)\n",
    "\n",
    "                print(f\"Iter {i} Output:\", real_outputs(var))\n",
    "\n",
    "                update_last_layer_weights(var, wanted_output[i])\n",
    "\n",
    "                # calc error for hidden layer backprop\n",
    "                output_errors = get_output_errors(var, wanted_output[i])\n",
    "\n",
    "                update_hidden_layer_weights(var, output_errors)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in iteration {i}: {e}\")\n",
    "\n",
    "        print(f\"{j + 1} loop of training data completed\")\n",
    "    \n",
    "    print(f\"{loops} loops completed\")\n",
    "\n",
    "\n",
    "\n",
    "train_Urd(training_data, result_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46936208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0 0 0 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6 7 7 7 8 8 8 9 9 9] [0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2]\n",
      "Iter 0 Output: [0.428, 0.428, 0.428]\n",
      "weights updated\n",
      "  Weight indices for neuron 0: [0, 1, 2]\n",
      "  w_3 values at those indices: [-0.09361119999999996, 0.02054880000000002, 0.13470880000000002]\n",
      "  Weight indices for neuron 1: [3, 4, 5]\n",
      "  w_3 values at those indices: [-0.09361119999999996, 0.02054880000000002, 0.13470880000000002]\n",
      "  Weight indices for neuron 2: [6, 7, 8]\n",
      "  w_3 values at those indices: [-0.09361119999999996, 0.02054880000000002, 0.13470880000000002]\n",
      "  Weight indices for neuron 3: [9, 10, 11]\n",
      "  w_3 values at those indices: [-0.09361119999999996, 0.02054880000000002, 0.13470880000000002]\n",
      "  Weight indices for neuron 4: [12, 13, 14]\n",
      "  w_3 values at those indices: [-0.09361119999999996, 0.02054880000000002, 0.13470880000000002]\n",
      "  Weight indices for neuron 5: [15, 16, 17]\n",
      "  w_3 values at those indices: [-0.09361119999999996, 0.02054880000000002, 0.13470880000000002]\n",
      "  Weight indices for neuron 6: [18, 19, 20]\n",
      "  w_3 values at those indices: [-0.09361119999999996, 0.02054880000000002, 0.13470880000000002]\n",
      "  Weight indices for neuron 7: [21, 22, 23]\n",
      "  w_3 values at those indices: [-0.09361119999999996, 0.02054880000000002, 0.13470880000000002]\n",
      "  Weight indices for neuron 8: [24, 25, 26]\n",
      "  w_3 values at those indices: [-0.09361119999999996, 0.02054880000000002, 0.13470880000000002]\n",
      "  Weight indices for neuron 9: [27, 28, 29]\n",
      "  w_3 values at those indices: [-0.09361119999999996, 0.02054880000000002, 0.13470880000000002]\n",
      "[0 0 0 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6 7 7 7 8 8 8 9 9 9] [0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2]\n",
      "Iter 1 Output: [0.396, 0.435, 0.479]\n",
      "weights updated\n",
      "  Weight indices for neuron 0: [0, 1, 2]\n",
      "  w_3 values at those indices: [-0.17803039999999992, 0.039086800000000005, 0.25477799999999995]\n",
      "  Weight indices for neuron 1: [3, 4, 5]\n",
      "  w_3 values at those indices: [-0.17803039999999992, 0.039086800000000005, 0.25477799999999995]\n",
      "  Weight indices for neuron 2: [6, 7, 8]\n",
      "  w_3 values at those indices: [-0.17803039999999992, 0.039086800000000005, 0.25477799999999995]\n",
      "  Weight indices for neuron 3: [9, 10, 11]\n",
      "  w_3 values at those indices: [-0.17803039999999992, 0.039086800000000005, 0.25477799999999995]\n",
      "  Weight indices for neuron 4: [12, 13, 14]\n",
      "  w_3 values at those indices: [-0.17803039999999992, 0.039086800000000005, 0.25477799999999995]\n",
      "  Weight indices for neuron 5: [15, 16, 17]\n",
      "  w_3 values at those indices: [-0.17803039999999992, 0.039086800000000005, 0.25477799999999995]\n",
      "  Weight indices for neuron 6: [18, 19, 20]\n",
      "  w_3 values at those indices: [-0.17803039999999992, 0.039086800000000005, 0.25477799999999995]\n",
      "  Weight indices for neuron 7: [21, 22, 23]\n",
      "  w_3 values at those indices: [-0.17803039999999992, 0.039086800000000005, 0.25477799999999995]\n",
      "  Weight indices for neuron 8: [24, 25, 26]\n",
      "  w_3 values at those indices: [-0.17803039999999992, 0.039086800000000005, 0.25477799999999995]\n",
      "  Weight indices for neuron 9: [27, 28, 29]\n",
      "  w_3 values at those indices: [-0.17803039999999992, 0.039086800000000005, 0.25477799999999995]\n",
      "[0 0 0 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6 7 7 7 8 8 8 9 9 9] [0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2]\n",
      "Iter 2 Output: [0.365, 0.439, 0.529]\n",
      "weights updated\n",
      "  Weight indices for neuron 0: [0, 1, 2]\n",
      "  w_3 values at those indices: [-0.2535554, 0.05647179999999999, 0.360513]\n",
      "  Weight indices for neuron 1: [3, 4, 5]\n",
      "  w_3 values at those indices: [-0.25344939999999994, 0.056447399999999995, 0.3603645999999999]\n",
      "  Weight indices for neuron 2: [6, 7, 8]\n",
      "  w_3 values at those indices: [-0.2535554, 0.05647179999999999, 0.360513]\n",
      "  Weight indices for neuron 3: [9, 10, 11]\n",
      "  w_3 values at those indices: [-0.25344939999999994, 0.056447399999999995, 0.3603645999999999]\n",
      "  Weight indices for neuron 4: [12, 13, 14]\n",
      "  w_3 values at those indices: [-0.2535554, 0.05647179999999999, 0.360513]\n",
      "  Weight indices for neuron 5: [15, 16, 17]\n",
      "  w_3 values at those indices: [-0.25344939999999994, 0.056447399999999995, 0.3603645999999999]\n",
      "  Weight indices for neuron 6: [18, 19, 20]\n",
      "  w_3 values at those indices: [-0.2535554, 0.05647179999999999, 0.360513]\n",
      "  Weight indices for neuron 7: [21, 22, 23]\n",
      "  w_3 values at those indices: [-0.25344939999999994, 0.056447399999999995, 0.3603645999999999]\n",
      "  Weight indices for neuron 8: [24, 25, 26]\n",
      "  w_3 values at those indices: [-0.2535554, 0.05647179999999999, 0.360513]\n",
      "  Weight indices for neuron 9: [27, 28, 29]\n",
      "  w_3 values at those indices: [-0.25344939999999994, 0.056447399999999995, 0.3603645999999999]\n",
      "[0 0 0 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6 7 7 7 8 8 8 9 9 9] [0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2]\n",
      "Iter 3 Output: [0.336, 0.444, 0.576]\n",
      "weights updated\n",
      "  Weight indices for neuron 0: [0, 1, 2]\n",
      "  w_3 values at those indices: [-0.3207209999999999, 0.07240940000000001, 0.45272339999999994]\n",
      "  Weight indices for neuron 1: [3, 4, 5]\n",
      "  w_3 values at those indices: [-0.32047339999999985, 0.07235140000000001, 0.4523805999999999]\n",
      "  Weight indices for neuron 2: [6, 7, 8]\n",
      "  w_3 values at those indices: [-0.3207209999999999, 0.07240940000000001, 0.45272339999999994]\n",
      "  Weight indices for neuron 3: [9, 10, 11]\n",
      "  w_3 values at those indices: [-0.32047339999999985, 0.07235140000000001, 0.4523805999999999]\n",
      "  Weight indices for neuron 4: [12, 13, 14]\n",
      "  w_3 values at those indices: [-0.3207209999999999, 0.07240940000000001, 0.45272339999999994]\n",
      "  Weight indices for neuron 5: [15, 16, 17]\n",
      "  w_3 values at those indices: [-0.32047339999999985, 0.07235140000000001, 0.4523805999999999]\n",
      "  Weight indices for neuron 6: [18, 19, 20]\n",
      "  w_3 values at those indices: [-0.3207209999999999, 0.07240940000000001, 0.45272339999999994]\n",
      "  Weight indices for neuron 7: [21, 22, 23]\n",
      "  w_3 values at those indices: [-0.32047339999999985, 0.07235140000000001, 0.4523805999999999]\n",
      "  Weight indices for neuron 8: [24, 25, 26]\n",
      "  w_3 values at those indices: [-0.3207209999999999, 0.07240940000000001, 0.45272339999999994]\n",
      "  Weight indices for neuron 9: [27, 28, 29]\n",
      "  w_3 values at those indices: [-0.32047339999999985, 0.07235140000000001, 0.4523805999999999]\n",
      "[0 0 0 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6 7 7 7 8 8 8 9 9 9] [0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2]\n",
      "Iter 4 Output: [0.31, 0.448, 0.622]\n",
      "weights updated\n",
      "  Weight indices for neuron 0: [0, 1, 2]\n",
      "  w_3 values at those indices: [-0.3804449999999999, 0.08719820000000003, 0.5317866]\n",
      "  Weight indices for neuron 1: [3, 4, 5]\n",
      "  w_3 values at those indices: [-0.37998739999999986, 0.08708820000000003, 0.5311657999999999]\n",
      "  Weight indices for neuron 2: [6, 7, 8]\n",
      "  w_3 values at those indices: [-0.38040299999999994, 0.08718780000000002, 0.531731]\n",
      "  Weight indices for neuron 3: [9, 10, 11]\n",
      "  w_3 values at those indices: [-0.37998739999999986, 0.08708820000000003, 0.5311657999999999]\n",
      "  Weight indices for neuron 4: [12, 13, 14]\n",
      "  w_3 values at those indices: [-0.3804449999999999, 0.08719820000000003, 0.5317866]\n",
      "  Weight indices for neuron 5: [15, 16, 17]\n",
      "  w_3 values at those indices: [-0.37998739999999986, 0.08708820000000003, 0.5311657999999999]\n",
      "  Weight indices for neuron 6: [18, 19, 20]\n",
      "  w_3 values at those indices: [-0.38040299999999994, 0.08718780000000002, 0.531731]\n",
      "  Weight indices for neuron 7: [21, 22, 23]\n",
      "  w_3 values at those indices: [-0.37998739999999986, 0.08708820000000003, 0.5311657999999999]\n",
      "  Weight indices for neuron 8: [24, 25, 26]\n",
      "  w_3 values at those indices: [-0.3804449999999999, 0.08719820000000003, 0.5317866]\n",
      "  Weight indices for neuron 9: [27, 28, 29]\n",
      "  w_3 values at those indices: [-0.37998739999999986, 0.08708820000000003, 0.5311657999999999]\n",
      "Final Output: [0.31, 0.448, 0.622]\n",
      "[-0.011241727353189564, -0.02237215047515943, -0.05576341984106902, -0.10028511232894849, -0.011151653233920672, -0.022192894059584703, -0.055316616536576796, -0.09948157983923292, -0.011232780566088193, -0.022354345483007194, -0.0557190402337642, -0.1002052999014402, -0.011151653233920672, -0.022192894059584703, -0.055316616536576796, -0.09948157983923292, -0.011241727353189564, -0.02237215047515943, -0.05576341984106902, -0.10028511232894849, -0.011151653233920672, -0.022192894059584703, -0.055316616536576796, -0.09948157983923292, -0.011232780566088193, -0.022354345483007194, -0.0557190402337642, -0.1002052999014402, -0.011151653233920672, -0.022192894059584703, -0.055316616536576796, -0.09948157983923292, -0.011241727353189564, -0.02237215047515943, -0.05576341984106902, -0.10028511232894849, -0.011151653233920672, -0.022192894059584703, -0.055316616536576796, -0.09948157983923292]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logging.getLogger('brian2').setLevel(logging.ERROR)\n",
    "\n",
    "inputs = [0.1, 0.2, 0.5, 0.9]\n",
    "wanted_output = [2.1, 2.1, 2.9]\n",
    "\n",
    "# Initialize weights if not already\n",
    "# w_1 = np.random.uniform(0.05, 0.95, size=4)\n",
    "# w_2 = np.random.uniform(-0.95, 0.95, size=40)\n",
    "# w_3 = np.random.uniform(-0.95, 0.95, size=30)\n",
    "\n",
    "def real_outputs(var):\n",
    "    return [round(var[-3 + i] - 2, 4) for i in range(3)]\n",
    "\n",
    "def get_output_errors(var, wanted_output):\n",
    "    return np.array([var[-3 + i] - wanted_output[i] for i in range(3)])\n",
    "\n",
    "\n",
    "print(w_2)\n",
    "for i in range(5):\n",
    "    try:\n",
    "        var = run_Urd(inputs, w_1, w_2, w_3)\n",
    "\n",
    "        print(f\"Iter {i} Output:\", real_outputs(var))\n",
    "\n",
    "        update_last_layer_weights(var, wanted_output)\n",
    "\n",
    "        # Compute error for hidden layer backprop\n",
    "        output_errors = get_output_errors(var, wanted_output)\n",
    "\n",
    "        update_hidden_layer_weights(var, output_errors)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in iteration {i}: {e}\")\n",
    "\n",
    "# Final output\n",
    "print(\"Final Output:\", real_outputs(var))\n",
    "print(w_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e6e6322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.011241727353189564, -0.02237215047515943, -0.05576341984106902, -0.10028511232894849, -0.011151653233920672, -0.022192894059584703, -0.055316616536576796, -0.09948157983923292, -0.011232780566088193, -0.022354345483007194, -0.0557190402337642, -0.1002052999014402, -0.011151653233920672, -0.022192894059584703, -0.055316616536576796, -0.09948157983923292, -0.011241727353189564, -0.02237215047515943, -0.05576341984106902, -0.10028511232894849, -0.011151653233920672, -0.022192894059584703, -0.055316616536576796, -0.09948157983923292, -0.011232780566088193, -0.022354345483007194, -0.0557190402337642, -0.1002052999014402, -0.011151653233920672, -0.022192894059584703, -0.055316616536576796, -0.09948157983923292, -0.011241727353189564, -0.02237215047515943, -0.05576341984106902, -0.10028511232894849, -0.011151653233920672, -0.022192894059584703, -0.055316616536576796, -0.09948157983923292]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 0, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[2, 2, 2, 2]\n",
      "[3, 3, 3, 3]\n",
      "[4, 4, 4, 4]\n",
      "[5, 5, 5, 5]\n",
      "[6, 6, 6, 6]\n",
      "[7, 7, 7, 7]\n",
      "[8, 8, 8, 8]\n",
      "[9, 9, 9, 9]\n"
     ]
    }
   ],
   "source": [
    "print(w_2)\n",
    "list = [i % 10 for i in range(40)]\n",
    "print(list)\n",
    "for i in range(10):\n",
    "    print(list[i::10])  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
